{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5501f101",
   "metadata": {},
   "source": [
    "### Edward Kim 2023 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0266ae9-9e89-49f4-b72c-f73ee79f6a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sequitur.models import LINEAR_AE, LSTM_AE\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0790f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc2c0297-1cfc-41eb-93c9-e7d0c02fd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test3_rs_segments.pickle', 'rb') as f:\n",
    "    segments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4c96f4f-d00f-4225-9d59-7f46f812df47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/test3_rs_bps.pickle', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e6de891-0e93-4a1c-bba1-2e5864dd8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 1000\n",
    "X_train = segments[:samples, :]\n",
    "seg_tensor = torch.tensor(X_train, dtype=torch.float32)  # input for linear autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6631e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 200])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seg_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c168c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = seg_tensor.shape[0]  \n",
    "input_size = seg_tensor.shape[1]  \n",
    "batch_size = 64  # Hyperparamter to adjust appropriately\n",
    "seq_len //= batch_size  # adjust size to accodomate different batch sizes\n",
    "\n",
    "#seg_tensor_reshaped = seg_tensor.reshape(seq_len, batch_size, input_size).to(device)  # input for LSTM autoencoder\n",
    "\n",
    "encoding_dim = 45  # should range from 20 - 100 for dimension 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2b5929-69c2-4b0e-b87c-9d6275ee24af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149, 98]\n"
     ]
    }
   ],
   "source": [
    "# CreaIte linear and LSTM autoencoder models\n",
    "\n",
    "# function for outputing list of hidden layer dimensions for the encoder and decoder\n",
    "def calculate_h_dims(input_dim, encoding_dim, num_hidden_layers):\n",
    "    units_per_layer = (input_dim - encoding_dim) // (num_hidden_layers + 1)\n",
    "    h_dims = [input_dim - units_per_layer]  # first hidden layer\n",
    "    for i in range(num_hidden_layers - 1):\n",
    "        h_dims.append(h_dims[-1] - units_per_layer)\n",
    "    return h_dims\n",
    "\n",
    "rows, cols = segments.shape\n",
    "input_dim = cols\n",
    "num_hidden_layers = 2  # Hyperparameter for tuning\n",
    "\n",
    "h_dims = calculate_h_dims(input_dim, encoding_dim, num_hidden_layers)\n",
    "print(h_dims)\n",
    "h_activ = nn.ReLU()  # activation function for the hidden layers\n",
    "out_activ = nn.ReLU()  # activation function for the decoder's output layer\n",
    "\n",
    "linear_model = LINEAR_AE(input_dim, encoding_dim, h_dims, h_activ, out_activ)\n",
    "#lstm_model = LSTM_AE(input_dim, encoding_dim, h_dims, h_activ, out_activ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c33a0989-063c-41ad-8029-33020785bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder training algorithm\n",
    "# Mostly taken from https://github.com/shobrook/sequitur/blob/master/sequitur/quick_train.py\n",
    "\n",
    "def get_device():\n",
    "    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def instantiate_model(model, train_set, encoding_dim, **kwargs):\n",
    "    return model(train_set[-1].shape[-1], encoding_dim, **kwargs)\n",
    "\n",
    "\n",
    "def train_model(model, train_set, verbose, lr, epochs, denoise, clip_value, device=None):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = MSELoss(reduction=\"sum\")\n",
    "    mean_losses = []\n",
    "    epoch_lst = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        losses = []\n",
    "        for x in train_set:\n",
    "            x = x.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_prime = model(x)  # Forward pass\n",
    "            loss = criterion(x_prime, x)\n",
    "            loss.backward()  # Backward pass\n",
    "            if clip_value is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        mean_loss = mean(losses)\n",
    "        print(f\"Epoch: {epoch}, Loss: {mean_loss}\")\n",
    "        epoch_lst.append(epoch)\n",
    "        mean_losses.append(mean_loss)\n",
    "    if len(epochs) == len(losses): \n",
    "        plt.plot(epoch_lst, mean_losses)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Losses')\n",
    "        plt.title('Losses for Training over Epochs')\n",
    "        plt.show()\n",
    "    return mean_losses\n",
    "\n",
    "\n",
    "def get_encodings(model, train_set, device=None):\n",
    "    if device is None:\n",
    "        device = get_device()\n",
    "    model.eval()\n",
    "    return [model.encoder(x.to(device)) for x in train_set]\n",
    "\n",
    "\n",
    "def train_ae(model, train_set, encoding_dim, verbose=True, lr=1e-3, epochs=50, clip_value=1, \n",
    "                denoise=False, device=None, **kwargs,):\n",
    "    model = instantiate_model(model, train_set, encoding_dim, **kwargs)\n",
    "    losses = train_model(model, train_set, verbose, lr, epochs, denoise, clip_value, device)\n",
    "    encodings = get_encodings(model, train_set, device)\n",
    "    return model.encoder, model.decoder, encodings, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7ea56dc-f261-4762-835a-294ad17cfc55",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Get linear encoder, decoder\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m encoder_lin, decoder_lin, encodings_lin, losses_lin \u001b[39m=\u001b[39m train_ae(LINEAR_AE, seg_tensor, encoding_dim, h_dims\u001b[39m=\u001b[39;49mh_dims,\n\u001b[1;32m      4\u001b[0m                                                        h_activ\u001b[39m=\u001b[39;49mh_activ, out_activ\u001b[39m=\u001b[39;49mout_activ, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[20], line 56\u001b[0m, in \u001b[0;36mtrain_ae\u001b[0;34m(model, train_set, encoding_dim, verbose, lr, epochs, clip_value, denoise, device, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_ae\u001b[39m(model, train_set, encoding_dim, verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, clip_value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, \n\u001b[1;32m     54\u001b[0m                 denoise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, device\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,):\n\u001b[1;32m     55\u001b[0m     model \u001b[39m=\u001b[39m instantiate_model(model, train_set, encoding_dim, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 56\u001b[0m     losses \u001b[39m=\u001b[39m train_model(model, train_set, verbose, lr, epochs, denoise, clip_value, device)\n\u001b[1;32m     57\u001b[0m     encodings \u001b[39m=\u001b[39m get_encodings(model, train_set, device)\n\u001b[1;32m     58\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mencoder, model\u001b[39m.\u001b[39mdecoder, encodings, losses\n",
      "Cell \u001b[0;32mIn[20], line 31\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_set, verbose, lr, epochs, denoise, clip_value, device)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mif\u001b[39;00m clip_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m         torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), clip_value)\n\u001b[0;32m---> 31\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     32\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[1;32m     33\u001b[0m mean_loss \u001b[39m=\u001b[39m mean(losses)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[1;32m    393\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get linear encoder, decoder\n",
    "\n",
    "encoder_lin, decoder_lin, encodings_lin, losses_lin = train_ae(LINEAR_AE, seg_tensor, encoding_dim, h_dims=h_dims,\n",
    "                                                       h_activ=h_activ, out_activ=out_activ, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09051317-4a07-4ef4-ab69-909869a6f7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# Get LSTM encoder, decoder\n",
    "\n",
    "\n",
    "# implement own version of quick_sort\n",
    "\n",
    "\n",
    "#train_segs = [s.reshape(200, 1) for s in X_train]\n",
    "#train_segs_tensor = [torch.tensor(s).float() for s in train_segs]\n",
    "\n",
    "#train_set = train_segs_tensor \n",
    "#encoder, decoder, _, _ = quick_train(LSTM_AE, train_set, encoding_dim=100, h_dims=[64], verbose=True)\n",
    "#encoder_lstm, decoder_lstm, encodings_lstm, losses_lstm = quick_train(LSTM_AE, train_set, encoding_dim, \n",
    "                                                                    # h_dims=[64], verbose=True)\n",
    "    \n",
    "encoder_lstm, decoder_lstm, encodings_lstm, losses_lstm = quick_train(LSTM_AE, seg_tensor_reshaped, encoding_dim, verbose=True, \n",
    "                                                              h_dims=h_dims, h_activ=h_activ, out_activ=out_activ, epochs=1000)\n",
    "                                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d6b887-649e-4bcf-9f8e-c11ecdeceff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.16 ('cs229')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "5f50178aaa0e1c5d48dbd1d95cd7694ff4464615447632ef401c1e79e7e694d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
