{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rohan Sanda ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rohansanda/Desktop/cs229_proj/losses_lin.pickle', 'rb') as file:\n",
    "    losses = pickle.load(file)\n",
    "with open('/Users/rohansanda/Desktop/cs229_proj/encodings_lin.pickle', 'rb') as file:\n",
    "    embeddings = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f979442c550>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rohansanda/Desktop/cs229_proj/hyper_parameter_tuning.pickle', 'rb') as file:\n",
    "    hyp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rohansanda/Desktop/cs229_proj/hyper_parameter_tuning.pickle', 'rb') as file:\n",
    "    hyp2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 549.3430177089147, Val Loss: 353.25805209367326, Train SBP MSE: 422.7694047654317, Val SBP MSE: 259.55016278077096, Train SBP MAE: 14.675705596191094, Val SBP MAE: 12.602975266483853, Train SBP R2: -0.1538048780471839, Val SBP R2: 0.2924222060131898, Train DBP MSE: 126.57361263816586, Val DBP MSE: 93.70767974468771, Train DBP MAE: 8.481873284931847, Val DBP MAE: 7.635911432974679, Train DBP R2: -0.0041792656862211786, Val DBP R2: 0.25715750560684936\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 329.66299869210377, Val Loss: 318.02241744158255, Train SBP MSE: 241.4655416832366, Val SBP MSE: 232.91953397055818, Train SBP MAE: 11.930247604751587, Val SBP MAE: 11.571835568128312, Train SBP R2: 0.341002171079518, Val SBP R2: 0.3650218198378512, Train DBP MSE: 88.19745675154682, Val DBP MSE: 85.10715611135522, Train DBP MAE: 7.342238363432884, Val DBP MAE: 7.157233925737653, Train DBP R2: 0.300280243960935, Val DBP R2: 0.32533584964736684\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 307.77300457589286, Val Loss: 331.6780311612368, Train SBP MSE: 224.79192476361965, Val SBP MSE: 241.36839129203977, Train SBP MAE: 11.449549061386925, Val SBP MAE: 12.09598862135751, Train SBP R2: 0.3865071208693881, Val SBP R2: 0.34198880085919314, Train DBP MSE: 82.98107955029135, Val DBP MSE: 90.30075596287188, Train DBP MAE: 7.072369093223981, Val DBP MAE: 7.468817689732143, Train DBP R2: 0.34166468198336364, Val DBP R2: 0.2841649799908781\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 294.0596562953404, Val Loss: 292.7013038202875, Train SBP MSE: 214.18655732582783, Val SBP MSE: 213.41236770017943, Train SBP MAE: 11.133135630607605, Val SBP MAE: 11.125560210745675, Train SBP R2: 0.41545085365912526, Val SBP R2: 0.4182016658015274, Train DBP MSE: 79.87309899633156, Val DBP MSE: 79.29236310086624, Train DBP MAE: 6.910693356932913, Val DBP MAE: 6.859624824251448, Train DBP R2: 0.36632203010981934, Val DBP R2: 0.3714310614385473\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 284.2666118687221, Val Loss: 283.51557923758054, Train SBP MSE: 206.72342522472988, Val SBP MSE: 205.91086886298493, Train SBP MAE: 10.912428880677904, Val SBP MAE: 10.83830234930856, Train SBP R2: 0.4358189269555719, Val SBP R2: 0.43865202476855314, Train DBP MSE: 77.54318669209242, Val DBP MSE: 77.6123324102988, Train DBP MAE: 6.787556086788858, Val DBP MAE: 6.7662432507923675, Train DBP R2: 0.3848065276130428, Val DBP R2: 0.38474905407520643\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 276.3119259172712, Val Loss: 279.9294270545081, Train SBP MSE: 200.63914479408956, Val SBP MSE: 203.86099468073135, Train SBP MAE: 10.729578448663439, Val SBP MAE: 10.747972751181466, Train SBP R2: 0.45242389496212587, Val SBP R2: 0.444240329689227, Train DBP MSE: 75.67278086227621, Val DBP MSE: 76.08284518586942, Train DBP MAE: 6.690844371131488, Val DBP MAE: 6.684121438080924, Train DBP R2: 0.3996455032381545, Val DBP R2: 0.39687365376685546\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 270.2727132254464, Val Loss: 274.20881501499434, Train SBP MSE: 196.08061629523576, Val SBP MSE: 199.55895189167578, Train SBP MAE: 10.586494548579624, Val SBP MAE: 10.689064847455706, Train SBP R2: 0.4648648435251205, Val SBP R2: 0.4559684284648303, Train DBP MSE: 74.19209689398166, Val DBP MSE: 74.66154825727986, Train DBP MAE: 6.609775432787623, Val DBP MAE: 6.601550031934465, Train DBP R2: 0.4113925973520428, Val DBP R2: 0.4081406039099321\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 264.80238680768696, Val Loss: 274.4089269516019, Train SBP MSE: 191.9043514607389, Val SBP MSE: 199.52515496220624, Train SBP MAE: 10.468756996004922, Val SBP MAE: 10.676363571657454, Train SBP R2: 0.47626253381146666, Val SBP R2: 0.45606056463050015, Train DBP MSE: 72.89803530761027, Val DBP MSE: 74.89448830225356, Train DBP MAE: 6.538380896932738, Val DBP MAE: 6.633770294761658, Train DBP R2: 0.42165911172632997, Val DBP R2: 0.4062940341888188\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 260.45235833653044, Val Loss: 268.6168357807278, Train SBP MSE: 188.73060794714533, Val SBP MSE: 195.33719177208357, Train SBP MAE: 10.364254690579006, Val SBP MAE: 10.490384723227365, Train SBP R2: 0.4849241841257478, Val SBP R2: 0.4674776630580897, Train DBP MSE: 71.72175033711285, Val DBP MSE: 73.2876852885614, Train DBP MAE: 6.47351099486351, Val DBP MAE: 6.5175154607772825, Train DBP R2: 0.43099123833069986, Val DBP R2: 0.4190315340601374\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 256.44648635689873, Val Loss: 273.5900646816442, Train SBP MSE: 185.81635883105744, Val SBP MSE: 200.10984164967311, Train SBP MAE: 10.276711273520334, Val SBP MAE: 10.635865713364737, Train SBP R2: 0.4928776329990229, Val SBP R2: 0.4544666094888087, Train DBP MSE: 70.63012770967961, Val DBP MSE: 73.49293994001064, Train DBP MAE: 6.41661074380534, Val DBP MAE: 6.529722253635952, Train DBP R2: 0.43965169121321335, Val DBP R2: 0.41740443286967177\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 252.37642488752093, Val Loss: 270.2991099523234, Train SBP MSE: 182.72668084672333, Val SBP MSE: 197.0586810078741, Train SBP MAE: 10.178594057178497, Val SBP MAE: 10.685332721546718, Train SBP R2: 0.501309855127059, Val SBP R2: 0.4627845912341989, Train DBP MSE: 69.64974408337584, Val DBP MSE: 73.2499412828811, Train DBP MAE: 6.361458407184056, Val DBP MAE: 6.553731382696969, Train DBP R2: 0.4474296228802729, Val DBP R2: 0.4193307395404602\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 248.92943023594447, Val Loss: 270.5690760289947, Train SBP MSE: 180.21625071284694, Val SBP MSE: 197.32381815886475, Train SBP MAE: 10.10374849149159, Val SBP MAE: 10.620435960960387, Train SBP R2: 0.5081612178364071, Val SBP R2: 0.46206178236214135, Train DBP MSE: 68.71317964499833, Val DBP MSE: 73.24884078875398, Train DBP MAE: 6.310046719561305, Val DBP MAE: 6.5428390618733, Train DBP R2: 0.45485991242005486, Val DBP R2: 0.4193394634124489\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 245.8275455470494, Val Loss: 270.2716573474612, Train SBP MSE: 177.89372548721062, Val SBP MSE: 196.8737114326697, Train SBP MAE: 10.02933117389679, Val SBP MAE: 10.528315147972107, Train SBP R2: 0.5144997581955744, Val SBP R2: 0.4632888496888097, Train DBP MSE: 67.93381994227542, Val DBP MSE: 73.40662276890843, Train DBP MAE: 6.272741587935175, Val DBP MAE: 6.5109858233043125, Train DBP R2: 0.4610430088623044, Val DBP R2: 0.41808868908928176\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 243.20023138514927, Val Loss: 261.0219680988375, Train SBP MSE: 175.98510347258733, Val SBP MSE: 189.47609286977652, Train SBP MAE: 9.968483459608896, Val SBP MAE: 10.316793859699795, Train SBP R2: 0.5197086909281652, Val SBP R2: 0.4834560133977728, Train DBP MSE: 67.21512762248105, Val DBP MSE: 71.55939889205173, Train DBP MAE: 6.233178170245035, Val DBP MAE: 6.409018825135912, Train DBP R2: 0.4667447970225945, Val DBP R2: 0.4327320608612161\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 240.476518863351, Val Loss: 259.56554833365095, Train SBP MSE: 174.042256441016, Val SBP MSE: 188.78932563597692, Train SBP MAE: 9.907982809816088, Val SBP MAE: 10.369087710789271, Train SBP R2: 0.5250110291699077, Val SBP R2: 0.4853282574336387, Train DBP MSE: 66.43426237292398, Val DBP MSE: 70.77961881106549, Train DBP MAE: 6.1885602787767136, Val DBP MAE: 6.408030521188463, Train DBP R2: 0.4729398378099794, Val DBP R2: 0.43891355827974277\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 237.87777037876674, Val Loss: 254.73658748257094, Train SBP MSE: 172.1188384953403, Val SBP MSE: 184.862059749123, Train SBP MAE: 9.852631477969034, Val SBP MAE: 10.198892431640624, Train SBP R2: 0.5302603423492176, Val SBP R2: 0.49603465076758135, Train DBP MSE: 65.75893192964601, Val DBP MSE: 69.882698133151, Train DBP MAE: 6.1540268475226, Val DBP MAE: 6.352370682552882, Train DBP R2: 0.47829761195019505, Val DBP R2: 0.4460236563578308\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 235.24339674246653, Val Loss: 257.9420495669628, Train SBP MSE: 170.2022676812376, Val SBP MSE: 187.78602372955535, Train SBP MAE: 9.793512730789185, Val SBP MAE: 10.300337096623013, Train SBP R2: 0.5354909686185463, Val SBP R2: 0.4880634287085963, Train DBP MSE: 65.04112910602719, Val DBP MSE: 70.16286296206088, Train DBP MAE: 6.11536715994903, Val DBP MAE: 6.330898858029502, Train DBP R2: 0.4839923432398011, Val DBP R2: 0.4438027248299594\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 233.22976796526228, Val Loss: 247.382213369366, Train SBP MSE: 168.72270426072453, Val SBP MSE: 179.4990961449007, Train SBP MAE: 9.74541069090707, Val SBP MAE: 10.02740645299639, Train SBP R2: 0.5395289322760994, Val SBP R2: 0.510654999742328, Train DBP MSE: 64.50706362039465, Val DBP MSE: 67.8868939630966, Train DBP MAE: 6.085614665770531, Val DBP MAE: 6.234539194379534, Train DBP R2: 0.4882293834570536, Val DBP R2: 0.46184485854790547\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 230.9086733328683, Val Loss: 253.71545214888383, Train SBP MSE: 167.03712824272768, Val SBP MSE: 184.23018882020713, Train SBP MAE: 9.694594116074699, Val SBP MAE: 10.164118229348318, Train SBP R2: 0.5441291370448507, Val SBP R2: 0.4977572381594618, Train DBP MSE: 63.871545121427665, Val DBP MSE: 69.50116892655404, Train DBP MAE: 6.0540857638972145, Val DBP MAE: 6.288426337133135, Train DBP R2: 0.4932713071749696, Val DBP R2: 0.44904812679914907\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0007), Train Loss: 228.8389533708845, Val Loss: 249.8982064283744, Train SBP MSE: 165.52576022667364, Val SBP MSE: 182.0096624947042, Train SBP MAE: 9.640122563893454, Val SBP MAE: 10.098909222630093, Train SBP R2: 0.5482539004969629, Val SBP R2: 0.503810769785316, Train DBP MSE: 63.313193202905076, Val DBP MSE: 67.90368832326011, Train DBP MAE: 6.021250782053811, Val DBP MAE: 6.211604087257386, Train DBP R2: 0.4977010252485091, Val DBP R2: 0.4617117257627421\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 600.8338744611468, Val Loss: 337.86154267556924, Train SBP MSE: 467.98228475861094, Val SBP MSE: 248.15768986384805, Train SBP MAE: 15.080139881867208, Val SBP MAE: 12.166831744493757, Train SBP R2: -0.2771980112745891, Val SBP R2: 0.3234800206885733, Train DBP MSE: 132.85159032138614, Val DBP MSE: 89.71346727953907, Train DBP MAE: 8.556251523642182, Val DBP MAE: 7.432557501084464, Train DBP R2: -0.05398597411882644, Val DBP R2: 0.2888205534897038\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 324.42114971923826, Val Loss: 315.3912189978786, Train SBP MSE: 237.8871087863691, Val SBP MSE: 230.0518653468706, Train SBP MAE: 11.843211383642469, Val SBP MAE: 11.544467508860997, Train SBP R2: 0.3507682830205209, Val SBP R2: 0.3728395712000335, Train DBP MSE: 86.53404091925746, Val DBP MSE: 85.34865679196378, Train DBP MAE: 7.2744528717688155, Val DBP MAE: 7.15717945325034, Train DBP R2: 0.31347705215960964, Val DBP R2: 0.3234214177836212\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 301.66166438685826, Val Loss: 296.0472067810282, Train SBP MSE: 220.85763227292082, Val SBP MSE: 217.25148879048444, Train SBP MAE: 11.34084731937136, Val SBP MAE: 11.138340975352696, Train SBP R2: 0.39724443018331823, Val SBP R2: 0.4077355701427059, Train DBP MSE: 80.80403204337809, Val DBP MSE: 78.80573037383893, Train DBP MAE: 6.9736071244001385, Val DBP MAE: 6.846923873056684, Train DBP R2: 0.35893641754728145, Val DBP R2: 0.3752887118443968\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 286.8172009364537, Val Loss: 285.30135060925807, Train SBP MSE: 209.53651645795762, Val SBP MSE: 207.96443208293977, Train SBP MAE: 11.000813462706974, Val SBP MAE: 10.944060231781005, Train SBP R2: 0.4281415540172656, Val SBP R2: 0.4330536629050107, Train DBP MSE: 77.28068448037789, Val DBP MSE: 77.34115983950166, Train DBP MAE: 6.78125723753316, Val DBP MAE: 6.762748766735622, Train DBP R2: 0.3868891044843694, Val DBP R2: 0.3868987018890333\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 276.5595390433175, Val Loss: 275.5949495444568, Train SBP MSE: 201.7204519958336, Val SBP MSE: 200.81284382408933, Train SBP MAE: 10.761202205290113, Val SBP MAE: 10.708789484024049, Train SBP R2: 0.44947283580321595, Val SBP R2: 0.4525501062494657, Train DBP MSE: 74.83908702757527, Val DBP MSE: 74.79344610689671, Train DBP MAE: 6.646857115892002, Val DBP MAE: 6.634534084320069, Train DBP R2: 0.40625966274018543, Val DBP R2: 0.4070950190882673\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 268.14694428100586, Val Loss: 271.37858094070685, Train SBP MSE: 195.30882480100158, Val SBP MSE: 197.907024494915, Train SBP MAE: 10.562698838887895, Val SBP MAE: 10.663633502360753, Train SBP R2: 0.46697118514030134, Val SBP R2: 0.46047186290965336, Train DBP MSE: 72.8381193635372, Val DBP MSE: 73.47890103211517, Train DBP MAE: 6.5389955801044195, Val DBP MAE: 6.571414519664219, Train DBP R2: 0.42213445842354524, Val DBP R2: 0.41751572254612135\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 261.2886098423549, Val Loss: 272.06705151266766, Train SBP MSE: 190.1247073526447, Val SBP MSE: 197.1431185053725, Train SBP MAE: 10.399760585975647, Val SBP MAE: 10.695229343387059, Train SBP R2: 0.48111946534426364, Val SBP R2: 0.46255440028548367, Train DBP MSE: 71.16390259746409, Val DBP MSE: 74.9246147556669, Train DBP MAE: 6.448732788310732, Val DBP MAE: 6.678265822901045, Train DBP R2: 0.43541695647123035, Val DBP R2: 0.4060552148107086\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 255.46258561314175, Val Loss: 259.85441776603403, Train SBP MSE: 185.72214875646546, Val SBP MSE: 188.6730794009238, Train SBP MAE: 10.267777531419481, Val SBP MAE: 10.312237808418274, Train SBP R2: 0.4931347472613138, Val SBP R2: 0.4856451643994326, Train DBP MSE: 69.74043703245907, Val DBP MSE: 71.19019830258057, Train DBP MAE: 6.372784742631231, Val DBP MAE: 6.429703084863935, Train DBP R2: 0.44671010498775865, Val DBP R2: 0.4356587994973814\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 250.29415697370257, Val Loss: 262.2476234714989, Train SBP MSE: 181.91028019358254, Val SBP MSE: 191.19375722896223, Train SBP MAE: 10.142925784124646, Val SBP MAE: 10.45592449002947, Train SBP R2: 0.5035379422246988, Val SBP R2: 0.4787733688366559, Train DBP MSE: 68.38387705752116, Val DBP MSE: 71.05971820938014, Train DBP MAE: 6.293767297536986, Val DBP MAE: 6.428753934778486, Train DBP R2: 0.4574724540358709, Val DBP R2: 0.43669314543536353\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 245.59108546578543, Val Loss: 254.84303179432314, Train SBP MSE: 178.4012581003683, Val SBP MSE: 185.37094178344475, Train SBP MAE: 10.036814532661438, Val SBP MAE: 10.155608228383745, Train SBP R2: 0.5131146210540772, Val SBP R2: 0.49464735197575194, Train DBP MSE: 67.18982728623442, Val DBP MSE: 69.47996861846372, Train DBP MAE: 6.229585374399594, Val DBP MAE: 6.296235664354052, Train DBP R2: 0.4669455187413176, Val DBP R2: 0.4492161865546208\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 241.13411542619977, Val Loss: 252.09488698202688, Train SBP MSE: 175.1713152664238, Val SBP MSE: 183.58160925594132, Train SBP MAE: 9.925940447916304, Val SBP MAE: 10.097098703520638, Train SBP R2: 0.5219296482429212, Val SBP R2: 0.49952537612705683, Train DBP MSE: 65.96280035841149, Val DBP MSE: 68.52178220559203, Train DBP MAE: 6.1614186449766155, Val DBP MAE: 6.257906132480076, Train DBP R2: 0.4766802096747338, Val DBP R2: 0.45681195231224625\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 237.2180474897112, Val Loss: 255.28510159243177, Train SBP MSE: 172.15761392409655, Val SBP MSE: 185.6960836667278, Train SBP MAE: 9.832483884988513, Val SBP MAE: 10.228565344401769, Train SBP R2: 0.5301545180432412, Val SBP R2: 0.49376096001960246, Train DBP MSE: 65.06043349921751, Val DBP MSE: 69.58765177888048, Train DBP MAE: 6.113334369846752, Val DBP MAE: 6.3333688649041315, Train DBP R2: 0.4838391906910642, Val DBP R2: 0.4483625571860774\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 233.47150953805107, Val Loss: 247.51378712837177, Train SBP MSE: 169.38316968955064, Val SBP MSE: 179.9443478104854, Train SBP MAE: 9.742714838518415, Val SBP MAE: 10.033091743305752, Train SBP R2: 0.5377264171816499, Val SBP R2: 0.509441168134873, Train DBP MSE: 64.08833973448976, Val DBP MSE: 67.57554633410787, Train DBP MAE: 6.0596371195554735, Val DBP MAE: 6.207337868091038, Train DBP R2: 0.49155135424945906, Val DBP R2: 0.4643129833587162\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 230.51280306396484, Val Loss: 244.74080945281705, Train SBP MSE: 167.13622784091075, Val SBP MSE: 177.86705075197457, Train SBP MAE: 9.670964816979, Val SBP MAE: 9.961519939558846, Train SBP R2: 0.5438586784957995, Val SBP R2: 0.5151042324703706, Train DBP MSE: 63.37657512402404, Val DBP MSE: 66.86907967255797, Train DBP MAE: 6.022904789246832, Val DBP MAE: 6.167675714342935, Train DBP R2: 0.49719818101675795, Val DBP R2: 0.4699133083107496\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 227.2992711983817, Val Loss: 244.4873405644837, Train SBP MSE: 164.78644589461095, Val SBP MSE: 177.71077754165924, Train SBP MAE: 9.596865354851314, Val SBP MAE: 9.969012697056362, Train SBP R2: 0.5502716067763882, Val SBP R2: 0.5155302597640139, Train DBP MSE: 62.51282538235368, Val DBP MSE: 66.77197352707675, Train DBP MAE: 5.975721124567304, Val DBP MAE: 6.1740629051208495, Train DBP R2: 0.5040507908399974, Val DBP R2: 0.47068309123064167\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 224.3903781842913, Val Loss: 251.0727785518444, Train SBP MSE: 162.540361235867, Val SBP MSE: 183.28989351367824, Train SBP MAE: 9.52703679171971, Val SBP MAE: 10.087093535232544, Train SBP R2: 0.5564015286831155, Val SBP R2: 0.5003206427497793, Train DBP MSE: 61.85001699681852, Val DBP MSE: 67.78886625483877, Train DBP MAE: 5.94113168184076, Val DBP MAE: 6.206804480307443, Train DBP R2: 0.5093092204921561, Val DBP R2: 0.46262194690950276\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 221.40992646397183, Val Loss: 248.0514976878053, Train SBP MSE: 160.2940715311197, Val SBP MSE: 180.77671534213718, Train SBP MAE: 9.453805678136009, Val SBP MAE: 10.017221071842739, Train SBP R2: 0.5625320101929654, Val SBP R2: 0.50717199297612, Train DBP MSE: 61.115854990637835, Val DBP MSE: 67.27163818655724, Train DBP MAE: 5.900863313034603, Val DBP MAE: 6.20451211340768, Train DBP R2: 0.5151337383272341, Val DBP R2: 0.4667221336760434\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 219.02096686837334, Val Loss: 240.49031117803654, Train SBP MSE: 158.47990759394168, Val SBP MSE: 174.18232579035086, Train SBP MAE: 9.399051337112699, Val SBP MAE: 9.82899544279916, Train SBP R2: 0.5674831518240742, Val SBP R2: 0.5251494180786572, Train DBP MSE: 60.54105928265748, Val DBP MSE: 66.31156671573812, Train DBP MAE: 5.868640627878053, Val DBP MAE: 6.146667459814889, Train DBP R2: 0.519693914180074, Val DBP R2: 0.4743328427248864\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 216.50881936645507, Val Loss: 239.69489524743673, Train SBP MSE: 156.54673044833612, Val SBP MSE: 174.79479132511682, Train SBP MAE: 9.338437698807034, Val SBP MAE: 9.886526750346592, Train SBP R2: 0.5727590994106, Val SBP R2: 0.5234797330846674, Train DBP MSE: 59.962088693699, Val DBP MSE: 64.89919638464258, Train DBP MAE: 5.839345630046299, Val DBP MAE: 6.035662465749468, Train DBP R2: 0.5242872116988567, Val DBP R2: 0.4855290296608603\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 214.21270029296875, Val Loss: 237.94926812836195, Train SBP MSE: 154.71027302024942, Val SBP MSE: 172.74576230725816, Train SBP MAE: 9.279332791887011, Val SBP MAE: 9.752596145929608, Train SBP R2: 0.5777710835205382, Val SBP R2: 0.5290657339437614, Train DBP MSE: 59.50242717096087, Val DBP MSE: 65.20683943539824, Train DBP MAE: 5.813555595517158, Val DBP MAE: 6.047626737798963, Train DBP R2: 0.5279339636619764, Val DBP R2: 0.483090271900251\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 8493.617398214286, Val Loss: 3581.235514248529, Train SBP MSE: 7079.364280193856, Val SBP MSE: 3340.2678430327633, Train SBP MAE: 80.2838814594809, Val SBP MAE: 54.53353211830003, Train SBP R2: -18.320709937590404, Val SBP R2: -8.10613704255132, Train DBP MSE: 1414.2531185855123, Val DBP MSE: 241.02158519591055, Train DBP MAE: 33.05001463822474, Val DBP MAE: 12.381611680998121, Train DBP R2: -10.220061026269734, Val DBP R2: -0.9106339633777061\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 1672.2348358468191, Val Loss: 610.2231758996381, Train SBP MSE: 1533.3615445024027, Val SBP MSE: 484.07901066404133, Train SBP MAE: 32.89431751050779, Val SBP MAE: 16.886326516233172, Train SBP R2: -3.184787285727201, Val SBP R2: -0.3196815398273991, Train DBP MSE: 138.87329107515265, Val DBP MSE: 126.16864199780532, Train DBP MAE: 9.280185107423579, Val DBP MAE: 8.929619995743888, Train DBP R2: -0.10175949432627607, Val DBP R2: -0.00016806510631051097\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 505.8127404436384, Val Loss: 492.997189098128, Train SBP MSE: 379.7550904148138, Val SBP MSE: 366.85317936970193, Train SBP MAE: 15.29236082555226, Val SBP MAE: 15.115950735473632, Train SBP R2: -0.036411979781201476, Val SBP R2: -0.00010402842518386635, Train DBP MSE: 126.05765005869652, Val DBP MSE: 126.16243734880052, Train DBP MAE: 8.926307169822284, Val DBP MAE: 8.929142612075806, Train DBP R2: -8.5845949089558e-05, Val DBP R2: -0.00011887941570210003\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 490.01954251708986, Val Loss: 478.2436749948226, Train SBP MSE: 364.4519652705627, Val SBP MSE: 355.3307530782617, Train SBP MAE: 15.088543990911756, Val SBP MAE: 14.809925471087864, Train SBP R2: 0.005352680200757187, Val SBP R2: 0.03130806120451646, Train DBP MSE: 125.56757694413902, Val DBP MSE: 122.93001550808893, Train DBP MAE: 8.903018392694849, Val DBP MAE: 8.787090950284686, Train DBP R2: 0.0038021781820990475, Val DBP R2: 0.02550527763980559\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 458.83723864222935, Val Loss: 447.4972403071262, Train SBP MSE: 340.47289012805817, Val SBP MSE: 331.8435022088008, Train SBP MAE: 14.488211971832174, Val SBP MAE: 14.272387542595181, Train SBP R2: 0.07079538622115278, Val SBP R2: 0.09533829327593768, Train DBP MSE: 118.36434846207784, Val DBP MSE: 115.66322139233732, Train DBP MAE: 8.614283854494776, Val DBP MAE: 8.516919821459906, Train DBP R2: 0.06094941872396542, Val DBP R2: 0.08311083869834202\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 437.98441744384763, Val Loss: 430.8121478274274, Train SBP MSE: 324.53816030373406, Val SBP MSE: 319.07878457196097, Train SBP MAE: 14.122057115115439, Val SBP MAE: 13.968428179795401, Train SBP R2: 0.11428379572862424, Val SBP R2: 0.13013707995197832, Train DBP MSE: 113.44625717866533, Val DBP MSE: 111.7448284233913, Train DBP MAE: 8.436921816439288, Val DBP MAE: 8.369089573574065, Train DBP R2: 0.09996738771939129, Val DBP R2: 0.11417284786338555\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 421.1701588030134, Val Loss: 412.5525381307933, Train SBP MSE: 311.3814113452079, Val SBP MSE: 304.67352446889157, Train SBP MAE: 13.792680682107381, Val SBP MAE: 13.611714679908753, Train SBP R2: 0.15019065406907617, Val SBP R2: 0.16940826381999008, Train DBP MSE: 109.78874734096061, Val DBP MSE: 107.89078728942944, Train DBP MAE: 8.292943184062413, Val DBP MAE: 8.212737049457004, Train DBP R2: 0.1289844590229161, Val DBP R2: 0.14472472511876422\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 404.3262451206752, Val Loss: 397.7591644789227, Train SBP MSE: 298.10685073984405, Val SBP MSE: 293.0666793222037, Train SBP MAE: 13.469708369520733, Val SBP MAE: 13.361640911320277, Train SBP R2: 0.18641903911245394, Val SBP R2: 0.2010504935764662, Train DBP MSE: 106.21939428928597, Val DBP MSE: 104.70463644290342, Train DBP MAE: 8.154289258762768, Val DBP MAE: 8.102748934745788, Train DBP R2: 0.15730213323398445, Val DBP R2: 0.16998208127991077\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 392.2677458844866, Val Loss: 387.58309818665333, Train SBP MSE: 288.6393248036903, Val SBP MSE: 285.1681308588628, Train SBP MAE: 13.239261129624502, Val SBP MAE: 13.163001062938145, Train SBP R2: 0.212257421656322, Val SBP R2: 0.22258327721070048, Train DBP MSE: 103.62842091634833, Val DBP MSE: 102.42666244765759, Train DBP MAE: 8.060741157126428, Val DBP MAE: 8.015810574831281, Train DBP R2: 0.17785777421491145, Val DBP R2: 0.1880401090680448\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 383.5173985421317, Val Loss: 380.945260523878, Train SBP MSE: 281.8222783767827, Val SBP MSE: 280.1247722910323, Train SBP MAE: 13.05968777405875, Val SBP MAE: 12.969086934007917, Train SBP R2: 0.23086222449347182, Val SBP R2: 0.2363323286136242, Train DBP MSE: 101.69512021697797, Val DBP MSE: 100.83118542424428, Train DBP MAE: 7.9856216774089, Val DBP MAE: 7.938108142580305, Train DBP R2: 0.19319573001928758, Val DBP R2: 0.20068782518958816\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 377.11964597342353, Val Loss: 375.2086111553408, Train SBP MSE: 276.91973157376174, Val SBP MSE: 275.6547940875931, Train SBP MAE: 12.924150198064531, Val SBP MAE: 12.839681899969918, Train SBP R2: 0.2442420536684774, Val SBP R2: 0.24851824783044285, Train DBP MSE: 100.19991441824553, Val DBP MSE: 99.56553408961068, Train DBP MAE: 7.923931151550157, Val DBP MAE: 7.8779931723458425, Train DBP R2: 0.20505803393655908, Val DBP R2: 0.21072093663800762\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 372.1481017211914, Val Loss: 370.03468286489874, Train SBP MSE: 273.1562743574698, Val SBP MSE: 271.70068234217564, Train SBP MAE: 12.82355039931706, Val SBP MAE: 12.791359493528093, Train SBP R2: 0.2545131263750954, Val SBP R2: 0.2592978275310459, Train DBP MSE: 98.99182717588508, Val DBP MSE: 98.34420209652149, Train DBP MAE: 7.873614698222705, Val DBP MAE: 7.8414358723776685, Train DBP R2: 0.21464246575163537, Val DBP R2: 0.22040271839485415\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 368.00066357073104, Val Loss: 366.2153011440577, Train SBP MSE: 270.04440305978295, Val SBP MSE: 268.77053969737915, Train SBP MAE: 12.73779151235308, Val SBP MAE: 12.704287659236362, Train SBP R2: 0.26300591758149416, Val SBP R2: 0.26728589367771605, Train DBP MSE: 97.95626036308589, Val DBP MSE: 97.4560932975183, Train DBP MAE: 7.828276602864266, Val DBP MAE: 7.802743970625741, Train DBP R2: 0.22285819650286587, Val DBP R2: 0.2274429626666309\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 364.3310293997628, Val Loss: 363.24433426795974, Train SBP MSE: 267.29337178501237, Val SBP MSE: 266.6690852478584, Train SBP MAE: 12.664080657482147, Val SBP MAE: 12.600469895662581, Train SBP R2: 0.2705139190326675, Val SBP R2: 0.27301481516104253, Train DBP MSE: 97.03765776214233, Val DBP MSE: 96.58549081115375, Train DBP MAE: 7.78833612142631, Val DBP MAE: 7.75073796874455, Train DBP R2: 0.23014598473966008, Val DBP R2: 0.23434443034097685\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 361.0764062866211, Val Loss: 359.7355829270274, Train SBP MSE: 264.8863603752942, Val SBP MSE: 263.9307780421412, Train SBP MAE: 12.598361152240209, Val SBP MAE: 12.582735188347952, Train SBP R2: 0.2770830356119266, Val SBP R2: 0.28047990534292055, Train DBP MSE: 96.19004567839936, Val DBP MSE: 95.81510245865823, Train DBP MAE: 7.750822795660155, Val DBP MAE: 7.733131093788147, Train DBP R2: 0.23687056549625862, Val DBP R2: 0.2404514773511942\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 358.1217793055943, Val Loss: 357.25274872300395, Train SBP MSE: 262.6692643027964, Val SBP MSE: 262.1811295141917, Train SBP MAE: 12.538675849928175, Val SBP MAE: 12.51144253174918, Train SBP R2: 0.28313384306088696, Val SBP R2: 0.28524974417636595, Train DBP MSE: 95.45251513728472, Val DBP MSE: 95.08184668304125, Train DBP MAE: 7.717691549379485, Val DBP MAE: 7.6927088373184205, Train DBP R2: 0.24272180780309638, Val DBP R2: 0.24626416581890098\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 355.37704232700895, Val Loss: 355.08608964853795, Train SBP MSE: 260.6389982549836, Val SBP MSE: 260.5773167882753, Train SBP MAE: 12.484413538673946, Val SBP MAE: 12.45440958807809, Train SBP R2: 0.2886747616876729, Val SBP R2: 0.2896220098625577, Train DBP MSE: 94.73804413344997, Val DBP MSE: 94.51813539737904, Train DBP MAE: 7.685954415120397, Val DBP MAE: 7.660830631828308, Train DBP R2: 0.2483901059027629, Val DBP R2: 0.2507328358222537\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 352.8278646205357, Val Loss: 352.2614662546998, Train SBP MSE: 258.7487073809765, Val SBP MSE: 258.50367686055057, Train SBP MAE: 12.433013329042707, Val SBP MAE: 12.438580582482475, Train SBP R2: 0.2938336658249474, Val SBP R2: 0.2952751042388527, Train DBP MSE: 94.07915714254912, Val DBP MSE: 93.76654221574172, Train DBP MAE: 7.655266288835662, Val DBP MAE: 7.639465443474906, Train DBP R2: 0.2536174249379268, Val DBP R2: 0.2566908891572368\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 350.5122126953125, Val Loss: 349.99634494118976, Train SBP MSE: 257.0644678182355, Val SBP MSE: 256.78621811607115, Train SBP MAE: 12.387154340253558, Val SBP MAE: 12.384515509850639, Train SBP R2: 0.2984302231949608, Val SBP R2: 0.2999571882593839, Train DBP MSE: 93.44774503074674, Val DBP MSE: 93.21953312321574, Train DBP MAE: 7.62545459017413, Val DBP MAE: 7.6152967269352505, Train DBP R2: 0.2586267703896341, Val DBP R2: 0.2610271570048116\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 348.2820139020647, Val Loss: 348.5620568047058, Train SBP MSE: 255.39301986742643, Val SBP MSE: 255.77715695685905, Train SBP MAE: 12.34260842906407, Val SBP MAE: 12.30960386995588, Train SBP R2: 0.30299187022359453, Val SBP R2: 0.3027080602348955, Train DBP MSE: 92.88899363714785, Val DBP MSE: 92.79386297120315, Train DBP MAE: 7.600039883024352, Val DBP MAE: 7.577993834277562, Train DBP R2: 0.26305965772239337, Val DBP R2: 0.2644015429502461\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 416.33052824707033, Val Loss: 368.5089661844034, Train SBP MSE: 308.2818432366765, Val SBP MSE: 269.93587485448535, Train SBP MAE: 13.611774279759231, Val SBP MAE: 12.835262288611275, Train SBP R2: 0.15864986791745617, Val SBP R2: 0.26410899226148776, Train DBP MSE: 108.04868480186384, Val DBP MSE: 98.58117743697984, Train DBP MAE: 8.171749703168386, Val DBP MAE: 7.903263605254037, Train DBP R2: 0.14278934841762292, Val DBP R2: 0.2185241599512412\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 338.4021696411133, Val Loss: 318.20029101467657, Train SBP MSE: 250.16886346485248, Val SBP MSE: 234.93626558339272, Train SBP MAE: 12.19095303666251, Val SBP MAE: 11.632948610033308, Train SBP R2: 0.31724942309527293, Val SBP R2: 0.3595238671862928, Train DBP MSE: 88.23330609480566, Val DBP MSE: 83.27115997562167, Train DBP MAE: 7.345819073271751, Val DBP MAE: 7.0541001276561195, Train DBP R2: 0.29999583106919037, Val DBP R2: 0.3398902165133527\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 308.32429323381695, Val Loss: 299.5888336362961, Train SBP MSE: 227.27223561066734, Val SBP MSE: 219.6817387155473, Train SBP MAE: 11.548283863885063, Val SBP MAE: 11.263875332859584, Train SBP R2: 0.3797379584793501, Val SBP R2: 0.40111029639065254, Train DBP MSE: 81.05205764611759, Val DBP MSE: 79.90576269195127, Train DBP MAE: 6.972620286692892, Val DBP MAE: 6.8915257689339775, Train DBP R2: 0.35696869171217926, Val DBP R2: 0.36656850072268277\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 290.67740507463725, Val Loss: 290.1919757905782, Train SBP MSE: 213.6568977378707, Val SBP MSE: 214.19003194224783, Train SBP MAE: 11.145981024374281, Val SBP MAE: 11.271087662397113, Train SBP R2: 0.41689637883053277, Val SBP R2: 0.41608162109429303, Train DBP MSE: 77.02050725251276, Val DBP MSE: 76.00236803004742, Train DBP MAE: 6.750412804545675, Val DBP MAE: 6.683075143732343, Train DBP R2: 0.38895323595838194, Val DBP R2: 0.3975116148318969\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 278.3982184866769, Val Loss: 290.8491897652746, Train SBP MSE: 204.1642891703856, Val SBP MSE: 212.72402804458133, Train SBP MAE: 10.856441031319754, Val SBP MAE: 11.25464842818124, Train SBP R2: 0.4428032158606007, Val SBP R2: 0.4200781965260838, Train DBP MSE: 74.233929325021, Val DBP MSE: 78.13014572139062, Train DBP MAE: 6.599444897971835, Val DBP MAE: 6.825405308450971, Train DBP R2: 0.4110607172784051, Val DBP R2: 0.3806442279532767\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 269.4974965829032, Val Loss: 293.9211660381645, Train SBP MSE: 197.31348170191345, Val SBP MSE: 214.11401293318247, Train SBP MAE: 10.645674946144648, Val SBP MAE: 11.073187639508928, Train SBP R2: 0.4615001579443613, Val SBP R2: 0.41628886181477365, Train DBP MSE: 72.18401492888607, Val DBP MSE: 79.80823623625515, Train DBP MAE: 6.490573709508351, Val DBP MAE: 6.90386619783129, Train DBP R2: 0.42732383476494606, Val DBP R2: 0.36734161553905653\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 262.6118047746931, Val Loss: 266.3729470512767, Train SBP MSE: 192.00579958427664, Val SBP MSE: 193.8241707797681, Train SBP MAE: 10.482920476722716, Val SBP MAE: 10.466316552843367, Train SBP R2: 0.47598566576357293, Val SBP R2: 0.4716024150695248, Train DBP MSE: 70.60600526944381, Val DBP MSE: 72.54676358442129, Train DBP MAE: 6.403075814897673, Val DBP MAE: 6.464006547546386, Train DBP R2: 0.43984306802404816, Val DBP R2: 0.42490499211985067\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 256.267531338065, Val Loss: 265.6100448733928, Train SBP MSE: 187.10946344462644, Val SBP MSE: 194.0801228197226, Train SBP MAE: 10.325076572745187, Val SBP MAE: 10.48194838747297, Train SBP R2: 0.48934854505144765, Val SBP R2: 0.4709046463690275, Train DBP MSE: 69.15806777723425, Val DBP MSE: 71.5388917838238, Train DBP MAE: 6.322635237196514, Val DBP MAE: 6.408838121032715, Train DBP R2: 0.45133036602701393, Val DBP R2: 0.4328946254607273\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 251.21901216692243, Val Loss: 263.8511552200457, Train SBP MSE: 183.30061747907732, Val SBP MSE: 192.66789056366792, Train SBP MAE: 10.201401849814824, Val SBP MAE: 10.532469957515172, Train SBP R2: 0.4997434908664581, Val SBP R2: 0.4747546311797872, Train DBP MSE: 67.9183945689941, Val DBP MSE: 71.1932675707856, Train DBP MAE: 6.258135579024042, Val DBP MAE: 6.388581635638646, Train DBP R2: 0.4611653869764447, Val DBP R2: 0.4356344686970073\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 247.21061274675642, Val Loss: 258.72736766612945, Train SBP MSE: 180.15353669344674, Val SBP MSE: 189.6293288438982, Train SBP MAE: 10.103506322969709, Val SBP MAE: 10.307362884630475, Train SBP R2: 0.5083323743597747, Val SBP R2: 0.48303826612546596, Train DBP MSE: 67.05707596993187, Val DBP MSE: 69.11040167980124, Train DBP MAE: 6.209630867433548, Val DBP MAE: 6.291536365372794, Train DBP R2: 0.46799870918555886, Val DBP R2: 0.45214582932572833\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 242.94490451921735, Val Loss: 259.0082410920473, Train SBP MSE: 176.91900668439126, Val SBP MSE: 188.98044356025565, Train SBP MAE: 10.005007826886859, Val SBP MAE: 10.347985494177681, Train SBP R2: 0.5171599206783379, Val SBP R2: 0.4848072375359679, Train DBP MSE: 66.02589787125876, Val DBP MSE: 70.03861673095976, Train DBP MAE: 6.1527655139514374, Val DBP MAE: 6.3509997512544905, Train DBP R2: 0.4761796218128803, Val DBP R2: 0.4447876534983628\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 239.39316859130858, Val Loss: 257.55029112765294, Train SBP MSE: 174.17465639942154, Val SBP MSE: 187.53062296238846, Train SBP MAE: 9.908432992621831, Val SBP MAE: 10.241083281871251, Train SBP R2: 0.5246496886468246, Val SBP R2: 0.48875969454591395, Train DBP MSE: 65.21851216477039, Val DBP MSE: 70.03167391718274, Train DBP MAE: 6.109615214071955, Val DBP MAE: 6.324947388512748, Train DBP R2: 0.4825850642188323, Val DBP R2: 0.44484269079219274\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 236.10811264038085, Val Loss: 245.05871796825903, Train SBP MSE: 171.7021042429128, Val SBP MSE: 178.71521954799897, Train SBP MAE: 9.832263783073426, Val SBP MAE: 10.031178557259695, Train SBP R2: 0.531397676337629, Val SBP R2: 0.5127919803831843, Train DBP MSE: 64.40600824838904, Val DBP MSE: 66.35924968380198, Train DBP MAE: 6.066352214983532, Val DBP MAE: 6.128989405018943, Train DBP R2: 0.48903111224664175, Val DBP R2: 0.4739548487863626\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 233.39372386038644, Val Loss: 245.2473713179175, Train SBP MSE: 169.6076336093903, Val SBP MSE: 178.7397803204181, Train SBP MAE: 9.768809101200103, Val SBP MAE: 10.01380938584464, Train SBP R2: 0.5371138194800725, Val SBP R2: 0.5127250235491729, Train DBP MSE: 63.7860901983497, Val DBP MSE: 66.51840390495971, Train DBP MAE: 6.03328389780862, Val DBP MAE: 6.1460619010652815, Train DBP R2: 0.4939492688773901, Val DBP R2: 0.47269319639074125\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 230.50347002999442, Val Loss: 247.79229245717607, Train SBP MSE: 167.4107231436034, Val SBP MSE: 180.31049794227363, Train SBP MAE: 9.697498355579377, Val SBP MAE: 10.049360750934056, Train SBP R2: 0.5431095372010939, Val SBP R2: 0.5084429807334745, Train DBP MSE: 63.09274676692451, Val DBP MSE: 67.49498280834655, Train DBP MAE: 5.994344368365833, Val DBP MAE: 6.174542719977243, Train DBP R2: 0.4994499501278118, Val DBP R2: 0.46495162909828314\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 228.08108728986468, Val Loss: 251.33880859667903, Train SBP MSE: 165.61829181727785, Val SBP MSE: 183.11757929232084, Train SBP MAE: 9.638166381795065, Val SBP MAE: 10.131814550944737, Train SBP R2: 0.5480013670841635, Val SBP R2: 0.5007904005619661, Train DBP MSE: 62.462795586627585, Val DBP MSE: 68.2408908602066, Train DBP MAE: 5.961918386118753, Val DBP MAE: 6.2303117651530675, Train DBP R2: 0.5044477051927407, Val DBP R2: 0.45903864310459175\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 226.08438203299386, Val Loss: 244.29377568748794, Train SBP MSE: 164.16938582243364, Val SBP MSE: 178.0451908479432, Train SBP MAE: 9.585564494541714, Val SBP MAE: 9.965262031555175, Train SBP R2: 0.5519556617560086, Val SBP R2: 0.5146185923352398, Train DBP MSE: 61.91499616727393, Val DBP MSE: 66.26660393850625, Train DBP MAE: 5.930605790267672, Val DBP MAE: 6.1244689529963905, Train DBP R2: 0.5087937043880266, Val DBP R2: 0.4746892730802721\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 223.52086401628767, Val Loss: 253.5065328678222, Train SBP MSE: 162.17451699070998, Val SBP MSE: 185.37252795605872, Train SBP MAE: 9.525788608516965, Val SBP MAE: 10.197354365893773, Train SBP R2: 0.5573999757559398, Val SBP R2: 0.4946430278000047, Train DBP MSE: 61.34634706300477, Val DBP MSE: 68.14713638907523, Train DBP MAE: 5.902304993656704, Val DBP MAE: 6.227697060462407, Train DBP R2: 0.5133051157956356, Val DBP R2: 0.45978185652515124\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 221.69063025163922, Val Loss: 241.5936246694115, Train SBP MSE: 160.7800726774859, Val SBP MSE: 175.42408591511355, Train SBP MAE: 9.476732543475288, Val SBP MAE: 9.901648700496128, Train SBP R2: 0.5612056358454058, Val SBP R2: 0.5217641692299307, Train DBP MSE: 60.91055767808142, Val DBP MSE: 66.18770329352348, Train DBP MAE: 5.876079683058602, Val DBP MAE: 6.131006718594687, Train DBP R2: 0.5167624767370286, Val DBP R2: 0.4753147367785294\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0007), Train Loss: 219.8171263811384, Val Loss: 238.53258055176116, Train SBP MSE: 159.36568376462387, Val SBP MSE: 173.86546071429927, Train SBP MAE: 9.438195490312577, Val SBP MAE: 9.80500757963998, Train SBP R2: 0.5650657279162157, Val SBP R2: 0.5260132460535732, Train DBP MSE: 60.451442486121955, Val DBP MSE: 64.67634799509429, Train DBP MAE: 5.8541589233909335, Val DBP MAE: 6.0114972763061525, Train DBP R2: 0.520404894352501, Val DBP R2: 0.4872956004906426\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 425.0032236589704, Val Loss: 387.18600901127735, Train SBP MSE: 314.7023053385374, Val SBP MSE: 286.3205375443241, Train SBP MAE: 13.75641116656474, Val SBP MAE: 13.24359545326233, Train SBP R2: 0.14112740671533974, Val SBP R2: 0.21944162100236642, Train DBP MSE: 110.30091840703116, Val DBP MSE: 100.87269116786291, Train DBP MAE: 8.252710311248686, Val DBP MAE: 7.9912392036710465, Train DBP R2: 0.12492111948229079, Val DBP R2: 0.20035879954083335\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 348.7519439488002, Val Loss: 324.25864661459076, Train SBP MSE: 257.8151860678886, Val SBP MSE: 238.9637451858279, Train SBP MAE: 12.386802132824489, Val SBP MAE: 11.887879618671962, Train SBP R2: 0.2963813938125003, Val SBP R2: 0.3485442742556384, Train DBP MSE: 90.93675796295382, Val DBP MSE: 85.29392714879889, Train DBP MAE: 7.4796231392485755, Val DBP MAE: 7.215294425664629, Train DBP R2: 0.2785478352729762, Val DBP R2: 0.32385527234876055\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 314.33510569893974, Val Loss: 301.61549240056513, Train SBP MSE: 231.7488276714082, Val SBP MSE: 221.59504972949307, Train SBP MAE: 11.665135334464482, Val SBP MAE: 11.32905256086077, Train SBP R2: 0.3675206274745769, Val SBP R2: 0.39589428584396713, Train DBP MSE: 82.58627818430426, Val DBP MSE: 80.01954538561465, Train DBP MAE: 7.061548337817192, Val DBP MAE: 6.914637677764893, Train DBP R2: 0.3447968620446391, Val DBP R2: 0.36566651894050684\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 295.1852936017718, Val Loss: 289.0389807246067, Train SBP MSE: 216.9914551336114, Val SBP MSE: 212.02319261838386, Train SBP MAE: 11.2368793672766, Val SBP MAE: 11.025745206069946, Train SBP R2: 0.40779584188068285, Val SBP R2: 0.42198879284204716, Train DBP MSE: 78.19383843817059, Val DBP MSE: 77.01824601076011, Train DBP MAE: 6.82055972093514, Val DBP MAE: 6.73015306628091, Train DBP R2: 0.37964454338128983, Val DBP R2: 0.38945851464578884\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 282.20045949358257, Val Loss: 290.99531660480955, Train SBP MSE: 207.04391794285792, Val SBP MSE: 214.54509095695119, Train SBP MAE: 10.937837774630955, Val SBP MAE: 11.043224901199341, Train SBP R2: 0.43494425140576476, Val SBP R2: 0.4151136699604264, Train DBP MSE: 75.15654172062852, Val DBP MSE: 76.4578742880772, Train DBP MAE: 6.656845165116446, Val DBP MAE: 6.691180517714364, Train DBP R2: 0.40374111709773675, Val DBP R2: 0.39390071115945036\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 272.7325484514509, Val Loss: 284.2057463455898, Train SBP MSE: 199.78866420647597, Val SBP MSE: 209.97411463974018, Train SBP MAE: 10.715898491709574, Val SBP MAE: 11.11758395009722, Train SBP R2: 0.45474499161579063, Val SBP R2: 0.42757492717655066, Train DBP MSE: 72.94388449732656, Val DBP MSE: 74.24164173951344, Train DBP MAE: 6.533145153685979, Val DBP MAE: 6.62058372530256, Train DBP R2: 0.42129536445940763, Val DBP R2: 0.4114693001909563\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 264.57647773960656, Val Loss: 270.4657585381154, Train SBP MSE: 193.41336938495243, Val SBP MSE: 198.82230792917454, Train SBP MAE: 10.516329438836234, Val SBP MAE: 10.546952777862549, Train SBP R2: 0.47214418413338555, Val SBP R2: 0.45797664492809864, Train DBP MSE: 71.16310829119516, Val DBP MSE: 71.65193047679617, Train DBP MAE: 6.435831967656953, Val DBP MAE: 6.46173224975041, Train DBP R2: 0.43542325814714244, Val DBP R2: 0.4319985415444537\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 258.0928183201381, Val Loss: 274.7060455273449, Train SBP MSE: 188.5300925026602, Val SBP MSE: 202.13063058502246, Train SBP MAE: 10.35788849043846, Val SBP MAE: 10.81723194961548, Train SBP R2: 0.48547142263298804, Val SBP R2: 0.44895759588747575, Train DBP MSE: 69.56272584502007, Val DBP MSE: 72.57949423272173, Train DBP MAE: 6.345910972731454, Val DBP MAE: 6.51514348091398, Train DBP R2: 0.44811998723720414, Val DBP R2: 0.42464552868533967\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 252.84526837158202, Val Loss: 265.03942797170913, Train SBP MSE: 184.47429845720458, Val SBP MSE: 194.38874171339643, Train SBP MAE: 10.227883606433869, Val SBP MAE: 10.47383529559544, Train SBP R2: 0.4965403289948327, Val SBP R2: 0.470063298886796, Train DBP MSE: 68.37096972018362, Val DBP MSE: 70.66449741409244, Train DBP MAE: 6.281581583104815, Val DBP MAE: 6.367446936825344, Train DBP R2: 0.4575748551624521, Val DBP R2: 0.43982615227330313\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 248.06624857003348, Val Loss: 253.62050550206268, Train SBP MSE: 180.76777988475396, Val SBP MSE: 184.5850461842998, Train SBP MAE: 10.11640520331519, Val SBP MAE: 10.184772556522914, Train SBP R2: 0.5066560070956143, Val SBP R2: 0.4967898367593835, Train DBP MSE: 67.29846876808465, Val DBP MSE: 69.05082650285075, Train DBP MAE: 6.223510290486472, Val DBP MAE: 6.262150088500976, Train DBP R2: 0.46608360509918056, Val DBP R2: 0.4526180955601541\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 243.6705374093192, Val Loss: 254.19772684072882, Train SBP MSE: 177.5498448008903, Val SBP MSE: 185.24791701025296, Train SBP MAE: 10.00915677634648, Val SBP MAE: 10.246968156324114, Train SBP R2: 0.5154382632266155, Val SBP R2: 0.4949827383869494, Train DBP MSE: 66.12069265222817, Val DBP MSE: 68.96248981193139, Train DBP MAE: 6.159275670497758, Val DBP MAE: 6.301414217703683, Train DBP R2: 0.4754275617937286, Val DBP R2: 0.453318360981385\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 239.46120102103097, Val Loss: 247.62288485846094, Train SBP MSE: 174.28436108816993, Val SBP MSE: 180.29932938633328, Train SBP MAE: 9.905604793037687, Val SBP MAE: 10.054734784861973, Train SBP R2: 0.5243502871206125, Val SBP R2: 0.5084734281124692, Train DBP MSE: 65.17683982063141, Val DBP MSE: 67.32748450129199, Train DBP MAE: 6.108552005062784, Val DBP MAE: 6.182793617112296, Train DBP R2: 0.48291567423354775, Val DBP R2: 0.46627942699657754\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 236.13626454816546, Val Loss: 248.19801211662224, Train SBP MSE: 171.76585499697765, Val SBP MSE: 181.19945160157417, Train SBP MAE: 9.826178673185622, Val SBP MAE: 10.118146863228935, Train SBP R2: 0.531223690400638, Val SBP R2: 0.5060195421870859, Train DBP MSE: 64.3704095235522, Val DBP MSE: 67.00926296461681, Train DBP MAE: 6.063437811435972, Val DBP MAE: 6.181509461375645, Train DBP R2: 0.4893135368422661, Val DBP R2: 0.46880204286666916\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 232.89033186645509, Val Loss: 254.02596650481007, Train SBP MSE: 169.34848147378193, Val SBP MSE: 184.96229220190182, Train SBP MAE: 9.748757586097717, Val SBP MAE: 10.121883288655962, Train SBP R2: 0.5378210868339794, Val SBP R2: 0.49576140009008884, Train DBP MSE: 63.54185038164704, Val DBP MSE: 69.0677701470602, Train DBP MAE: 6.022240483181817, Val DBP MAE: 6.243544681712559, Train DBP R2: 0.49588695995435217, Val DBP R2: 0.4524837793657617\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 229.6978550746373, Val Loss: 238.7980674625097, Train SBP MSE: 166.861705980214, Val SBP MSE: 173.27203249433268, Train SBP MAE: 9.667356130559105, Val SBP MAE: 9.77550660356794, Train SBP R2: 0.5446078922715176, Val SBP R2: 0.5276310320964515, Train DBP MSE: 62.836149269971514, Val DBP MSE: 65.53222491079661, Train DBP MAE: 5.978975064696584, Val DBP MAE: 6.0869167675563265, Train DBP R2: 0.5014856815942412, Val DBP R2: 0.4805108658276346\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 226.61951639317104, Val Loss: 246.54917578200318, Train SBP MSE: 164.58219402075144, Val SBP MSE: 179.5408501420434, Train SBP MAE: 9.594379722513471, Val SBP MAE: 10.00522159816197, Train SBP R2: 0.5508290425930602, Val SBP R2: 0.5105411712597263, Train DBP MSE: 62.037322014895814, Val DBP MSE: 67.01699563358687, Train DBP MAE: 5.938547998571396, Val DBP MAE: 6.1438047972542895, Train DBP R2: 0.5078232250181238, Val DBP R2: 0.46874074420767253\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 224.18763880353654, Val Loss: 240.95932949700781, Train SBP MSE: 162.79826700117837, Val SBP MSE: 175.7124095097225, Train SBP MAE: 9.539394799770628, Val SBP MAE: 9.938352734157018, Train SBP R2: 0.5556976628717808, Val SBP R2: 0.5209781501774208, Train DBP MSE: 61.38937183621383, Val DBP MSE: 65.25705034607658, Train DBP MAE: 5.903638713213375, Val DBP MAE: 6.068634050723484, Train DBP R2: 0.5129637762046508, Val DBP R2: 0.48269223837476316\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 221.5558329938616, Val Loss: 248.12117962601852, Train SBP MSE: 160.7987671077377, Val SBP MSE: 180.85292898871583, Train SBP MAE: 9.477690240553446, Val SBP MAE: 10.02797320147923, Train SBP R2: 0.5611546157749521, Val SBP R2: 0.5069642216407448, Train DBP MSE: 60.75706597465503, Val DBP MSE: 67.2811982478001, Train DBP MAE: 5.867780946731568, Val DBP MAE: 6.180419009535653, Train DBP R2: 0.5179802122730781, Val DBP R2: 0.46664634885499623\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 219.08545147007533, Val Loss: 238.3175757441268, Train SBP MSE: 158.97750845390618, Val SBP MSE: 173.50791834798616, Train SBP MAE: 9.419570409257071, Val SBP MAE: 9.805755231094361, Train SBP R2: 0.5661251200150647, Val SBP R2: 0.5269879672253968, Train DBP MSE: 60.10794309304354, Val DBP MSE: 64.8297489123608, Train DBP MAE: 5.834530642063277, Val DBP MAE: 6.028748866885049, Train DBP R2: 0.5231300671678747, Val DBP R2: 0.48607955586831364\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 216.8559163870675, Val Loss: 240.23760776066476, Train SBP MSE: 157.28301409309134, Val SBP MSE: 174.46225867064055, Train SBP MAE: 9.361137403120313, Val SBP MAE: 9.883034099851336, Train SBP R2: 0.5707496643583725, Val SBP R2: 0.524386273537434, Train DBP MSE: 59.57290242448729, Val DBP MSE: 65.7841172151555, Train DBP MAE: 5.804080791660717, Val DBP MAE: 6.127878524575915, Train DBP R2: 0.5273748440567113, Val DBP R2: 0.47851405715412776\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 705.6325147495814, Val Loss: 438.13794503918075, Train SBP MSE: 532.5787277730739, Val SBP MSE: 324.11056653024957, Train SBP MAE: 16.262085741504414, Val SBP MAE: 14.02565805467878, Train SBP R2: -0.45349196777775025, Val SBP R2: 0.11641958835142108, Train DBP MSE: 173.05378748826348, Val DBP MSE: 114.04516978403309, Train DBP MAE: 9.548894615908942, Val DBP MAE: 8.446938822378431, Train DBP R2: -0.3729324906049545, Val DBP R2: 0.09593750878604845\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 422.9712143833705, Val Loss: 412.14960528553297, Train SBP MSE: 312.52714720802527, Val SBP MSE: 304.0116495161449, Train SBP MAE: 13.813334340320315, Val SBP MAE: 13.712396224975587, Train SBP R2: 0.14706375885723966, Val SBP R2: 0.17121264727304608, Train DBP MSE: 110.44406714383346, Val DBP MSE: 108.1486382380794, Train DBP MAE: 8.329192189758164, Val DBP MAE: 8.277481196757725, Train DBP R2: 0.1237854404856189, Val DBP R2: 0.14268068089102692\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 400.74113147670204, Val Loss: 405.9589451749756, Train SBP MSE: 295.39580171053194, Val SBP MSE: 300.0707518800348, Train SBP MAE: 13.39880143664905, Val SBP MAE: 13.305392555672782, Train SBP R2: 0.19381792266312425, Val SBP R2: 0.18195620306900961, Train DBP MSE: 105.34532935042414, Val DBP MSE: 105.90392956252583, Train DBP MAE: 8.138801119930404, Val DBP MAE: 8.116761447116307, Train DBP R2: 0.1642365792861601, Val DBP R2: 0.16047500678061533\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 387.3315085292271, Val Loss: 382.3400735314629, Train SBP MSE: 285.1562505023271, Val SBP MSE: 281.4963045877683, Train SBP MAE: 13.14784344903401, Val SBP MAE: 12.947648405947003, Train SBP R2: 0.221763284838979, Val SBP R2: 0.232593298799469, Train DBP MSE: 102.17525811615444, Val DBP MSE: 100.84973230760542, Train DBP MAE: 8.01343837165492, Val DBP MAE: 7.935073992347717, Train DBP R2: 0.18938652750879725, Val DBP R2: 0.20054079974688443\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 379.3962456176758, Val Loss: 383.02305732740996, Train SBP MSE: 279.2172223608005, Val SBP MSE: 282.5955127342802, Train SBP MAE: 13.000567220538002, Val SBP MAE: 12.892811320604597, Train SBP R2: 0.23797183626988272, Val SBP R2: 0.22959667083704238, Train DBP MSE: 100.17902317124721, Val DBP MSE: 100.43588665854855, Train DBP MAE: 7.9325755447557995, Val DBP MAE: 7.899053328677586, Train DBP R2: 0.2052237758841322, Val DBP R2: 0.20382145011702213\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 373.48423680071147, Val Loss: 369.00320293001107, Train SBP MSE: 274.82081640993846, Val SBP MSE: 271.6198541149882, Train SBP MAE: 12.8901010946955, Val SBP MAE: 12.80442470250811, Train SBP R2: 0.24997032664028873, Val SBP R2: 0.25951817899633656, Train DBP MSE: 98.6634202806803, Val DBP MSE: 97.38603155381935, Train DBP MAE: 7.8721649726901735, Val DBP MAE: 7.821911976351057, Train DBP R2: 0.21724790133966576, Val DBP R2: 0.2279983583459675\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 368.88421764962334, Val Loss: 381.3222434830186, Train SBP MSE: 271.3937042958734, Val SBP MSE: 280.6804579586253, Train SBP MAE: 12.803589829308645, Val SBP MAE: 13.263918484933036, Train SBP R2: 0.259323460122161, Val SBP R2: 0.23481743517409404, Train DBP MSE: 97.49051313657945, Val DBP MSE: 100.63930876118268, Train DBP MAE: 7.821608166132655, Val DBP MAE: 7.996902472741263, Train DBP R2: 0.22655322975790648, Val DBP R2: 0.20220887596571302\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 365.01109301583426, Val Loss: 365.3851147221037, Train SBP MSE: 268.50819665249793, Val SBP MSE: 268.76340947249327, Train SBP MAE: 12.733273717389787, Val SBP MAE: 12.831591035842896, Train SBP R2: 0.26719846894976595, Val SBP R2: 0.26730533188088, Train DBP MSE: 96.5028966268067, Val DBP MSE: 96.6175473870322, Train DBP MAE: 7.7784701320001055, Val DBP MAE: 7.796503055245536, Train DBP R2: 0.23438854393510644, Val DBP R2: 0.23409031043477346\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 361.39633665597097, Val Loss: 362.70627168589147, Train SBP MSE: 265.7812199033039, Val SBP MSE: 266.8608962712639, Train SBP MAE: 12.661134690434592, Val SBP MAE: 12.822739036342076, Train SBP R2: 0.27464082177869653, Val SBP R2: 0.2724919057575209, Train DBP MSE: 95.61511670440147, Val DBP MSE: 95.8424856639162, Train DBP MAE: 7.738692652024541, Val DBP MAE: 7.7708820665359495, Train DBP R2: 0.24143179862295583, Val DBP R2: 0.24023440433696808\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 358.19379538748603, Val Loss: 355.74817151866404, Train SBP MSE: 263.36510709258783, Val SBP MSE: 261.4092528068962, Train SBP MAE: 12.601020780127389, Val SBP MAE: 12.532260116849626, Train SBP R2: 0.2812347775273706, Val SBP R2: 0.28735401108156244, Train DBP MSE: 94.82868830804738, Val DBP MSE: 94.34032331305124, Train DBP MAE: 7.703702900052071, Val DBP MAE: 7.6654319037573675, Train DBP R2: 0.24767097496552581, Val DBP R2: 0.2521423934232442\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 355.12290868617464, Val Loss: 354.1512135744531, Train SBP MSE: 261.04730476317735, Val SBP MSE: 260.3104832856816, Train SBP MAE: 12.538802034555163, Val SBP MAE: 12.531901493344987, Train SBP R2: 0.287560428352332, Val SBP R2: 0.2903494432769861, Train DBP MSE: 94.075603937747, Val DBP MSE: 93.84261164516732, Train DBP MAE: 7.66753887283802, Val DBP MAE: 7.636261231558663, Train DBP R2: 0.2536456144990421, Val DBP R2: 0.25608786916084436\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 352.20350766427174, Val Loss: 359.21535052590656, Train SBP MSE: 258.82613438908083, Val SBP MSE: 264.1125731225207, Train SBP MAE: 12.47913093884332, Val SBP MAE: 12.434067649841309, Train SBP R2: 0.2936223552177074, Val SBP R2: 0.2799843010999703, Train DBP MSE: 93.37737348299257, Val DBP MSE: 95.10887415023737, Train DBP MAE: 7.635555992559024, Val DBP MAE: 7.65865281829834, Train DBP R2: 0.2591850672390019, Val DBP R2: 0.24604991282273447\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 349.5193406651088, Val Loss: 350.793155718983, Train SBP MSE: 256.77426785769364, Val SBP MSE: 257.77484432590853, Train SBP MAE: 12.425363802228656, Val SBP MAE: 12.432620166233608, Train SBP R2: 0.2992222249961979, Val SBP R2: 0.2972620254240397, Train DBP MSE: 92.74507289220894, Val DBP MSE: 93.01242973074226, Train DBP MAE: 7.605222422092302, Val DBP MAE: 7.584027155821664, Train DBP R2: 0.2642014614914212, Val DBP R2: 0.26266891359382816\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 346.838877671596, Val Loss: 345.41838082099093, Train SBP MSE: 254.72924290073934, Val SBP MSE: 253.6589114185825, Train SBP MAE: 12.367679836177826, Val SBP MAE: 12.322475020599365, Train SBP R2: 0.3048034230310257, Val SBP R2: 0.30848275707591455, Train DBP MSE: 92.10963463308366, Val DBP MSE: 91.75772509362264, Train DBP MAE: 7.575249589828083, Val DBP MAE: 7.553458243942261, Train DBP R2: 0.2692427486217923, Val DBP R2: 0.27261524803412174\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 344.24605754220147, Val Loss: 342.68615099193846, Train SBP MSE: 252.74116247903763, Val SBP MSE: 251.49260082915714, Train SBP MAE: 12.314727562209539, Val SBP MAE: 12.277313620485579, Train SBP R2: 0.31022921038141926, Val SBP R2: 0.3143884874038535, Train DBP MSE: 91.50489534720005, Val DBP MSE: 91.1916325257429, Train DBP MAE: 7.545368151184491, Val DBP MAE: 7.515017396763393, Train DBP R2: 0.2740404836265299, Val DBP R2: 0.2771027950134827\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 341.70671890345983, Val Loss: 341.2627914052123, Train SBP MSE: 250.80882566863633, Val SBP MSE: 250.42600831237573, Train SBP MAE: 12.256562750353131, Val SBP MAE: 12.26573273778643, Train SBP R2: 0.3155028645596536, Val SBP R2: 0.3172961996241863, Train DBP MSE: 90.89789335205474, Val DBP MSE: 90.84028439921076, Train DBP MAE: 7.51442830047948, Val DBP MAE: 7.507523720496041, Train DBP R2: 0.2788561699694454, Val DBP R2: 0.2798880130385646\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 339.2577072091239, Val Loss: 345.19059715759164, Train SBP MSE: 248.93890816398513, Val SBP MSE: 253.76974788295834, Train SBP MAE: 12.207522720411845, Val SBP MAE: 12.132873308127268, Train SBP R2: 0.32060616653489804, Val SBP R2: 0.3081805980631206, Train DBP MSE: 90.31879889267475, Val DBP MSE: 91.4293743115778, Train DBP MAE: 7.485542193307196, Val DBP MAE: 7.4838533088956565, Train DBP R2: 0.28345045022156645, Val DBP R2: 0.2752181607797438\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 336.77764532819475, Val Loss: 335.35000433215714, Train SBP MSE: 247.02912439378414, Val SBP MSE: 245.99569600706744, Train SBP MAE: 12.155489141368866, Val SBP MAE: 12.166202213505336, Train SBP R2: 0.32581826988304863, Val SBP R2: 0.32937398287069675, Train DBP MSE: 89.74852087304836, Val DBP MSE: 89.357183831836, Train DBP MAE: 7.456432520202228, Val DBP MAE: 7.447428706169128, Train DBP R2: 0.2879747847258085, Val DBP R2: 0.2916448949494842\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 334.52907824532645, Val Loss: 340.501234169634, Train SBP MSE: 245.32810528411082, Val SBP MSE: 250.4057272756116, Train SBP MAE: 12.10557380145618, Val SBP MAE: 12.082185358428955, Train SBP R2: 0.33046062130268694, Val SBP R2: 0.31735148917245537, Train DBP MSE: 89.20097298152552, Val DBP MSE: 90.10444235544907, Train DBP MAE: 7.429936974944387, Val DBP MAE: 7.421247946984427, Train DBP R2: 0.29231878841012515, Val DBP R2: 0.2857212034532304\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 332.3109623151507, Val Loss: 334.02611223042993, Train SBP MSE: 243.65895968488812, Val SBP MSE: 245.05815732490734, Train SBP MAE: 12.055576969460079, Val SBP MAE: 11.994568594414847, Train SBP R2: 0.3350159848480284, Val SBP R2: 0.33192987243513705, Train DBP MSE: 88.65200232824675, Val DBP MSE: 88.97589074713514, Train DBP MAE: 7.400437365235601, Val DBP MAE: 7.392511788259234, Train DBP R2: 0.29667407965924675, Val DBP R2: 0.2946674935978101\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hyp2)):\n",
    "    print(hyp2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rohansanda/Desktop/cs229_proj/hyper_parameter_tuning.pickle', 'rb') as file:\n",
    "    hyp3 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/rohansanda/Desktop/cs229_proj/hyper_parameter_tuning.pickle', 'rb') as file:\n",
    "    hyp4 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 535.9274108694894, Val Loss: 411.78085683512296, Train SBP MSE: 409.0774510965324, Val SBP MSE: 303.8016894282165, Train SBP MAE: 14.878876594811466, Val SBP MAE: 13.769761938149589, Train SBP R2: -0.11722540490131816, Val SBP R2: 0.17097314414125908, Train DBP MSE: 126.8499600411145, Val DBP MSE: 107.98066399446063, Train DBP MAE: 8.616570554615278, Val DBP MAE: 8.254084366525923, Train DBP R2: -0.007181756657542282, Val DBP R2: 0.14681235738890042\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 378.7410867797852, Val Loss: 373.8773697429427, Train SBP MSE: 278.7893788922832, Val SBP MSE: 275.22595601837634, Train SBP MAE: 12.94258607145037, Val SBP MAE: 12.697425138419016, Train SBP R2: 0.2386024312016688, Val SBP R2: 0.24895180998477118, Train DBP MSE: 99.95170766665647, Val DBP MSE: 98.67193826167694, Train DBP MAE: 7.859577907647405, Val DBP MAE: 7.737271902547564, Train DBP R2: 0.20638889853812115, Val DBP R2: 0.22036339393442883\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 363.0440548863002, Val Loss: 357.03891521921105, Train SBP MSE: 266.8188861929604, Val SBP MSE: 262.22100818261345, Train SBP MAE: 12.626213096768515, Val SBP MAE: 12.481780578286306, Train SBP R2: 0.27129486760221055, Val SBP R2: 0.28444025981920484, Train DBP MSE: 96.22516864546961, Val DBP MSE: 94.8353439442471, Train DBP MAE: 7.690453131556511, Val DBP MAE: 7.6402334156853815, Train DBP R2: 0.23597741489551916, Val DBP R2: 0.2506774774032158\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 353.27847052699497, Val Loss: 350.1235519562604, Train SBP MSE: 259.15872242071896, Val SBP MSE: 256.53622459033437, Train SBP MAE: 12.411268495368958, Val SBP MAE: 12.366989741080149, Train SBP R2: 0.29221542811981616, Val SBP R2: 0.29995313690890935, Train DBP MSE: 94.11974791493316, Val DBP MSE: 93.60174535278456, Train DBP MAE: 7.58687648679529, Val DBP MAE: 7.5403586152212965, Train DBP R2: 0.25269434053899287, Val DBP R2: 0.26042451020746193\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 344.76168245849607, Val Loss: 345.15557219036316, Train SBP MSE: 252.70299584168936, Val SBP MSE: 253.29212753530246, Train SBP MAE: 12.229535944720677, Val SBP MAE: 12.282708905029297, Train SBP R2: 0.309846567948852, Val SBP R2: 0.30880576569677254, Train DBP MSE: 92.05868672338079, Val DBP MSE: 91.87517012805144, Train DBP MAE: 7.488889871600696, Val DBP MAE: 7.4889929622377664, Train DBP R2: 0.26905905386498497, Val DBP R2: 0.2740666993854832\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 339.312146585519, Val Loss: 342.1866657110629, Train SBP MSE: 248.42779965477953, Val SBP MSE: 250.26230425070045, Train SBP MAE: 12.104072234330859, Val SBP MAE: 12.100980656596592, Train SBP R2: 0.3215224933222742, Val SBP R2: 0.3170736751878904, Train DBP MSE: 90.88434696431517, Val DBP MSE: 91.93623542342624, Train DBP MAE: 7.436571383043698, Val DBP MAE: 7.448267816434588, Train DBP R2: 0.2783832474324496, Val DBP R2: 0.2735842041545884\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 334.3897389578683, Val Loss: 340.0729527586775, Train SBP MSE: 244.75504889825498, Val SBP MSE: 249.8343566496228, Train SBP MAE: 11.995600004918234, Val SBP MAE: 12.144523188672746, Train SBP R2: 0.3315530888490157, Val SBP R2: 0.318241476640415, Train DBP MSE: 89.63469020744509, Val DBP MSE: 90.2607239942902, Train DBP MAE: 7.369485024850709, Val DBP MAE: 7.417688573237828, Train DBP R2: 0.2883054538501374, Val DBP R2: 0.28682292295396405\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 330.32618473074774, Val Loss: 332.56627791716807, Train SBP MSE: 241.76923930100415, Val SBP MSE: 243.8131416208522, Train SBP MAE: 11.919245833410535, Val SBP MAE: 11.939471642793928, Train SBP R2: 0.33970758948772173, Val SBP R2: 0.3346724220151627, Train DBP MSE: 88.556945435919, Val DBP MSE: 88.76305083137821, Train DBP MAE: 7.321148279615811, Val DBP MAE: 7.335220029939924, Train DBP R2: 0.2968626884906709, Val DBP R2: 0.29865648822387514\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 326.5087432355608, Val Loss: 331.64315494628016, Train SBP MSE: 238.7684468935997, Val SBP MSE: 243.00838803323583, Train SBP MAE: 11.82574297889982, Val SBP MAE: 11.919813747406005, Train SBP R2: 0.3479030094586849, Val SBP R2: 0.3368684675267539, Train DBP MSE: 87.74029625131874, Val DBP MSE: 88.64092598768282, Train DBP MAE: 7.276047641478266, Val DBP MAE: 7.321762182262965, Train DBP R2: 0.30334683842695864, Val DBP R2: 0.29962143327646407\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 322.1293044799805, Val Loss: 321.67265620397256, Train SBP MSE: 235.38927425821493, Val SBP MSE: 234.637021161322, Train SBP MAE: 11.725166961969649, Val SBP MAE: 11.726427100590298, Train SBP R2: 0.35713181810037253, Val SBP R2: 0.3597126063138838, Train DBP MSE: 86.74003032074123, Val DBP MSE: 87.05417603765247, Train DBP MAE: 7.227588746380806, Val DBP MAE: 7.2544334042685374, Train DBP R2: 0.31128889530074244, Val DBP R2: 0.31215882098274006\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 319.0236910016741, Val Loss: 322.50020602852163, Train SBP MSE: 233.07997072328544, Val SBP MSE: 235.57561549406262, Train SBP MAE: 11.663716190801347, Val SBP MAE: 11.697008506611414, Train SBP R2: 0.3634387229907201, Val SBP R2: 0.3571513305353874, Train DBP MSE: 85.94372031908584, Val DBP MSE: 86.94476621025407, Train DBP MAE: 7.184347129668509, Val DBP MAE: 7.211052641568865, Train DBP R2: 0.3176115532349768, Val DBP R2: 0.3130233008744485\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 316.7454838256836, Val Loss: 319.7445757654947, Train SBP MSE: 231.29568448362016, Val SBP MSE: 233.51106290123374, Train SBP MAE: 11.60940598105022, Val SBP MAE: 11.63066128365653, Train SBP R2: 0.36831176087444184, Val SBP R2: 0.36278516867502797, Train DBP MSE: 85.44979921660885, Val DBP MSE: 86.23193078280045, Train DBP MAE: 7.1621491966894695, Val DBP MAE: 7.147751317269462, Train DBP R2: 0.3215332598203139, Val DBP R2: 0.3186556275838863\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 314.13240293666297, Val Loss: 324.0171821845297, Train SBP MSE: 229.24391781633608, Val SBP MSE: 237.94323705286237, Train SBP MAE: 11.55544777914456, Val SBP MAE: 11.835419353866577, Train SBP R2: 0.373915310616612, Val SBP R2: 0.350690465026544, Train DBP MSE: 84.88848473713473, Val DBP MSE: 86.07935072885745, Train DBP MAE: 7.133265781692097, Val DBP MAE: 7.190974290902274, Train DBP R2: 0.32599006613929726, Val DBP R2: 0.3198612083954636\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 310.89355475376675, Val Loss: 328.0364975310331, Train SBP MSE: 226.69001505350045, Val SBP MSE: 239.56230411067364, Train SBP MAE: 11.478465113176618, Val SBP MAE: 11.915160328074863, Train SBP R2: 0.38089023685769263, Val SBP R2: 0.3462722865928165, Train DBP MSE: 84.20353961627677, Val DBP MSE: 88.47129650845623, Train DBP MAE: 7.0998392928395955, Val DBP MAE: 7.325385916273935, Train DBP R2: 0.3314284930005762, Val DBP R2: 0.30096172671553856\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 308.9285323451451, Val Loss: 316.9973386175236, Train SBP MSE: 225.20499936738602, Val SBP MSE: 231.32159797501114, Train SBP MAE: 11.437720519379207, Val SBP MAE: 11.558933510480609, Train SBP R2: 0.38494594133799775, Val SBP R2: 0.3687598728552962, Train DBP MSE: 83.72353304626205, Val DBP MSE: 85.685262644807, Train DBP MAE: 7.075917756015913, Val DBP MAE: 7.153693607466561, Train DBP R2: 0.33523971895790305, Val DBP R2: 0.32297501665496253\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 307.3824413260324, Val Loss: 310.62343923788404, Train SBP MSE: 224.08466572002965, Val SBP MSE: 226.72421569117196, Train SBP MAE: 11.409475417246137, Val SBP MAE: 11.474062313679287, Train SBP R2: 0.3880056680705205, Val SBP R2: 0.3813054034187543, Train DBP MSE: 83.29777555744342, Val DBP MSE: 83.9083102895184, Train DBP MAE: 7.055763847184181, Val DBP MAE: 7.055750332614354, Train DBP R2: 0.33862021017255906, Val DBP R2: 0.33701525066499505\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 305.7406817086356, Val Loss: 321.9995408973485, Train SBP MSE: 222.90919468047963, Val SBP MSE: 235.77308844470122, Train SBP MAE: 11.374953944751194, Val SBP MAE: 11.732383903176444, Train SBP R2: 0.3912159797232184, Val SBP R2: 0.3566124580238712, Train DBP MSE: 82.8314870432728, Val DBP MSE: 86.2269303432492, Train DBP MAE: 7.03302146515165, Val DBP MAE: 7.1991563429968695, Train DBP R2: 0.3423225155154964, Val DBP R2: 0.3186951375579402\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 303.5016605242048, Val Loss: 306.4186419638681, Train SBP MSE: 221.04659400197366, Val SBP MSE: 223.98763800236785, Train SBP MAE: 11.315371964876991, Val SBP MAE: 11.343402293450492, Train SBP R2: 0.3963029010180372, Val SBP R2: 0.3887730919672687, Train DBP MSE: 82.45506661214031, Val DBP MSE: 82.43682967233745, Train DBP MAE: 7.012027891598429, Val DBP MAE: 6.97957225894928, Train DBP R2: 0.3453112731859518, Val DBP R2: 0.34864186076793846\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 301.3806846296038, Val Loss: 307.20699022980017, Train SBP MSE: 219.39710331333595, Val SBP MSE: 224.49431645599356, Train SBP MAE: 11.271800185598646, Val SBP MAE: 11.448765998840331, Train SBP R2: 0.40080780075659417, Val SBP R2: 0.38739044644567455, Train DBP MSE: 81.98358148786171, Val DBP MSE: 82.72456373248454, Train DBP MAE: 6.984246050695011, Val DBP MAE: 7.006453148378645, Train DBP R2: 0.34905483932940873, Val DBP R2: 0.3463683875793646\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.001), Train Loss: 299.9698852556501, Val Loss: 303.3676100247957, Train SBP MSE: 218.43964273908335, Val SBP MSE: 220.72957190791365, Train SBP MAE: 11.241503348970413, Val SBP MAE: 11.275761495317731, Train SBP R2: 0.40342270723672147, Val SBP R2: 0.3976638400587258, Train DBP MSE: 81.53024223122686, Val DBP MSE: 82.64364185354407, Train DBP MAE: 6.9683230378185, Val DBP MAE: 6.979492988041469, Train DBP R2: 0.352654328274548, Val DBP R2: 0.34700777563806773\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 642.5863963814871, Val Loss: 398.34672143995436, Train SBP MSE: 500.7359195576432, Val SBP MSE: 295.97962816918727, Train SBP MAE: 15.815185380740225, Val SBP MAE: 13.617917654309954, Train SBP R2: -0.36755249886508334, Val SBP R2: 0.19231831461780335, Train DBP MSE: 141.85047789102506, Val DBP MSE: 102.38012414896895, Train DBP MAE: 8.873362346554657, Val DBP MAE: 8.033388532175337, Train DBP R2: -0.12628504935033402, Val DBP R2: 0.19106390402107998\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 366.3954543247768, Val Loss: 357.18235082120736, Train SBP MSE: 269.1590440092527, Val SBP MSE: 261.218603185696, Train SBP MAE: 12.678235986300876, Val SBP MAE: 12.388319681876046, Train SBP R2: 0.2649036970382209, Val SBP R2: 0.28717566482783274, Train DBP MSE: 97.23641034623277, Val DBP MSE: 95.98817324974405, Train DBP MAE: 7.742761852526665, Val DBP MAE: 7.639869926207406, Train DBP R2: 0.2279482110057438, Val DBP R2: 0.24156862697476866\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 346.257814768764, Val Loss: 340.5011812171727, Train SBP MSE: 253.33335276811394, Val SBP MSE: 248.89741370301104, Train SBP MAE: 12.243699956757682, Val SBP MAE: 12.086143289293561, Train SBP R2: 0.30812500942620746, Val SBP R2: 0.3207982460468344, Train DBP MSE: 92.92446222902977, Val DBP MSE: 91.61984460602197, Train DBP MAE: 7.544969828595434, Val DBP MAE: 7.473419028745378, Train DBP R2: 0.26218484362189176, Val DBP R2: 0.27608410298516795\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 335.25658233816966, Val Loss: 332.4609888554491, Train SBP MSE: 245.02751460112162, Val SBP MSE: 242.62479483074327, Train SBP MAE: 12.011510472406659, Val SBP MAE: 11.928391677365985, Train SBP R2: 0.3308089617787242, Val SBP R2: 0.3379152328268077, Train DBP MSE: 90.22906779665652, Val DBP MSE: 89.85512566791395, Train DBP MAE: 7.414069319796562, Val DBP MAE: 7.342216162027632, Train DBP R2: 0.2835861282451012, Val DBP R2: 0.2900276770935174\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 326.2556248308454, Val Loss: 334.66355921799345, Train SBP MSE: 238.1152480398125, Val SBP MSE: 245.02337060705344, Train SBP MAE: 11.807732381044115, Val SBP MAE: 11.834852689634051, Train SBP R2: 0.34968695123290705, Val SBP R2: 0.33136989814445006, Train DBP MSE: 88.14037680026199, Val DBP MSE: 89.65928974200229, Train DBP MAE: 7.30709599138328, Val DBP MAE: 7.322233148002624, Train DBP R2: 0.30017022071293964, Val DBP R2: 0.2915750355351704\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 319.8097647984096, Val Loss: 320.8764288447239, Train SBP MSE: 233.33851460847427, Val SBP MSE: 234.38849453898936, Train SBP MAE: 11.662412306363242, Val SBP MAE: 11.72881155646188, Train SBP R2: 0.3627326175917531, Val SBP R2: 0.360390796236716, Train DBP MSE: 86.47125031301377, Val DBP MSE: 86.49982821163178, Train DBP MAE: 7.224090722298622, Val DBP MAE: 7.24554015851702, Train DBP R2: 0.31342299388658057, Val DBP R2: 0.31653888957440424\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 313.4793844831194, Val Loss: 317.41757937889867, Train SBP MSE: 228.4640706245156, Val SBP MSE: 231.49801618666407, Train SBP MAE: 11.523960878453936, Val SBP MAE: 11.62815870552063, Train SBP R2: 0.3760451398025212, Val SBP R2: 0.3682784554030164, Train DBP MSE: 85.01531394241128, Val DBP MSE: 85.92604471162288, Train DBP MAE: 7.149850948098727, Val DBP MAE: 7.192412465940203, Train DBP R2: 0.3249830491743375, Val DBP R2: 0.3210725252609459\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 308.55450972987586, Val Loss: 310.9282789212912, Train SBP MSE: 224.6945595569022, Val SBP MSE: 227.11975969598723, Train SBP MAE: 11.410343495041984, Val SBP MAE: 11.486024281801496, Train SBP R2: 0.38633999599052593, Val SBP R2: 0.380226026265576, Train DBP MSE: 83.85995049123835, Val DBP MSE: 83.81418914150358, Train DBP MAE: 7.088974863873209, Val DBP MAE: 7.0864726276670185, Train DBP R2: 0.33415657189324943, Val DBP R2: 0.337758930111148\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 303.34734428710937, Val Loss: 301.12480409053825, Train SBP MSE: 220.70594206228262, Val SBP MSE: 219.14825247739654, Train SBP MAE: 11.291892544419424, Val SBP MAE: 11.232216150774274, Train SBP R2: 0.3972332505159907, Val SBP R2: 0.4019790111759677, Train DBP MSE: 82.64140199082829, Val DBP MSE: 81.98824058903385, Train DBP MAE: 7.029237673749242, Val DBP MAE: 6.992322279521397, Train DBP R2: 0.34383178045317053, Val DBP R2: 0.3521862977840371\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 298.79611979282924, Val Loss: 299.2957030859464, Train SBP MSE: 217.24837722866567, Val SBP MSE: 217.83829450150796, Train SBP MAE: 11.196914774377005, Val SBP MAE: 11.177827391651698, Train SBP R2: 0.40667615493630493, Val SBP R2: 0.40555367971748213, Train DBP MSE: 81.54774268804529, Val DBP MSE: 81.4735123747475, Train DBP MAE: 6.971823694430078, Val DBP MAE: 6.932744105093819, Train DBP R2: 0.352515375602943, Val DBP R2: 0.3562533199293624\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 295.33882155064174, Val Loss: 301.08334923836605, Train SBP MSE: 214.60782485931531, Val SBP MSE: 219.2436865787111, Train SBP MAE: 11.113946200084687, Val SBP MAE: 11.164267039271763, Train SBP R2: 0.41388772864222, Val SBP R2: 0.4017185865775943, Train DBP MSE: 80.73099674781808, Val DBP MSE: 81.85483618845966, Train DBP MAE: 6.9265152449301315, Val DBP MAE: 6.952264196940831, Train DBP R2: 0.3590002937736251, Val DBP R2: 0.3532403660017106\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 291.8227704171317, Val Loss: 302.7996323705809, Train SBP MSE: 211.90524661181544, Val SBP MSE: 220.8158547682428, Train SBP MAE: 11.029226880809238, Val SBP MAE: 11.357080426624844, Train SBP R2: 0.42126870031090324, Val SBP R2: 0.39742838775249345, Train DBP MSE: 79.91752395100498, Val DBP MSE: 81.99265258636996, Train DBP MAE: 6.884234597645487, Val DBP MAE: 6.991553370884486, Train DBP R2: 0.3654592233643147, Val DBP R2: 0.35215143726857856\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 288.7646578438895, Val Loss: 296.9887148911164, Train SBP MSE: 209.52396872071913, Val SBP MSE: 216.445971765559, Train SBP MAE: 10.963050979491642, Val SBP MAE: 11.194731599698748, Train SBP R2: 0.4277721733058857, Val SBP R2: 0.4093531086880612, Train DBP MSE: 79.24068904582302, Val DBP MSE: 80.55012487826231, Train DBP MAE: 6.848686836852346, Val DBP MAE: 6.93155771296365, Train DBP R2: 0.3708332555559478, Val DBP R2: 0.36354928174511103\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 285.938408203125, Val Loss: 315.9240311966082, Train SBP MSE: 207.42578334809932, Val SBP MSE: 229.63759008325817, Train SBP MAE: 10.902567530059814, Val SBP MAE: 11.44032875202724, Train SBP R2: 0.43350249649089545, Val SBP R2: 0.3733552645740481, Train DBP MSE: 78.51262469071783, Val DBP MSE: 86.29959559353787, Train DBP MAE: 6.807087906827245, Val DBP MAE: 7.115923954173497, Train DBP R2: 0.3766140467828186, Val DBP R2: 0.3181209876009006\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 282.80875450613837, Val Loss: 292.0306560788338, Train SBP MSE: 205.07023149806366, Val SBP MSE: 212.16422439518948, Train SBP MAE: 10.830909083366395, Val SBP MAE: 11.011407908793858, Train SBP R2: 0.4399357094738352, Val SBP R2: 0.42103732139510597, Train DBP MSE: 77.73852310986611, Val DBP MSE: 79.88201183396528, Train DBP MAE: 6.766303376187597, Val DBP MAE: 6.8549037278584075, Train DBP R2: 0.38276037106846217, Val DBP R2: 0.3688282434793224\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 280.1878269723075, Val Loss: 313.06180938637016, Train SBP MSE: 203.08769077092612, Val SBP MSE: 228.93816208499268, Train SBP MAE: 10.767575671413967, Val SBP MAE: 11.619315437916347, Train SBP R2: 0.4453501972699053, Val SBP R2: 0.37526389317776965, Train DBP MSE: 77.10013627739893, Val DBP MSE: 84.13510585037758, Train DBP MAE: 6.731200786805153, Val DBP MAE: 7.109401038469587, Train DBP R2: 0.38782912766202293, Val DBP R2: 0.33522327085336845\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 277.5079304216657, Val Loss: 284.1331124663135, Train SBP MSE: 201.0014843056386, Val SBP MSE: 206.69180049857573, Train SBP MAE: 10.710806950787136, Val SBP MAE: 10.843676439285279, Train SBP R2: 0.45104780503743425, Val SBP R2: 0.43597070239596414, Train DBP MSE: 76.50644592561261, Val DBP MSE: 77.45995356211765, Train DBP MAE: 6.7014249290909085, Val DBP MAE: 6.733184626415798, Train DBP R2: 0.3925429966394274, Val DBP R2: 0.38796565300044195\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 274.66578907296315, Val Loss: 280.27303361979875, Train SBP MSE: 198.86702834703544, Val SBP MSE: 202.77870974331404, Train SBP MAE: 10.64938250492641, Val SBP MAE: 10.728386190632412, Train SBP R2: 0.45687718628590535, Val SBP R2: 0.4466489093922127, Train DBP MSE: 75.79876096202241, Val DBP MSE: 77.50486126737185, Train DBP MAE: 6.670101004835537, Val DBP MAE: 6.736756828362601, Train DBP R2: 0.398161976610394, Val DBP R2: 0.3876108237396877\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 273.0155187386649, Val Loss: 280.4816999627206, Train SBP MSE: 197.7239759389036, Val SBP MSE: 203.28445128113376, Train SBP MAE: 10.617286519868033, Val SBP MAE: 10.70881711780003, Train SBP R2: 0.4599989598915524, Val SBP R2: 0.4452688205659624, Train DBP MSE: 75.29154273327806, Val DBP MSE: 77.21488952365564, Train DBP MAE: 6.6405611148084915, Val DBP MAE: 6.686122983469282, Train DBP R2: 0.4021892616522642, Val DBP R2: 0.38990197753790623\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0005), Train Loss: 270.94883496180944, Val Loss: 286.4302936742249, Train SBP MSE: 196.09350790075044, Val SBP MSE: 208.16995766505966, Train SBP MAE: 10.56839640336718, Val SBP MAE: 10.876027707835606, Train SBP R2: 0.464451907149392, Val SBP R2: 0.4319370448132772, Train DBP MSE: 74.85532705338461, Val DBP MSE: 78.27385577399134, Train DBP MAE: 6.618087189684595, Val DBP MAE: 6.767813978930882, Train DBP R2: 0.40565279033303203, Val DBP R2: 0.38153476728649505\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 8580.536637276786, Val Loss: 3710.9127267562058, Train SBP MSE: 7148.97372700865, Val SBP MSE: 3454.240760383389, Train SBP MAE: 80.87728068432381, Val SBP MAE: 55.57285932569163, Train SBP R2: -18.524456909998168, Val SBP R2: -8.426077788933377, Train DBP MSE: 1431.5629105781115, Val DBP MSE: 256.7848993730061, Train DBP MAE: 33.49143588348873, Val DBP MAE: 12.858404263346536, Train DBP R2: -10.366531345965878, Val DBP R2: -1.0289345781891335\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 1739.2135898890904, Val Loss: 627.3343547841966, Train SBP MSE: 1598.0740735459367, Val SBP MSE: 500.813115477594, Train SBP MAE: 33.740308723442574, Val SBP MAE: 17.186068434797015, Train SBP R2: -3.3644765779533143, Val SBP R2: -0.3666399396219042, Train DBP MSE: 141.1395162716766, Val DBP MSE: 126.57300684131336, Train DBP MAE: 9.34191107304756, Val DBP MAE: 8.935698593575614, Train DBP R2: -0.12064005291155455, Val DBP R2: -9.13249679461714e-05\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 489.4903237426758, Val Loss: 446.4612341328121, Train SBP MSE: 367.6142072657712, Val SBP MSE: 330.33847563924735, Train SBP MAE: 14.943310122990608, Val SBP MAE: 14.232823810141428, Train SBP R2: -0.003985750031137991, Val SBP R2: 0.09855844335887676, Train DBP MSE: 121.8761164857362, Val DBP MSE: 116.15290574979166, Train DBP MAE: 8.75556541547094, Val DBP MAE: 8.52432057334355, Train DBP R2: 0.03231028959790794, Val DBP R2: 0.08224102192798344\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 437.28731598249163, Val Loss: 431.10433080558147, Train SBP MSE: 324.3115761759085, Val SBP MSE: 319.55002801204154, Train SBP MAE: 14.10987558927536, Val SBP MAE: 13.98743083278111, Train SBP R2: 0.11427742830583654, Val SBP R2: 0.12799841399502576, Train DBP MSE: 112.9757401051391, Val DBP MSE: 111.58091237876503, Train DBP MAE: 8.412158907648495, Val DBP MAE: 8.33948762449537, Train DBP R2: 0.10297879209501215, Val DBP R2: 0.11836571409009033\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 426.92101205008373, Val Loss: 424.0119182579696, Train SBP MSE: 316.70295982233915, Val SBP MSE: 314.1184275620678, Train SBP MAE: 13.925477578258514, Val SBP MAE: 13.878516797855923, Train SBP R2: 0.1350572084271059, Val SBP R2: 0.14282039425391646, Train DBP MSE: 110.21805258423407, Val DBP MSE: 109.91709721162984, Train DBP MAE: 8.297326512946402, Val DBP MAE: 8.285489795930046, Train DBP R2: 0.12487468043993155, Val DBP R2: 0.13151201721211492\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 420.8562348109654, Val Loss: 417.8621908114641, Train SBP MSE: 312.0017752040714, Val SBP MSE: 309.5178029316775, Train SBP MAE: 13.804448607247217, Val SBP MAE: 13.738487482942853, Train SBP R2: 0.1478965445346847, Val SBP R2: 0.15537477266931332, Train DBP MSE: 108.85445957386511, Val DBP MSE: 108.36830196208493, Train DBP MAE: 8.238497843977383, Val DBP MAE: 8.211763607161386, Train DBP R2: 0.1357015344894259, Val DBP R2: 0.14374951343564513\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 415.697227734375, Val Loss: 412.8502442954445, Train SBP MSE: 308.0274058025142, Val SBP MSE: 305.7255948630856, Train SBP MAE: 13.696994266101292, Val SBP MAE: 13.631750822012766, Train SBP R2: 0.15875088630292467, Val SBP R2: 0.16572310989477101, Train DBP MSE: 107.66982170825568, Val DBP MSE: 107.14759642224965, Train DBP MAE: 8.189421597688538, Val DBP MAE: 8.150249771881104, Train DBP R2: 0.1451074944605666, Val DBP R2: 0.15339467436841914\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 411.21606055908205, Val Loss: 408.6527888212605, Train SBP MSE: 304.59040739657246, Val SBP MSE: 302.4365887621918, Train SBP MAE: 13.607109668472836, Val SBP MAE: 13.531960080337525, Train SBP R2: 0.16813762205536142, Val SBP R2: 0.17469828837997314, Train DBP MSE: 106.6256533563485, Val DBP MSE: 106.23956105105327, Train DBP MAE: 8.1438796174969, Val DBP MAE: 8.108928649330139, Train DBP R2: 0.1533981341626146, Val DBP R2: 0.1605693344334681\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 407.14395842459544, Val Loss: 405.52848347275085, Train SBP MSE: 301.43897389975797, Val SBP MSE: 299.95558483699676, Train SBP MAE: 13.524754911681583, Val SBP MAE: 13.422491236277988, Train SBP R2: 0.17674445568811337, Val SBP R2: 0.18146855646949156, Train DBP MSE: 105.70498440746543, Val DBP MSE: 105.59618211971225, Train DBP MAE: 8.105547291847637, Val DBP MAE: 8.06163261579786, Train DBP R2: 0.1607081953477787, Val DBP R2: 0.1656528645158971\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 403.33093916538786, Val Loss: 402.0385843099144, Train SBP MSE: 298.4855083705352, Val SBP MSE: 297.2437512691799, Train SBP MAE: 13.450260795341219, Val SBP MAE: 13.461518714741299, Train SBP R2: 0.18481062191874542, Val SBP R2: 0.18886872221765016, Train DBP MSE: 104.84543083938686, Val DBP MSE: 104.81776514884739, Train DBP MAE: 8.071577397506578, Val DBP MAE: 8.085442880221775, Train DBP R2: 0.1675330037462831, Val DBP R2: 0.17180337068776808\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 399.92060179094585, Val Loss: 398.16799778912144, Train SBP MSE: 295.82901403299763, Val SBP MSE: 294.3399932062679, Train SBP MAE: 13.381869180761065, Val SBP MAE: 13.277756309073311, Train SBP R2: 0.19206573449930442, Val SBP R2: 0.19679261961796146, Train DBP MSE: 104.09158792177045, Val DBP MSE: 103.85242188227862, Train DBP MAE: 8.040119313788415, Val DBP MAE: 7.994835225514003, Train DBP R2: 0.1735184753519714, Val DBP R2: 0.1794308376383007\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 396.6629023716518, Val Loss: 394.605802665027, Train SBP MSE: 293.31168452000986, Val SBP MSE: 291.6546719487582, Train SBP MAE: 13.316634464195797, Val SBP MAE: 13.219338847841536, Train SBP R2: 0.19894077607609928, Val SBP R2: 0.20412043745621566, Train DBP MSE: 103.35121810802225, Val DBP MSE: 102.97454284151708, Train DBP MAE: 8.010709262885365, Val DBP MAE: 7.969032520048959, Train DBP R2: 0.17939697124858367, Val DBP R2: 0.18636722348348733\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 393.6745946271624, Val Loss: 391.23884353777174, Train SBP MSE: 291.00543688385636, Val SBP MSE: 289.06543679562117, Train SBP MAE: 13.26022831773758, Val SBP MAE: 13.217337589645386, Train SBP R2: 0.20523933504628344, Val SBP R2: 0.21118605148266878, Train DBP MSE: 102.66915789133952, Val DBP MSE: 102.19640614916072, Train DBP MAE: 7.984487698497091, Val DBP MAE: 7.9672922990254, Train DBP R2: 0.1848124921282286, Val DBP R2: 0.1925155150907215\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 391.03132347063337, Val Loss: 389.1005209621171, Train SBP MSE: 288.9188076460103, Val SBP MSE: 287.3346584482413, Train SBP MAE: 13.207434459768022, Val SBP MAE: 13.190400611005511, Train SBP R2: 0.2109380974417241, Val SBP R2: 0.21590907239218782, Train DBP MSE: 102.11251573823496, Val DBP MSE: 101.78861278405415, Train DBP MAE: 7.961206038437571, Val DBP MAE: 7.9575842091969085, Train DBP R2: 0.18923220043094924, Val DBP R2: 0.19573761289024572\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 388.4671632237026, Val Loss: 386.02195496358644, Train SBP MSE: 286.8995494554323, Val SBP MSE: 284.9869426286173, Train SBP MAE: 13.154151486151559, Val SBP MAE: 13.112416890226092, Train SBP R2: 0.21645286376170025, Val SBP R2: 0.2223156182809085, Train DBP MSE: 101.56761385615732, Val DBP MSE: 101.05738346302984, Train DBP MAE: 7.9389346662282945, Val DBP MAE: 7.924275042234148, Train DBP R2: 0.1935586916227403, Val DBP R2: 0.2015152752747339\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 386.1714703944615, Val Loss: 383.7416941069162, Train SBP MSE: 285.1079357428108, Val SBP MSE: 283.2544795189655, Train SBP MAE: 13.109715937927792, Val SBP MAE: 13.034607754353114, Train SBP R2: 0.2213459135989494, Val SBP R2: 0.22704323664073078, Train DBP MSE: 101.06353492661273, Val DBP MSE: 100.5098735841616, Train DBP MAE: 7.918722733112744, Val DBP MAE: 7.884161323165894, Train DBP R2: 0.1975610508003719, Val DBP R2: 0.20584131519315718\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 384.0210629865374, Val Loss: 382.4558310290795, Train SBP MSE: 283.4201472401061, Val SBP MSE: 282.1314755009359, Train SBP MAE: 13.067329657908848, Val SBP MAE: 12.980624287523542, Train SBP R2: 0.22595540793374524, Val SBP R2: 0.23010773734161916, Train DBP MSE: 100.60091556083134, Val DBP MSE: 100.34650984769868, Train DBP MAE: 7.898661728855542, Val DBP MAE: 7.8706810766765045, Train DBP R2: 0.20123422330543594, Val DBP R2: 0.20713210111764535\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 381.8423539202009, Val Loss: 380.1062970483979, Train SBP MSE: 281.72631831928527, Val SBP MSE: 280.37116345563817, Train SBP MAE: 13.023294337081909, Val SBP MAE: 13.007085003335135, Train SBP R2: 0.23058139916553988, Val SBP R2: 0.2349113510509111, Train DBP MSE: 100.11603570431325, Val DBP MSE: 99.75643328982476, Train DBP MAE: 7.879516934391431, Val DBP MAE: 7.871346016066415, Train DBP R2: 0.20508414289151577, Val DBP R2: 0.21179447314564426\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 379.91040829729354, Val Loss: 377.483424708002, Train SBP MSE: 280.22096953821546, Val SBP MSE: 278.35626521207774, Train SBP MAE: 12.983923238618033, Val SBP MAE: 12.910871041434152, Train SBP R2: 0.2346926350621663, Val SBP R2: 0.24040969030925452, Train DBP MSE: 99.68943854847609, Val DBP MSE: 99.14805353972365, Train DBP MAE: 7.861288806373732, Val DBP MAE: 7.828778006308419, Train DBP R2: 0.20847130101645284, Val DBP R2: 0.21660146419014947\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05), Train Loss: 377.9569578020368, Val Loss: 376.3452573772758, Train SBP MSE: 278.6627861462357, Val SBP MSE: 277.4515209808748, Train SBP MAE: 12.94459896277019, Val SBP MAE: 12.862579508427212, Train SBP R2: 0.23894816678690134, Val SBP R2: 0.24287859450383675, Train DBP MSE: 99.29417185613514, Val DBP MSE: 98.91524047670374, Train DBP MAE: 7.84289790963786, Val DBP MAE: 7.804157440948487, Train DBP R2: 0.21160969697188836, Val DBP R2: 0.21844099009283524\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 444.14935236990794, Val Loss: 433.02237863209393, Train SBP MSE: 329.37043693807897, Val SBP MSE: 323.2792739820825, Train SBP MAE: 14.166387086559046, Val SBP MAE: 14.256723666163854, Train SBP R2: 0.10046124814678503, Val SBP R2: 0.11782189039805147, Train DBP MSE: 114.77891532801748, Val DBP MSE: 109.75376033329503, Train DBP MAE: 8.435744167655264, Val DBP MAE: 8.329253887612479, Train DBP R2: 0.08866167927959334, Val DBP R2: 0.13280259092246993\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 410.2374690673828, Val Loss: 395.31643858077973, Train SBP MSE: 304.7818379365731, Val SBP MSE: 293.99348238549646, Train SBP MAE: 13.593081540611813, Val SBP MAE: 13.21421873664856, Train SBP R2: 0.16761480892550173, Val SBP R2: 0.19773819295169048, Train DBP MSE: 105.45563120895758, Val DBP MSE: 101.34521713765416, Train DBP MAE: 8.065356948937689, Val DBP MAE: 7.849271880340576, Train DBP R2: 0.16268804612912569, Val DBP R2: 0.19924101500227054\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 396.1571431623186, Val Loss: 390.6154866331892, Train SBP MSE: 294.09464277080366, Val SBP MSE: 290.2871278976771, Train SBP MAE: 13.299045061765398, Val SBP MAE: 13.035061380985805, Train SBP R2: 0.19680245032282395, Val SBP R2: 0.20785224930706436, Train DBP MSE: 102.06250058937228, Val DBP MSE: 100.3552218056963, Train DBP MAE: 7.91126647068773, Val DBP MAE: 7.8028090381077355, Train DBP R2: 0.1896293179820674, Val DBP R2: 0.20706326532212826\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 385.6071012660435, Val Loss: 372.97327646956364, Train SBP MSE: 286.19620343709124, Val SBP MSE: 275.61082995617085, Train SBP MAE: 13.083587305654799, Val SBP MAE: 12.785020618656704, Train SBP R2: 0.21837376171884837, Val SBP R2: 0.24790154976024026, Train DBP MSE: 99.41089779683735, Val DBP MSE: 97.38370817310756, Train DBP MAE: 7.786726699767794, Val DBP MAE: 7.6130308319909235, Train DBP R2: 0.2106828993760056, Val DBP R2: 0.2305420865979929\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 376.6469888253348, Val Loss: 370.51279315564926, Train SBP MSE: 279.38537160540966, Val SBP MSE: 272.9448823389466, Train SBP MAE: 12.891472638934, Val SBP MAE: 12.763660027749198, Train SBP R2: 0.23697472427610689, Val SBP R2: 0.25517649999225245, Train DBP MSE: 97.26161732074787, Val DBP MSE: 97.58346787745847, Train DBP MAE: 7.680199812272617, Val DBP MAE: 7.763329496492658, Train DBP R2: 0.2277480690044067, Val DBP R2: 0.22896372520495145\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 368.03823707101003, Val Loss: 365.20950937358293, Train SBP MSE: 272.8434172499165, Val SBP MSE: 270.8730769150537, Train SBP MAE: 12.704425751481738, Val SBP MAE: 12.536844644982475, Train SBP R2: 0.25484135951613385, Val SBP R2: 0.2608301299630197, Train DBP MSE: 95.19481985422519, Val DBP MSE: 94.35655259564354, Train DBP MAE: 7.5867384324039735, Val DBP MAE: 7.570587935256958, Train DBP R2: 0.24415832804046012, Val DBP R2: 0.2544605515843359\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 361.0878241646903, Val Loss: 361.12433332063165, Train SBP MSE: 267.4657540217188, Val SBP MSE: 265.87881758704816, Train SBP MAE: 12.559519622673307, Val SBP MAE: 12.51201135673523, Train SBP R2: 0.26952821639724933, Val SBP R2: 0.274458675333627, Train DBP MSE: 93.62207037561748, Val DBP MSE: 95.26682684871383, Train DBP MAE: 7.510312188710485, Val DBP MAE: 7.628837381526402, Train DBP R2: 0.2566458730277258, Val DBP R2: 0.24726820144147643\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 356.2496692679269, Val Loss: 365.8327413625212, Train SBP MSE: 263.7404898456242, Val SBP MSE: 270.29432003304163, Train SBP MAE: 12.463637862028394, Val SBP MAE: 12.49766254561288, Train SBP R2: 0.2797022305511593, Val SBP R2: 0.26240946613822025, Train DBP MSE: 92.50917947502171, Val DBP MSE: 95.56368579947883, Train DBP MAE: 7.458698120641708, Val DBP MAE: 7.557369204030718, Train DBP R2: 0.26548216601407737, Val DBP R2: 0.2449226297527879\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 351.23489599434987, Val Loss: 355.27190893616057, Train SBP MSE: 259.9417291482854, Val SBP MSE: 262.7616246562793, Train SBP MAE: 12.357787407772882, Val SBP MAE: 12.489983645302908, Train SBP R2: 0.29007696997234056, Val SBP R2: 0.282965002797981, Train DBP MSE: 91.29316683982006, Val DBP MSE: 92.52807848584558, Train DBP MAE: 7.3978142093930925, Val DBP MAE: 7.416969907597133, Train DBP R2: 0.2751372399427028, Val DBP R2: 0.26890787444386166\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 346.955078023856, Val Loss: 345.80801664976576, Train SBP MSE: 256.43064211678484, Val SBP MSE: 255.9555588952311, Train SBP MAE: 12.257806680999483, Val SBP MAE: 12.267313499668667, Train SBP R2: 0.29966604807942576, Val SBP R2: 0.301537681933733, Train DBP MSE: 90.52443596276741, Val DBP MSE: 89.86664643300205, Train DBP MAE: 7.3590418011324745, Val DBP MAE: 7.317120678111485, Train DBP R2: 0.28124092113342525, Val DBP R2: 0.2899366480699591\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 343.4404527378627, Val Loss: 343.4305777122595, Train SBP MSE: 253.84881043627777, Val SBP MSE: 254.29615078806617, Train SBP MAE: 12.175672559942518, Val SBP MAE: 12.182461617824009, Train SBP R2: 0.30671725057643395, Val SBP R2: 0.3060659447233791, Train DBP MSE: 89.59164227990391, Val DBP MSE: 89.1407990520095, Train DBP MAE: 7.315112533204896, Val DBP MAE: 7.295669591576712, Train DBP R2: 0.28864725204437713, Val DBP R2: 0.2956717861305681\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 339.1459922188895, Val Loss: 340.15967589802017, Train SBP MSE: 250.520001412838, Val SBP MSE: 252.1110557754614, Train SBP MAE: 12.083190534727914, Val SBP MAE: 12.12286853376116, Train SBP R2: 0.31580851189891124, Val SBP R2: 0.31202872409916793, Train DBP MSE: 88.62599090655553, Val DBP MSE: 88.05787546836206, Train DBP MAE: 7.265086607956886, Val DBP MAE: 7.259333734021868, Train DBP R2: 0.2963144712237332, Val DBP R2: 0.304228290464599\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 335.4336786603655, Val Loss: 342.69903846894147, Train SBP MSE: 247.71706042501683, Val SBP MSE: 253.39438371813452, Train SBP MAE: 12.003030487060547, Val SBP MAE: 12.111597964532034, Train SBP R2: 0.3234635827703052, Val SBP R2: 0.30852672471479203, Train DBP MSE: 87.71661817507504, Val DBP MSE: 89.32516288809289, Train DBP MAE: 7.221628636377198, Val DBP MAE: 7.325836396081107, Train DBP R2: 0.3035348410594986, Val DBP R2: 0.29421507211463294\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 332.5134223615374, Val Loss: 333.6320933981831, Train SBP MSE: 245.47838590985856, Val SBP MSE: 245.00558973160403, Train SBP MAE: 11.938043189246313, Val SBP MAE: 11.92962736478533, Train SBP R2: 0.3295775937844436, Val SBP R2: 0.3314184193468699, Train DBP MSE: 87.03503644087164, Val DBP MSE: 88.6247125098666, Train DBP MAE: 7.185624283167294, Val DBP MAE: 7.3087914303098405, Train DBP R2: 0.30894656281438326, Val DBP R2: 0.2997495408320656\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 329.43130047956197, Val Loss: 337.53408752804046, Train SBP MSE: 243.08754713671388, Val SBP MSE: 248.53956817134284, Train SBP MAE: 11.86995580698422, Val SBP MAE: 11.916721643938336, Train SBP R2: 0.33610717836364856, Val SBP R2: 0.3217747500174355, Train DBP MSE: 86.34375349597107, Val DBP MSE: 89.01041844038743, Train DBP MAE: 7.150537747859955, Val DBP MAE: 7.223417117868151, Train DBP R2: 0.31443531165251193, Val DBP R2: 0.29670196248397285\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 326.05379728131976, Val Loss: 326.67841195449967, Train SBP MSE: 240.53722175733287, Val SBP MSE: 240.44861242063487, Train SBP MAE: 11.80118741197586, Val SBP MAE: 11.685483968952724, Train SBP R2: 0.34307233446543695, Val SBP R2: 0.3438536911172233, Train DBP MSE: 85.51657534003905, Val DBP MSE: 86.23337633771335, Train DBP MAE: 7.111486168425424, Val DBP MAE: 7.083325797598703, Train DBP R2: 0.32100306104628606, Val DBP R2: 0.31864420582055586\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 323.88065506591795, Val Loss: 326.9906519134912, Train SBP MSE: 238.81773922280126, Val SBP MSE: 242.14887295652238, Train SBP MAE: 11.752381150913239, Val SBP MAE: 11.69017996384757, Train SBP R2: 0.3477683879040059, Val SBP R2: 0.33921394849808095, Train DBP MSE: 85.06291600068293, Val DBP MSE: 84.85857653575407, Train DBP MAE: 7.090882250104632, Val DBP MAE: 7.033560118293762, Train DBP R2: 0.3246050914307558, Val DBP R2: 0.32950691177831903\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 321.95497144949775, Val Loss: 321.1293458607341, Train SBP MSE: 237.40531251927703, Val SBP MSE: 237.09973817959275, Train SBP MAE: 11.712731144401005, Val SBP MAE: 11.666247715759278, Train SBP R2: 0.35162584568249833, Val SBP R2: 0.3529922403068041, Train DBP MSE: 84.54965886060445, Val DBP MSE: 84.03412489866601, Train DBP MAE: 7.061195283910206, Val DBP MAE: 7.02253995538439, Train DBP R2: 0.3286803250988921, Val DBP R2: 0.33602115166788027\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 319.6554534999302, Val Loss: 320.84949517119304, Train SBP MSE: 235.45349390605185, Val SBP MSE: 236.75437026212907, Train SBP MAE: 11.657161826671873, Val SBP MAE: 11.65859316493443, Train SBP R2: 0.3569564287655046, Val SBP R2: 0.3539346948378116, Train DBP MSE: 84.20195955637752, Val DBP MSE: 84.10820398087463, Train DBP MAE: 7.048572189191409, Val DBP MAE: 7.025490545504434, Train DBP R2: 0.33144103858990415, Val DBP R2: 0.33543583060040094\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.001), Train Loss: 317.44222204938615, Val Loss: 317.6420471498256, Train SBP MSE: 233.76994903065517, Val SBP MSE: 233.64443999519833, Train SBP MAE: 11.608864113712311, Val SBP MAE: 11.595402918515887, Train SBP R2: 0.3615543333922272, Val SBP R2: 0.3624212036389509, Train DBP MSE: 83.67227309123517, Val DBP MSE: 84.00045152910239, Train DBP MAE: 7.024625197815895, Val DBP MAE: 7.0173273208890645, Train DBP R2: 0.3356467202019985, Val DBP R2: 0.3362872150697337\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 446.5100026698521, Val Loss: 437.2893224294268, Train SBP MSE: 330.7089104220039, Val SBP MSE: 324.9512401364014, Train SBP MAE: 14.187442961860505, Val SBP MAE: 14.345563544028145, Train SBP R2: 0.09680576291771781, Val SBP R2: 0.11325935867998882, Train DBP MSE: 115.80109224421906, Val DBP MSE: 112.35235950751701, Train DBP MAE: 8.474084130591933, Val DBP MAE: 8.460598626736232, Train DBP R2: 0.08054565037630468, Val DBP R2: 0.11227027873313822\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 410.33286371547155, Val Loss: 406.39664120996673, Train SBP MSE: 304.3278201486424, Val SBP MSE: 301.39880415746643, Train SBP MAE: 13.606722554274969, Val SBP MAE: 13.641508403124128, Train SBP R2: 0.16885477022279072, Val SBP R2: 0.17753023875369667, Train DBP MSE: 106.00504367035487, Val DBP MSE: 105.01837836337432, Train DBP MAE: 8.10777635103975, Val DBP MAE: 8.129486456189836, Train DBP R2: 0.15832574118381648, Val DBP R2: 0.1702182654545974\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 383.7736936907087, Val Loss: 367.7828033210155, Train SBP MSE: 284.27160156066424, Val SBP MSE: 272.138882989429, Train SBP MAE: 13.069439604173388, Val SBP MAE: 12.807010992758615, Train SBP R2: 0.22363001357262646, Val SBP R2: 0.25737594499143057, Train DBP MSE: 99.50209217462191, Val DBP MSE: 95.65553579675499, Train DBP MAE: 7.823697382651057, Val DBP MAE: 7.657551351274763, Train DBP R2: 0.20995882099565277, Val DBP R2: 0.2441968953504332\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 358.05702950788225, Val Loss: 351.6112398430024, Train SBP MSE: 264.1334216383905, Val SBP MSE: 258.7177634222842, Train SBP MAE: 12.530353404181344, Val SBP MAE: 12.357428971426828, Train SBP R2: 0.27862910031605326, Val SBP R2: 0.2940000617887908, Train DBP MSE: 93.92360768822866, Val DBP MSE: 92.91570748314923, Train DBP MAE: 7.570254152662414, Val DBP MAE: 7.542644785962786, Train DBP R2: 0.25425168322967584, Val DBP R2: 0.2658451013678027\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 340.92414801025393, Val Loss: 333.17587605952343, Train SBP MSE: 250.94017491127855, Val SBP MSE: 244.9734619222301, Train SBP MAE: 12.166830906418392, Val SBP MAE: 11.977359965787615, Train SBP R2: 0.31466098224244754, Val SBP R2: 0.3315060910673301, Train DBP MSE: 89.98397285394152, Val DBP MSE: 88.22010507809838, Train DBP MAE: 7.3747458644492285, Val DBP MAE: 7.296743059376308, Train DBP R2: 0.2855321687079563, Val DBP R2: 0.3029464656158486\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 327.9649116908482, Val Loss: 327.68876348073564, Train SBP MSE: 241.01886974787078, Val SBP MSE: 240.62414578532517, Train SBP MAE: 11.886895208311081, Val SBP MAE: 11.873514826583863, Train SBP R2: 0.3417569127285356, Val SBP R2: 0.34337468827263284, Train DBP MSE: 86.94604171430737, Val DBP MSE: 87.06853481090995, Train DBP MAE: 7.225386970911707, Val DBP MAE: 7.242868532453264, Train DBP R2: 0.30965317608414833, Val DBP R2: 0.3120453680046499\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 318.202699937221, Val Loss: 310.26458487083534, Train SBP MSE: 233.53485541966722, Val SBP MSE: 227.89240992875426, Train SBP MAE: 11.669360265650068, Val SBP MAE: 11.403727233941215, Train SBP R2: 0.36219639409252147, Val SBP R2: 0.37811758574190757, Train DBP MSE: 84.667844734887, Val DBP MSE: 82.38836480760791, Train DBP MAE: 7.111419096098627, Val DBP MAE: 6.964808432170323, Train DBP R2: 0.327741935710094, Val DBP R2: 0.3490247962135863\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 310.0251716169085, Val Loss: 314.5797329367406, Train SBP MSE: 227.44663092500684, Val SBP MSE: 230.77616588008456, Train SBP MAE: 11.489700484343938, Val SBP MAE: 11.556965710013253, Train SBP R2: 0.3788238543887187, Val SBP R2: 0.3702482709468028, Train DBP MSE: 82.57854067193685, Val DBP MSE: 83.81240654168485, Train DBP MAE: 7.002939079894339, Val DBP MAE: 7.033666652543205, Train DBP R2: 0.3443308958929102, Val DBP R2: 0.3377730149674619\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 302.90752580915176, Val Loss: 301.0482185719436, Train SBP MSE: 221.88349606655962, Val SBP MSE: 220.31324347029945, Train SBP MAE: 11.326429412841797, Val SBP MAE: 11.217589287458148, Train SBP R2: 0.39401725010898914, Val SBP R2: 0.39879993464822416, Train DBP MSE: 81.02402975541914, Val DBP MSE: 80.7439258225091, Train DBP MAE: 6.92102906464168, Val DBP MAE: 6.882810943821498, Train DBP R2: 0.35667362769301614, Val DBP R2: 0.36201800230450487\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 297.00275797642297, Val Loss: 298.3500555620769, Train SBP MSE: 217.4950097895098, Val SBP MSE: 218.4082257268319, Train SBP MAE: 11.196123842838832, Val SBP MAE: 11.19664423664638, Train SBP R2: 0.4060025803799161, Val SBP R2: 0.4039984273662681, Train DBP MSE: 79.50774813734814, Val DBP MSE: 79.95510358297696, Train DBP MAE: 6.840920617004803, Val DBP MAE: 6.800008845792498, Train DBP R2: 0.3687128209507934, Val DBP R2: 0.36825072362783506\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 291.74582755214146, Val Loss: 295.93514161397593, Train SBP MSE: 213.51395485244814, Val SBP MSE: 217.27069759702707, Train SBP MAE: 11.083987899398803, Val SBP MAE: 11.196811981473651, Train SBP R2: 0.4168751809157585, Val SBP R2: 0.40710256207558415, Train DBP MSE: 78.23187270893473, Val DBP MSE: 78.67932416920083, Train DBP MAE: 6.776502416389329, Val DBP MAE: 6.772733743858337, Train DBP R2: 0.37884320218898326, Val DBP R2: 0.37833103977209637\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 286.84991661725724, Val Loss: 298.0590582225179, Train SBP MSE: 209.68061759883872, Val SBP MSE: 219.33595407247464, Train SBP MAE: 10.967655321325575, Val SBP MAE: 11.299893850708008, Train SBP R2: 0.427344351860789, Val SBP R2: 0.40146680315138383, Train DBP MSE: 77.16929915640002, Val DBP MSE: 78.71926704955202, Train DBP MAE: 6.723030823411261, Val DBP MAE: 6.7813765964780535, Train DBP R2: 0.3872799781790809, Val DBP R2: 0.37801543908336865\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 282.4730746677944, Val Loss: 288.8625348350902, Train SBP MSE: 206.40338128862828, Val SBP MSE: 211.53135272868317, Train SBP MAE: 10.874702077933721, Val SBP MAE: 10.962386850956507, Train SBP R2: 0.4362947637053378, Val SBP R2: 0.4227643282752629, Train DBP MSE: 76.06969336627265, Val DBP MSE: 77.34155989884715, Train DBP MAE: 6.666279381786074, Val DBP MAE: 6.693445854895455, Train DBP R2: 0.39601078811368673, Val DBP R2: 0.38890111687637285\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 279.0325291556222, Val Loss: 284.4114502169314, Train SBP MSE: 203.77655907326465, Val SBP MSE: 207.59308384532866, Train SBP MAE: 10.793344014630998, Val SBP MAE: 10.8258141015734, Train SBP R2: 0.4434688391898134, Val SBP R2: 0.43351124240875105, Train DBP MSE: 75.25597023291822, Val DBP MSE: 76.8261106236645, Train DBP MAE: 6.622360612140383, Val DBP MAE: 6.623540412766593, Train DBP R2: 0.4024717053628458, Val DBP R2: 0.39297383634030614\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 275.4913687325614, Val Loss: 286.294060178823, Train SBP MSE: 201.19931914070816, Val SBP MSE: 209.31424240073594, Train SBP MAE: 10.715398405960627, Val SBP MAE: 10.85741996029445, Train SBP R2: 0.4505075012315859, Val SBP R2: 0.42881447239305703, Train DBP MSE: 74.2920496127013, Val DBP MSE: 76.99028559021808, Train DBP MAE: 6.572027866656439, Val DBP MAE: 6.662270924036844, Train DBP R2: 0.41012518245683793, Val DBP R2: 0.39167664064333596\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 272.2496080235073, Val Loss: 293.68611852168164, Train SBP MSE: 198.68894376971622, Val SBP MSE: 215.47953258472, Train SBP MAE: 10.639521796308244, Val SBP MAE: 10.991081712559291, Train SBP R2: 0.4573635504535435, Val SBP R2: 0.4119903686617551, Train DBP MSE: 73.56066404336684, Val DBP MSE: 78.2179328883062, Train DBP MAE: 6.534942112725122, Val DBP MAE: 6.690243447249276, Train DBP R2: 0.41593234394334944, Val DBP R2: 0.38197663079465205\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 269.22970997052875, Val Loss: 277.4261177453524, Train SBP MSE: 196.50225798462154, Val SBP MSE: 203.20368711117385, Train SBP MAE: 10.567401002461569, Val SBP MAE: 10.716265910557338, Train SBP R2: 0.4633355758123011, Val SBP R2: 0.4454892132372933, Train DBP MSE: 72.72745198263893, Val DBP MSE: 74.22876653782461, Train DBP MAE: 6.490370807147026, Val DBP MAE: 6.511475866685595, Train DBP R2: 0.42254800221174904, Val DBP R2: 0.41349623169954663\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 266.7434220877511, Val Loss: 275.67937051748663, Train SBP MSE: 194.49966639048344, Val SBP MSE: 201.69527504051044, Train SBP MAE: 10.51104491739273, Val SBP MAE: 10.729035351780484, Train SBP R2: 0.46880482423607905, Val SBP R2: 0.44960543167779976, Train DBP MSE: 72.24375581192001, Val DBP MSE: 73.99496442038068, Train DBP MAE: 6.464071090902601, Val DBP MAE: 6.524460908944266, Train DBP R2: 0.42638852339721367, Val DBP R2: 0.4153435724181562\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 263.939418548584, Val Loss: 274.86333324704356, Train SBP MSE: 192.37614239206005, Val SBP MSE: 201.15891295800128, Train SBP MAE: 10.449815991306306, Val SBP MAE: 10.632688083430699, Train SBP R2: 0.4746043493690265, Val SBP R2: 0.4510690791371055, Train DBP MSE: 71.56327591001812, Val DBP MSE: 73.71004925817729, Train DBP MAE: 6.428981798114095, Val DBP MAE: 6.486657148674556, Train DBP R2: 0.43179149666378414, Val DBP R2: 0.4175947726478283\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 0.0005), Train Loss: 261.5322881147112, Val Loss: 276.9405012461995, Train SBP MSE: 190.59387668349544, Val SBP MSE: 203.34709864123244, Train SBP MAE: 10.39544795432772, Val SBP MAE: 10.663252282605852, Train SBP R2: 0.4794718690100027, Val SBP R2: 0.44509786580903465, Train DBP MSE: 70.93841122734635, Val DBP MSE: 73.59845721573592, Train DBP MAE: 6.396920512151718, Val DBP MAE: 6.490805891036987, Train DBP R2: 0.43675288812628565, Val DBP R2: 0.41847649487570415\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 647.5511396362305, Val Loss: 454.28042340322213, Train SBP MSE: 485.1093812760879, Val SBP MSE: 335.7566614092416, Train SBP MAE: 15.981530603412237, Val SBP MAE: 14.418853498159136, Train SBP R2: -0.32487509019340144, Val SBP R2: 0.08377306964416531, Train DBP MSE: 162.44175879797498, Val DBP MSE: 118.55185609653816, Train DBP MAE: 9.483511016166856, Val DBP MAE: 8.62576520739964, Train DBP R2: -0.28977869545766244, Val DBP R2: 0.0632861950602146\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 447.0381605817522, Val Loss: 442.6343593841497, Train SBP MSE: 330.7685041251978, Val SBP MSE: 327.2187723842246, Train SBP MAE: 14.266613231103761, Val SBP MAE: 14.214796310315814, Train SBP R2: 0.09664300743216903, Val SBP R2: 0.10707162110186919, Train DBP MSE: 116.26965624630935, Val DBP MSE: 115.4405045529589, Train DBP MAE: 8.531305439613547, Val DBP MAE: 8.490874863161359, Train DBP R2: 0.07682527778352788, Val DBP R2: 0.08786991765092744\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 437.9785659580776, Val Loss: 436.0794617201336, Train SBP MSE: 323.9058861233996, Val SBP MSE: 322.1399479651441, Train SBP MAE: 14.10223361165183, Val SBP MAE: 14.021917616598946, Train SBP R2: 0.1153854024363189, Val SBP R2: 0.12093093125756138, Train DBP MSE: 114.07267991674146, Val DBP MSE: 113.96386688505198, Train DBP MAE: 8.44418206022467, Val DBP MAE: 8.402624938610622, Train DBP R2: 0.09426914988433177, Val DBP R2: 0.0995372751598318\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 433.4742198364258, Val Loss: 432.2264582966974, Train SBP MSE: 320.51143001164075, Val SBP MSE: 319.29443297194257, Train SBP MAE: 14.019798977116176, Val SBP MAE: 13.996792005375454, Train SBP R2: 0.12465595155535258, Val SBP R2: 0.12869589251420432, Train DBP MSE: 112.96278968652284, Val DBP MSE: 112.9558914952663, Train DBP MAE: 8.400526385644504, Val DBP MAE: 8.396382303019932, Train DBP R2: 0.10308161771172619, Val DBP R2: 0.1075015913142997\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 430.36341112060546, Val Loss: 429.709566587068, Train SBP MSE: 318.23502223776063, Val SBP MSE: 317.4396585812971, Train SBP MAE: 13.961639733382635, Val SBP MAE: 13.936902374049595, Train SBP R2: 0.13087301531693785, Val SBP R2: 0.13375727905322632, Train DBP MSE: 112.12838898854275, Val DBP MSE: 112.29425423121218, Train DBP MAE: 8.368747269780295, Val DBP MAE: 8.370982025636945, Train DBP R2: 0.10970671369500784, Val DBP R2: 0.11272938596474702\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 427.7100528616769, Val Loss: 427.00289287253315, Train SBP MSE: 316.3749734360757, Val SBP MSE: 315.6827152266142, Train SBP MAE: 13.916752285412379, Val SBP MAE: 13.912740063694546, Train SBP R2: 0.13595296721853523, Val SBP R2: 0.13855170013757268, Train DBP MSE: 111.33507966935584, Val DBP MSE: 111.34276573814829, Train DBP MAE: 8.337183349755833, Val DBP MAE: 8.341591495350428, Train DBP R2: 0.11600554637428129, Val DBP R2: 0.12024738219053821\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 425.2257323486328, Val Loss: 424.49871443307376, Train SBP MSE: 314.62996614319263, Val SBP MSE: 313.92143737400727, Train SBP MAE: 13.87522820427077, Val SBP MAE: 13.8158835509164, Train SBP R2: 0.14071873094890308, Val SBP R2: 0.1433579493825604, Train DBP MSE: 110.59576594637144, Val DBP MSE: 110.60184748160668, Train DBP MAE: 8.30938358688695, Val DBP MAE: 8.290926070131574, Train DBP R2: 0.12187565696789227, Val DBP R2: 0.12610159976322022\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 422.98011646379746, Val Loss: 424.01474169882823, Train SBP MSE: 313.0392630189963, Val SBP MSE: 313.79368550945, Train SBP MAE: 13.837012691743034, Val SBP MAE: 13.899536059842792, Train SBP R2: 0.14506307683559105, Val SBP R2: 0.14370656405551807, Train DBP MSE: 109.94085327673324, Val DBP MSE: 110.23817092154586, Train DBP MAE: 8.284433442023822, Val DBP MAE: 8.287746852357047, Train DBP R2: 0.1270756278062719, Val DBP R2: 0.12897511744196988\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 420.9357764072963, Val Loss: 420.25274393196736, Train SBP MSE: 311.60013940578875, Val SBP MSE: 310.89892899817823, Train SBP MAE: 13.800925450617926, Val SBP MAE: 13.784801581573486, Train SBP R2: 0.14899344615112997, Val SBP R2: 0.15160589764228305, Train DBP MSE: 109.33563687273603, Val DBP MSE: 109.37316306538028, Train DBP MAE: 8.257870034732138, Val DBP MAE: 8.24571653540475, Train DBP R2: 0.13188101300890298, Val DBP R2: 0.13580980419366329\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 418.8290243669782, Val Loss: 418.9813881478318, Train SBP MSE: 310.05582282729637, Val SBP MSE: 310.0792546358657, Train SBP MAE: 13.764616450439181, Val SBP MAE: 13.67345708857945, Train SBP R2: 0.15321110642567548, Val SBP R2: 0.15384265959280052, Train DBP MSE: 108.77320147803307, Val DBP MSE: 108.92574670531546, Train DBP MAE: 8.235242336787497, Val DBP MAE: 8.21070108669826, Train DBP R2: 0.1363467193336012, Val DBP R2: 0.13934497517139433\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 416.8197283150809, Val Loss: 415.6633759869954, Train SBP MSE: 308.57583171295045, Val SBP MSE: 307.44739040626587, Train SBP MAE: 13.726585537706102, Val SBP MAE: 13.67372458948408, Train SBP R2: 0.15725308837198693, Val SBP R2: 0.16102460163999177, Train DBP MSE: 108.24389673718478, Val DBP MSE: 108.23908813093605, Train DBP MAE: 8.214418763702257, Val DBP MAE: 8.209687715067183, Train DBP R2: 0.14054937007564272, Val DBP R2: 0.14477047070625704\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 414.5340518310547, Val Loss: 417.0485888172547, Train SBP MSE: 306.90113005876844, Val SBP MSE: 308.2054649882625, Train SBP MAE: 13.685740361854009, Val SBP MAE: 13.60128876626151, Train SBP R2: 0.16182684140742631, Val SBP R2: 0.15895593576653355, Train DBP MSE: 107.6329215782867, Val DBP MSE: 108.86655036524877, Train DBP MAE: 8.190542710137366, Val DBP MAE: 8.178315853146144, Train DBP R2: 0.1454004794777558, Val DBP R2: 0.1398127032253289\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 412.2404398838588, Val Loss: 411.32437255134096, Train SBP MSE: 305.1450648331804, Val SBP MSE: 304.2102806559251, Train SBP MAE: 13.641852501242502, Val SBP MAE: 13.653238068771362, Train SBP R2: 0.16662280529502715, Val SBP R2: 0.16985816317628732, Train DBP MSE: 107.09537523693984, Val DBP MSE: 107.13319338800359, Train DBP MAE: 8.167724697749955, Val DBP MAE: 8.18649111077445, Train DBP R2: 0.14966856807776097, Val DBP R2: 0.15350847706586757\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 409.920391003418, Val Loss: 409.7439922074731, Train SBP MSE: 303.40533673982856, Val SBP MSE: 302.9834251462713, Train SBP MAE: 13.599467824895042, Val SBP MAE: 13.50111766646249, Train SBP R2: 0.17137415108126675, Val SBP R2: 0.173206058205033, Train DBP MSE: 106.51505393333021, Val DBP MSE: 106.78052071486063, Train DBP MAE: 8.145179781304087, Val DBP MAE: 8.115400607054575, Train DBP R2: 0.15427628754259837, Val DBP R2: 0.15629504973065156\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 407.53715878208703, Val Loss: 408.0374615196772, Train SBP MSE: 301.598350528824, Val SBP MSE: 301.67017226861674, Train SBP MAE: 13.553459236036028, Val SBP MAE: 13.499561758259365, Train SBP R2: 0.17630918452256084, Val SBP R2: 0.17678971801337207, Train DBP MSE: 105.93880826976614, Val DBP MSE: 106.38185090556998, Train DBP MAE: 8.121394917498316, Val DBP MAE: 8.0892755657741, Train DBP R2: 0.15885164664800633, Val DBP R2: 0.1594450595767326\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 405.088629901995, Val Loss: 405.6446583484601, Train SBP MSE: 299.7311424161339, Val SBP MSE: 299.81802850741644, Train SBP MAE: 13.506465427316938, Val SBP MAE: 13.588459754180908, Train SBP R2: 0.18140868911305696, Val SBP R2: 0.18184392597987864, Train DBP MSE: 105.35748738276534, Val DBP MSE: 105.84159076684193, Train DBP MAE: 8.097042256842341, Val DBP MAE: 8.143060435049874, Train DBP R2: 0.163467302750392, Val DBP R2: 0.16371381712189614\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 402.5240133178711, Val Loss: 409.75894684591066, Train SBP MSE: 297.7793730409248, Val SBP MSE: 302.5123922611326, Train SBP MAE: 13.457628028787886, Val SBP MAE: 13.683393315614973, Train SBP R2: 0.1867391377228419, Val SBP R2: 0.17449143259681976, Train DBP MSE: 104.74464017469025, Val DBP MSE: 107.25727395164519, Train DBP MAE: 8.071353148525102, Val DBP MAE: 8.202593032809666, Train DBP R2: 0.168333276120756, Val DBP R2: 0.15252807928286571\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 400.091721875, Val Loss: 399.48964904561996, Train SBP MSE: 295.92590155267953, Val SBP MSE: 295.2381587652567, Train SBP MAE: 13.408373722730364, Val SBP MAE: 13.355451599884033, Train SBP R2: 0.19180112642052538, Val SBP R2: 0.19434166758141913, Train DBP MSE: 104.16582017091348, Val DBP MSE: 104.27016309602845, Train DBP MAE: 8.045933012761388, Val DBP MAE: 8.036543626921517, Train DBP R2: 0.1729290753468925, Val DBP R2: 0.17613013890024687\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 397.3920167724609, Val Loss: 399.18170590723236, Train SBP MSE: 293.8632356910157, Val SBP MSE: 294.95189602347574, Train SBP MAE: 13.357626636069162, Val SBP MAE: 13.299848435156687, Train SBP R2: 0.19743444279202482, Val SBP R2: 0.19512283341764203, Train DBP MSE: 103.52878076236388, Val DBP MSE: 104.24854810722424, Train DBP MAE: 8.018884666780064, Val DBP MAE: 8.015700326592581, Train DBP R2: 0.17798713346811745, Val DBP R2: 0.17630092541572795\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.sgd.SGD'>, 1e-05), Train Loss: 394.88214736676895, Val Loss: 395.57355569703486, Train SBP MSE: 291.9792871528335, Val SBP MSE: 292.40169897591375, Train SBP MAE: 13.306560786942073, Val SBP MAE: 13.203885823386056, Train SBP R2: 0.2025796669121569, Val SBP R2: 0.2020819186160807, Train DBP MSE: 102.90286042099771, Val DBP MSE: 103.18949260988857, Train DBP MAE: 7.991815322988374, Val DBP MAE: 7.970063674191066, Train DBP R2: 0.18295690680301335, Val DBP R2: 0.1846688408344782\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hyp4)):\n",
    "    print(hyp4[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 444.59170714285716, Val Loss: 410.8250228072869, Train SBP MSE: 328.80103265258043, Val SBP MSE: 303.6714136039881, Train SBP MAE: 13.96843563375942, Val SBP MAE: 13.671253119604929, Train SBP R2: 0.10201633980904434, Val SBP R2: 0.17132864630175626, Train DBP MSE: 114.76387699949808, Val DBP MSE: 107.17719885887253, Train DBP MAE: 8.349716715528816, Val DBP MAE: 8.24754889428275, Train DBP R2: 0.08878108278693742, Val DBP R2: 0.15316077662984695\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 373.4667152709961, Val Loss: 349.1616490449504, Train SBP MSE: 274.3502794182269, Val SBP MSE: 257.32715464660987, Train SBP MAE: 12.819070884650094, Val SBP MAE: 12.300032640021188, Train SBP R2: 0.25072599042989263, Val SBP R2: 0.29779481363232596, Train DBP MSE: 97.33871658744036, Val DBP MSE: 91.8472402187216, Train DBP MAE: 7.717933222787721, Val DBP MAE: 7.436812934820993, Train DBP R2: 0.2271359050365256, Val DBP R2: 0.2742873819838111\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 342.51007596958704, Val Loss: 352.9637489807017, Train SBP MSE: 250.0220653237024, Val SBP MSE: 257.6358143223869, Train SBP MAE: 12.156466937923431, Val SBP MAE: 12.296623605455672, Train SBP R2: 0.3171684178221257, Val SBP R2: 0.2969525300985464, Train DBP MSE: 90.17149260605758, Val DBP MSE: 95.35416962202211, Train DBP MAE: 7.363870205960955, Val DBP MAE: 7.550875481278556, Train DBP R2: 0.2840432721148237, Val DBP R2: 0.24657807996878545\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 325.44710466657364, Val Loss: 318.5035022965733, Train SBP MSE: 236.3292193073142, Val SBP MSE: 233.43113362363636, Train SBP MAE: 11.759672317218781, Val SBP MAE: 11.69609828540257, Train SBP R2: 0.3545647480131553, Val SBP R2: 0.3630032830568879, Train DBP MSE: 86.41996169585934, Val DBP MSE: 85.0851138024003, Train DBP MAE: 7.172537737805503, Val DBP MAE: 7.126205462673732, Train DBP R2: 0.3138302227064037, Val DBP R2: 0.32771697282681034\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 313.69576602608817, Val Loss: 314.1963089589009, Train SBP MSE: 226.97096675633267, Val SBP MSE: 229.94855871700992, Train SBP MAE: 11.480237603105817, Val SBP MAE: 11.506841019821167, Train SBP R2: 0.3801229337978127, Val SBP R2: 0.3725066802584208, Train DBP MSE: 83.68718107228426, Val DBP MSE: 84.25833451264293, Train DBP MAE: 7.031582614483152, Val DBP MAE: 7.085984789262499, Train DBP R2: 0.3355283516464517, Val DBP R2: 0.33424960419888594\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 305.29265649239676, Val Loss: 302.6623534528603, Train SBP MSE: 220.15694765642857, Val SBP MSE: 219.55574282001857, Train SBP MAE: 11.277250036866324, Val SBP MAE: 11.292718059158325, Train SBP R2: 0.3987326010563952, Val SBP R2: 0.4008670343526244, Train DBP MSE: 81.76682347388943, Val DBP MSE: 83.11756307199863, Train DBP MAE: 6.935506250752722, Val DBP MAE: 7.045450569289072, Train DBP R2: 0.3507758861252567, Val DBP R2: 0.34326318181729454\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 298.15876094098775, Val Loss: 306.171067121042, Train SBP MSE: 214.61515730751162, Val SBP MSE: 224.94144322573118, Train SBP MAE: 11.116413844994137, Val SBP MAE: 11.280080936840603, Train SBP R2: 0.41386770310088794, Val SBP R2: 0.38617030806927677, Train DBP MSE: 79.87126237640653, Val DBP MSE: 81.24384902206856, Train DBP MAE: 6.839990846306937, Val DBP MAE: 6.840646795981271, Train DBP R2: 0.36582653774072227, Val DBP R2: 0.3580679590250838\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 292.4648682032994, Val Loss: 328.311120160537, Train SBP MSE: 210.13100474019302, Val SBP MSE: 242.66039907912963, Train SBP MAE: 10.974012815618515, Val SBP MAE: 11.733633092607771, Train SBP R2: 0.42611430616892065, Val SBP R2: 0.3378180744530326, Train DBP MSE: 78.39576379703901, Val DBP MSE: 85.66023682867711, Train DBP MAE: 6.760332582415853, Val DBP MAE: 7.0935141501562935, Train DBP R2: 0.3775419158979676, Val DBP R2: 0.32317275314109273\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 287.7879553615025, Val Loss: 320.8997493862452, Train SBP MSE: 206.42252224617565, Val SBP MSE: 235.99234870842403, Train SBP MAE: 10.869317501708439, Val SBP MAE: 11.576773951067244, Train SBP R2: 0.4362424881179432, Val SBP R2: 0.35601413137403914, Train DBP MSE: 77.18481436556404, Val DBP MSE: 84.92406704751313, Train DBP MAE: 6.700062732533046, Val DBP MAE: 7.05171790328707, Train DBP R2: 0.3871567882654564, Val DBP R2: 0.3289894515842978\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 283.28179235927036, Val Loss: 289.8912650915561, Train SBP MSE: 202.8077848668485, Val SBP MSE: 212.47033847919298, Train SBP MAE: 10.756563180051531, Val SBP MAE: 10.944976571764265, Train SBP R2: 0.44611464416420166, Val SBP R2: 0.420201984379459, Train DBP MSE: 76.07672591321757, Val DBP MSE: 77.43813844449188, Train DBP MAE: 6.644238471354757, Val DBP MAE: 6.696161765970502, Train DBP R2: 0.3959549500749243, Val DBP R2: 0.38813802079382176\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 279.0067183872768, Val Loss: 290.84596540461513, Train SBP MSE: 199.3462368198193, Val SBP MSE: 213.1277882287837, Train SBP MAE: 10.651404253680365, Val SBP MAE: 11.11221681540353, Train SBP R2: 0.4555684270800314, Val SBP R2: 0.41840790779017434, Train DBP MSE: 75.02878657384126, Val DBP MSE: 77.72736351024398, Train DBP MAE: 6.593498218904223, Val DBP MAE: 6.723368254865919, Train DBP R2: 0.40427553121157944, Val DBP R2: 0.3858527667223546\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 274.94038232160295, Val Loss: 294.21132016922917, Train SBP MSE: 196.11968598313908, Val SBP MSE: 216.03711090253506, Train SBP MAE: 10.557627909237997, Val SBP MAE: 11.04023126247951, Train SBP R2: 0.4643804125739326, Val SBP R2: 0.410468825445247, Train DBP MSE: 73.96972807812301, Val DBP MSE: 78.1792878823813, Train DBP MAE: 6.542482249144145, Val DBP MAE: 6.745364383084433, Train DBP R2: 0.4126843978424787, Val DBP R2: 0.38228197658790863\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 271.8185816807338, Val Loss: 319.7531804463109, Train SBP MSE: 193.56444129415618, Val SBP MSE: 236.6064319186915, Train SBP MAE: 10.48473617164748, Val SBP MAE: 11.552396922193255, Train SBP R2: 0.47135900372976003, Val SBP R2: 0.3543383952252316, Train DBP MSE: 73.20991939078444, Val DBP MSE: 83.15241006799224, Train DBP MAE: 6.508071068780763, Val DBP MAE: 6.992523526859284, Train DBP R2: 0.41871723733402666, Val DBP R2: 0.3429878452406888\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 268.101561516462, Val Loss: 308.07339938162016, Train SBP MSE: 190.65047450915492, Val SBP MSE: 226.13791643085304, Train SBP MAE: 10.3920711562906, Val SBP MAE: 11.328458277784074, Train SBP R2: 0.47931729552148716, Val SBP R2: 0.3829053215538025, Train DBP MSE: 72.21216409590173, Val DBP MSE: 81.95399211960232, Train DBP MAE: 6.457359968791689, Val DBP MAE: 6.91288803799493, Train DBP R2: 0.4266393598974757, Val DBP R2: 0.3524569052225951\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 265.06690601021904, Val Loss: 286.658243524527, Train SBP MSE: 188.20198243015463, Val SBP MSE: 206.75316065185734, Train SBP MAE: 10.319748535646712, Val SBP MAE: 10.910249484089443, Train SBP R2: 0.4860043361956339, Val SBP R2: 0.43580326022325666, Train DBP MSE: 71.48081858892158, Val DBP MSE: 79.9115463973951, Train DBP MAE: 6.4212393646819255, Val DBP MAE: 6.891429389994485, Train DBP R2: 0.4324462032910814, Val DBP R2: 0.3685948820272247\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 262.6003149649484, Val Loss: 284.5043363623471, Train SBP MSE: 186.10965902185177, Val SBP MSE: 208.2238130730959, Train SBP MAE: 10.258229890516827, Val SBP MAE: 10.819827504866463, Train SBP R2: 0.4917186498561882, Val SBP R2: 0.43179008190573287, Train DBP MSE: 70.93102939031003, Val DBP MSE: 76.28611511161868, Train DBP MAE: 6.398370210402352, Val DBP MAE: 6.636859373378754, Train DBP R2: 0.43681149950930187, Val DBP R2: 0.3972405029906111\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 259.8903182983398, Val Loss: 271.12024477412973, Train SBP MSE: 183.8866202207944, Val SBP MSE: 195.67983503496177, Train SBP MAE: 10.192404682023184, Val SBP MAE: 10.439124420547486, Train SBP R2: 0.49778995840171003, Val SBP R2: 0.46602061792575267, Train DBP MSE: 70.27998873806301, Val DBP MSE: 75.4537434329517, Train DBP MAE: 6.3681943873814175, Val DBP MAE: 6.575639719104767, Train DBP R2: 0.4419807267410103, Val DBP R2: 0.40381732150632765\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 258.1287813206264, Val Loss: 265.94990954146306, Train SBP MSE: 182.44523821915004, Val SBP MSE: 193.5289449666056, Train SBP MAE: 10.145635540035792, Val SBP MAE: 10.426043487085614, Train SBP R2: 0.5017264955686647, Val SBP R2: 0.4718900574078805, Train DBP MSE: 69.78257598290713, Val DBP MSE: 72.42178119289635, Train DBP MAE: 6.342940144572939, Val DBP MAE: 6.449651914487566, Train DBP R2: 0.44593015685797177, Val DBP R2: 0.42777376537679124\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 255.67584368460518, Val Loss: 335.01349243080375, Train SBP MSE: 180.47563368712062, Val SBP MSE: 249.5892473953228, Train SBP MAE: 10.094245477363042, Val SBP MAE: 11.97127156325749, Train SBP R2: 0.507105653512701, Val SBP R2: 0.318910341105312, Train DBP MSE: 69.15488651212326, Val DBP MSE: 85.44792313727113, Train DBP MAE: 6.312676671522004, Val DBP MAE: 7.1090703931535995, Train DBP R2: 0.4509139769838483, Val DBP R2: 0.3248503073546325\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 253.29515173165458, Val Loss: 297.27888156814157, Train SBP MSE: 178.5029752213351, Val SBP MSE: 219.22353903290815, Train SBP MAE: 10.034402878267425, Val SBP MAE: 11.244290526362828, Train SBP R2: 0.5124931520102635, Val SBP R2: 0.40177356604983394, Train DBP MSE: 68.59320722473718, Val DBP MSE: 78.05607133333413, Train DBP MAE: 6.287253512689046, Val DBP MAE: 6.7488280289513725, Train DBP R2: 0.45537367985773447, Val DBP R2: 0.3832555475322179\n",
      "Epoch: 20, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 251.54776271362306, Val Loss: 332.19343772623176, Train SBP MSE: 177.12332923640454, Val SBP MSE: 245.26006440677665, Train SBP MAE: 9.98369860660008, Val SBP MAE: 11.891059240068708, Train SBP R2: 0.5162610828507507, Val SBP R2: 0.3307239981267276, Train DBP MSE: 68.06746720650288, Val DBP MSE: 86.9509376668346, Train DBP MAE: 6.2592826990945, Val DBP MAE: 7.2242232871328085, Train DBP R2: 0.45954802689685637, Val DBP R2: 0.31297453834330036\n",
      "Epoch: 21, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 249.5275043709891, Val Loss: 268.2952313118051, Train SBP MSE: 175.43719460544003, Val SBP MSE: 195.80894777936382, Train SBP MAE: 9.945281872660773, Val SBP MAE: 10.431238216645378, Train SBP R2: 0.520866060320782, Val SBP R2: 0.4656682896265112, Train DBP MSE: 67.60498091411667, Val DBP MSE: 72.50187514136105, Train DBP MAE: 6.236626672029495, Val DBP MAE: 6.417315581539699, Train DBP R2: 0.46322014280642876, Val DBP R2: 0.4271409190453266\n",
      "Epoch: 22, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 248.26082931780135, Val Loss: 265.7370159107327, Train SBP MSE: 174.3319026855435, Val SBP MSE: 193.41410784496745, Train SBP MAE: 9.903456028100422, Val SBP MAE: 10.477018837356567, Train SBP R2: 0.5238847068128598, Val SBP R2: 0.4722034297859825, Train DBP MSE: 67.29313280578093, Val DBP MSE: 72.33101899180632, Train DBP MAE: 6.222743865609169, Val DBP MAE: 6.4617101428031924, Train DBP R2: 0.46569619975955756, Val DBP R2: 0.4284909047749169\n",
      "Epoch: 23, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 246.25393120640345, Val Loss: 299.7907689249712, Train SBP MSE: 172.7267129430605, Val SBP MSE: 220.9968757296283, Train SBP MAE: 9.856018100445612, Val SBP MAE: 11.171383322416034, Train SBP R2: 0.5282686168895016, Val SBP R2: 0.3969344101227297, Train DBP MSE: 66.78435591549648, Val DBP MSE: 78.8142085724112, Train DBP MAE: 6.193163131598064, Val DBP MAE: 6.748192887360709, Train DBP R2: 0.4697358604889529, Val DBP R2: 0.3772652776092895\n",
      "Epoch: 24, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 244.58210260532925, Val Loss: 258.58134738008545, Train SBP MSE: 171.3375254624612, Val SBP MSE: 186.9867505217332, Train SBP MAE: 9.818815671634674, Val SBP MAE: 10.21860425049918, Train SBP R2: 0.5320626063683549, Val SBP R2: 0.48974267337343647, Train DBP MSE: 66.36129860377422, Val DBP MSE: 71.6105380228316, Train DBP MAE: 6.17678934981823, Val DBP MAE: 6.409545986992972, Train DBP R2: 0.47309491244489466, Val DBP R2: 0.43418364120314656\n",
      "Epoch: 25, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 243.44401530587334, Val Loss: 303.71238712680406, Train SBP MSE: 170.32184466273512, Val SBP MSE: 222.41912915507234, Train SBP MAE: 9.784443103654043, Val SBP MAE: 11.198741812433516, Train SBP R2: 0.5348365172492475, Val SBP R2: 0.3930533050250282, Train DBP MSE: 66.12859865694519, Val DBP MSE: 81.29997589816986, Train DBP MAE: 6.162165998826708, Val DBP MAE: 6.8870317989758085, Train DBP R2: 0.4749425373171883, Val DBP R2: 0.3576244837274096\n",
      "Epoch: 26, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 241.77317791486468, Val Loss: 257.5524999907945, Train SBP MSE: 168.9745223752356, Val SBP MSE: 186.69902751183602, Train SBP MAE: 9.747525194031851, Val SBP MAE: 10.207765054484776, Train SBP R2: 0.5385161693154991, Val SBP R2: 0.4905278240508478, Train DBP MSE: 65.6746929288229, Val DBP MSE: 70.86540420390243, Train DBP MAE: 6.142895089006424, Val DBP MAE: 6.339030299391065, Train DBP R2: 0.4785465240150075, Val DBP R2: 0.440071167199788\n",
      "Epoch: 27, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 240.48327686680386, Val Loss: 253.99970115298981, Train SBP MSE: 167.93897657764808, Val SBP MSE: 183.65242629350095, Train SBP MAE: 9.715987577186311, Val SBP MAE: 10.073141069412232, Train SBP R2: 0.54134433319963, Val SBP R2: 0.4988415178747544, Train DBP MSE: 65.32209085325583, Val DBP MSE: 70.36389175386964, Train DBP MAE: 6.126569013810157, Val DBP MAE: 6.298806225763048, Train DBP R2: 0.4813461652427671, Val DBP R2: 0.4440337676243006\n",
      "Epoch: 28, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 238.92126194109235, Val Loss: 254.76778135003295, Train SBP MSE: 166.69297439174562, Val SBP MSE: 184.89185816139107, Train SBP MAE: 9.675629915434973, Val SBP MAE: 10.170435275486538, Train SBP R2: 0.544747271427883, Val SBP R2: 0.49545930394953897, Train DBP MSE: 64.90055578351203, Val DBP MSE: 69.88520589266851, Train DBP MAE: 6.106590302109718, Val DBP MAE: 6.3054024107251845, Train DBP R2: 0.484693130680515, Val DBP R2: 0.44781600831778623\n",
      "Epoch: 29, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.001), Train Loss: 238.0329444292341, Val Loss: 279.8400269426419, Train SBP MSE: 165.89144600199347, Val SBP MSE: 203.82709335138628, Train SBP MAE: 9.657106334761211, Val SBP MAE: 10.75795337538038, Train SBP R2: 0.5469363138143074, Val SBP R2: 0.4437880360113906, Train DBP MSE: 64.70130098547578, Val DBP MSE: 76.02414743381445, Train DBP MAE: 6.09627451293809, Val DBP MAE: 6.672386674090794, Train DBP R2: 0.4862752028975149, Val DBP R2: 0.399310388257084\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 461.0786571986607, Val Loss: 393.0114270337539, Train SBP MSE: 341.9178250001887, Val SBP MSE: 290.1044561884858, Train SBP MAE: 14.098685749833166, Val SBP MAE: 13.187037434114728, Train SBP R2: 0.06619326131307268, Val SBP R2: 0.20835073156702233, Train DBP MSE: 118.26146409843633, Val DBP MSE: 102.92616039939239, Train DBP MAE: 8.413675161252845, Val DBP MAE: 8.02219727671487, Train DBP R2: 0.06101043219130764, Val DBP R2: 0.1867495076833905\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 382.22456459786554, Val Loss: 367.6603168020301, Train SBP MSE: 281.6013423967158, Val SBP MSE: 269.81990735733467, Train SBP MAE: 13.007185985810416, Val SBP MAE: 12.770622252873013, Train SBP R2: 0.23092271906797246, Val SBP R2: 0.26370406344497366, Train DBP MSE: 99.30611591662468, Val DBP MSE: 97.84750238227453, Train DBP MAE: 7.811160724888529, Val DBP MAE: 7.780484071922302, Train DBP R2: 0.2115148617837529, Val DBP R2: 0.22687750931778516\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 354.70138164236886, Val Loss: 342.9451830652994, Train SBP MSE: 260.6810326055453, Val SBP MSE: 253.33435293692227, Train SBP MAE: 12.442369136169978, Val SBP MAE: 12.124499390193394, Train SBP R2: 0.2880578691830691, Val SBP R2: 0.30869053924096135, Train DBP MSE: 92.38858731241247, Val DBP MSE: 89.63596761223263, Train DBP MAE: 7.472723893659455, Val DBP MAE: 7.344490162413461, Train DBP R2: 0.26643966120080453, Val DBP R2: 0.29175931068391237\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 335.4687601928711, Val Loss: 346.7237656225452, Train SBP MSE: 245.606663537353, Val SBP MSE: 257.533088478851, Train SBP MAE: 12.024460161563328, Val SBP MAE: 12.459203495298112, Train SBP R2: 0.329227256644293, Val SBP R2: 0.2972328527104523, Train DBP MSE: 88.02067604367959, Val DBP MSE: 89.21838432672867, Train DBP MAE: 7.262451108200209, Val DBP MAE: 7.367650491632734, Train DBP R2: 0.30112063818448453, Val DBP R2: 0.29505876158348465\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 322.1416209228516, Val Loss: 312.3741364696998, Train SBP MSE: 234.9363214332792, Val SBP MSE: 229.55624243798007, Train SBP MAE: 11.717680206693922, Val SBP MAE: 11.494531547546387, Train SBP R2: 0.35836887089290215, Val SBP R2: 0.37357724945742166, Train DBP MSE: 85.20210013182434, Val DBP MSE: 82.84178942076838, Train DBP MAE: 7.1219750504629955, Val DBP MAE: 6.98057869744982, Train DBP R2: 0.32349997702901334, Val DBP R2: 0.34544215222443586\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 312.00428288748606, Val Loss: 320.70232081718376, Train SBP MSE: 226.87424927872294, Val SBP MSE: 236.35934136859487, Train SBP MAE: 11.487336302512032, Val SBP MAE: 11.803205032076155, Train SBP R2: 0.38038707747719125, Val SBP R2: 0.3550126663336133, Train DBP MSE: 83.00197152069376, Val DBP MSE: 84.35783640287795, Train DBP MAE: 7.016692273739406, Val DBP MAE: 7.087592115483965, Train DBP R2: 0.3409688780733088, Val DBP R2: 0.33346340989312284\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 303.32047387608117, Val Loss: 299.1565720873733, Train SBP MSE: 220.0343274171923, Val SBP MSE: 218.79553553813201, Train SBP MAE: 11.29237536900384, Val SBP MAE: 11.288606648799352, Train SBP R2: 0.399067487386753, Val SBP R2: 0.402941520027439, Train DBP MSE: 81.0187930848818, Val DBP MSE: 80.3837366474602, Train DBP MAE: 6.916612108962877, Val DBP MAE: 6.867216499274118, Train DBP R2: 0.35671520657115785, Val DBP R2: 0.364863965107343\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 296.6040224583217, Val Loss: 299.454642245277, Train SBP MSE: 214.60006995920338, Val SBP MSE: 218.48544276502517, Train SBP MAE: 11.13346963766643, Val SBP MAE: 11.295621672167098, Train SBP R2: 0.4139089079357604, Val SBP R2: 0.4037877142576196, Train DBP MSE: 79.5983258458711, Val DBP MSE: 80.98835296163402, Train DBP MAE: 6.8460159425531115, Val DBP MAE: 6.914681129755293, Train DBP R2: 0.3679936388907077, Val DBP R2: 0.36008671009990356\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 290.8085433105469, Val Loss: 298.86177780597694, Train SBP MSE: 210.03890659837688, Val SBP MSE: 218.53763289208172, Train SBP MAE: 11.000379209940775, Val SBP MAE: 11.160753105272565, Train SBP R2: 0.42636583404831185, Val SBP R2: 0.40364529563900686, Train DBP MSE: 78.23400679138716, Val DBP MSE: 80.33463367067723, Train DBP MAE: 6.780615980587687, Val DBP MAE: 6.838711290168762, Train DBP R2: 0.37882625769083267, Val DBP R2: 0.3652519424678896\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 285.50059422956195, Val Loss: 316.6861442621709, Train SBP MSE: 205.75778739000182, Val SBP MSE: 232.94381696057252, Train SBP MAE: 10.880790366091047, Val SBP MAE: 11.724111704036167, Train SBP R2: 0.4380579356984686, Val SBP R2: 0.36433309330826513, Train DBP MSE: 77.0763687319349, Val DBP MSE: 83.76832284790385, Train DBP MAE: 6.721809612154961, Val DBP MAE: 7.065554294885908, Train DBP R2: 0.3880178406752879, Val DBP R2: 0.33812133346619366\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 280.73331128627234, Val Loss: 283.6910582966081, Train SBP MSE: 202.0280672137551, Val SBP MSE: 206.4789765577296, Train SBP MAE: 10.773821843596867, Val SBP MAE: 10.908441372244699, Train SBP R2: 0.44824411956880017, Val SBP R2: 0.4365514653366285, Train DBP MSE: 75.91542263644546, Val DBP MSE: 77.22274907927276, Train DBP MAE: 6.664477934224265, Val DBP MAE: 6.70052932819639, Train DBP R2: 0.39723568928525843, Val DBP R2: 0.3898398768294934\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 276.63905139421735, Val Loss: 279.08768297854465, Train SBP MSE: 198.85989661629347, Val SBP MSE: 203.3123005702813, Train SBP MAE: 10.675336597320012, Val SBP MAE: 10.761701419339861, Train SBP R2: 0.456896663650753, Val SBP R2: 0.4451928242518427, Train DBP MSE: 74.87825500281262, Val DBP MSE: 75.78467347969236, Train DBP MAE: 6.611283324507305, Val DBP MAE: 6.623525658089774, Train DBP R2: 0.40547074366645075, Val DBP R2: 0.4012025438600044\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 273.0553136657715, Val Loss: 304.8524980213786, Train SBP MSE: 196.00454777209978, Val SBP MSE: 222.89256020484405, Train SBP MAE: 10.596540924521856, Val SBP MAE: 11.343544167055402, Train SBP R2: 0.46469486484722, Val SBP R2: 0.3917613864205042, Train DBP MSE: 74.04375115046562, Val DBP MSE: 81.96914335040101, Train DBP MAE: 6.5690473050832745, Val DBP MAE: 6.966821964427403, Train DBP R2: 0.41209665868977374, Val DBP R2: 0.3523371907995716\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 269.96689535348077, Val Loss: 275.92916016517654, Train SBP MSE: 193.55863092088254, Val SBP MSE: 200.9094867138518, Train SBP MAE: 10.52090121025358, Val SBP MAE: 10.702500379071918, Train SBP R2: 0.471374872354677, Val SBP R2: 0.4517497239858721, Train DBP MSE: 73.31134376361733, Val DBP MSE: 75.03325830514814, Train DBP MAE: 6.52986511625903, Val DBP MAE: 6.575919794464111, Train DBP R2: 0.41791193335155297, Val DBP R2: 0.40713970073305783\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 266.94648544224333, Val Loss: 282.3145287773509, Train SBP MSE: 191.24433310291624, Val SBP MSE: 205.93815459835187, Train SBP MAE: 10.450582805606297, Val SBP MAE: 10.878687407139369, Train SBP R2: 0.47769541705790863, Val SBP R2: 0.43802728309592454, Train DBP MSE: 72.4993333082803, Val DBP MSE: 76.38346625033621, Train DBP MAE: 6.485891743281909, Val DBP MAE: 6.687739237254006, Train DBP R2: 0.4243592520307673, Val DBP R2: 0.3964713024182551\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 263.9307068272182, Val Loss: 276.69629663610374, Train SBP MSE: 188.85163595452528, Val SBP MSE: 201.21981095734637, Train SBP MAE: 10.377805568599701, Val SBP MAE: 10.639051544788906, Train SBP R2: 0.4842300770183925, Val SBP R2: 0.45090289810954054, Train DBP MSE: 71.78836464992416, Val DBP MSE: 75.49240481987609, Train DBP MAE: 6.4527928893327715, Val DBP MAE: 6.586191533361163, Train DBP R2: 0.4300043043588839, Val DBP R2: 0.4035118462818764\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 261.31737786342075, Val Loss: 276.7940042624744, Train SBP MSE: 186.79084329793832, Val SBP MSE: 200.7582466115595, Train SBP MAE: 10.320035425049918, Val SBP MAE: 10.76450342854091, Train SBP R2: 0.4898582775070812, Val SBP R2: 0.4521624343520294, Train DBP MSE: 71.14352784359853, Val DBP MSE: 76.04510025274253, Train DBP MAE: 6.423852505973407, Val DBP MAE: 6.682599333272662, Train DBP R2: 0.435124273392709, Val DBP R2: 0.39914483374458143\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 258.9654814208984, Val Loss: 266.7711997964918, Train SBP MSE: 184.8685824984856, Val SBP MSE: 193.63531076711317, Train SBP MAE: 10.266611645971025, Val SBP MAE: 10.45897892276219, Train SBP R2: 0.49510813567999645, Val SBP R2: 0.4715998019279598, Train DBP MSE: 70.61543887315138, Val DBP MSE: 73.14687722182218, Train DBP MAE: 6.394904129546029, Val DBP MAE: 6.466938835253035, Train DBP R2: 0.4393172709841474, Val DBP R2: 0.42204456397442125\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 256.2747373334612, Val Loss: 272.79448955891553, Train SBP MSE: 182.7684082772165, Val SBP MSE: 197.4962270305301, Train SBP MAE: 10.20325840716362, Val SBP MAE: 10.504479486465454, Train SBP R2: 0.5008438905802757, Val SBP R2: 0.46106397088429896, Train DBP MSE: 69.94171474985406, Val DBP MSE: 75.312009329141, Train DBP MAE: 6.362343294048309, Val DBP MAE: 6.5692187676838465, Train DBP R2: 0.44466660373746636, Val DBP R2: 0.4049372052098954\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 254.65013769880022, Val Loss: 276.45015320089226, Train SBP MSE: 181.43541748973817, Val SBP MSE: 200.91881087906754, Train SBP MAE: 10.154189585072654, Val SBP MAE: 10.677455854633877, Train SBP R2: 0.5044844020977848, Val SBP R2: 0.4517242798108023, Train DBP MSE: 69.56294395279367, Val DBP MSE: 75.54476239572779, Train DBP MAE: 6.341688870750155, Val DBP MAE: 6.632454723153796, Train DBP R2: 0.4476740231850582, Val DBP R2: 0.40309815335703914\n",
      "Epoch: 20, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 252.34198588169642, Val Loss: 269.1302847156141, Train SBP MSE: 179.61031035223718, Val SBP MSE: 195.6755671459689, Train SBP MAE: 10.098099990122659, Val SBP MAE: 10.526950808007376, Train SBP R2: 0.5094689253346857, Val SBP R2: 0.466032264321135, Train DBP MSE: 69.00852582079075, Val DBP MSE: 73.46809753705152, Train DBP MAE: 6.3163537859542025, Val DBP MAE: 6.502166496971675, Train DBP R2: 0.4520760728816644, Val DBP R2: 0.41950650583168414\n",
      "Epoch: 21, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 250.574013697161, Val Loss: 270.5668643519037, Train SBP MSE: 178.1053150769544, Val SBP MSE: 196.4183130655845, Train SBP MAE: 10.060336541931969, Val SBP MAE: 10.52707669645037, Train SBP R2: 0.5135791957768607, Val SBP R2: 0.4640054279477107, Train DBP MSE: 68.66203296691097, Val DBP MSE: 74.16307694427971, Train DBP MAE: 6.298604680987767, Val DBP MAE: 6.532115214811053, Train DBP R2: 0.45482720722279313, Val DBP R2: 0.41401526489852314\n",
      "Epoch: 22, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 249.1075743268694, Val Loss: 265.40917401078417, Train SBP MSE: 176.9961223747439, Val SBP MSE: 191.05108594765775, Train SBP MAE: 10.02568656355994, Val SBP MAE: 10.311362531770978, Train SBP R2: 0.5166084956380947, Val SBP R2: 0.47865174354466844, Train DBP MSE: 68.23011531144097, Val DBP MSE: 74.36870137717844, Train DBP MAE: 6.276177415088245, Val DBP MAE: 6.506130973543439, Train DBP R2: 0.45825660982431315, Val DBP R2: 0.41239056452460143\n",
      "Epoch: 23, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 247.30437344098772, Val Loss: 266.50244485830694, Train SBP MSE: 175.4862818252335, Val SBP MSE: 193.1992890741024, Train SBP MAE: 9.976820812715802, Val SBP MAE: 10.420546416255405, Train SBP R2: 0.5207319989373884, Val SBP R2: 0.47278963630288784, Train DBP MSE: 67.86503119825686, Val DBP MSE: 73.31706671957608, Train DBP MAE: 6.25819895668711, Val DBP MAE: 6.525022576100485, Train DBP R2: 0.4611553577492262, Val DBP R2: 0.42069984566084184\n",
      "Epoch: 24, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 245.70282380109515, Val Loss: 271.8281275315084, Train SBP MSE: 174.26797281440693, Val SBP MSE: 198.8078286092602, Train SBP MAE: 9.93110395133836, Val SBP MAE: 10.51404223398481, Train SBP R2: 0.5240593047428468, Val SBP R2: 0.45748481721006984, Train DBP MSE: 67.41167154054426, Val DBP MSE: 73.02415106292067, Train DBP MAE: 6.233710798522404, Val DBP MAE: 6.468619116769518, Train DBP R2: 0.4647550086778087, Val DBP R2: 0.4230142601989719\n",
      "Epoch: 25, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 244.00880765904017, Val Loss: 262.1155339647255, Train SBP MSE: 172.94739113851313, Val SBP MSE: 190.3830190152379, Train SBP MAE: 9.900501986285619, Val SBP MAE: 10.31153082586016, Train SBP R2: 0.5276659259183746, Val SBP R2: 0.4804747927499893, Train DBP MSE: 66.96689502051609, Val DBP MSE: 71.74316899281337, Train DBP MAE: 6.214348666596413, Val DBP MAE: 6.3940358704158236, Train DBP R2: 0.4682865099618203, Val DBP R2: 0.4331356840927719\n",
      "Epoch: 26, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 242.50709540230886, Val Loss: 268.834821265184, Train SBP MSE: 171.67444335940513, Val SBP MSE: 195.5977414632012, Train SBP MAE: 9.858917874704089, Val SBP MAE: 10.476331416484287, Train SBP R2: 0.5311424548595813, Val SBP R2: 0.4662446383247536, Train DBP MSE: 66.66129795128563, Val DBP MSE: 73.24902518748071, Train DBP MAE: 6.200470007027898, Val DBP MAE: 6.487050237628392, Train DBP R2: 0.470712934005763, Val DBP R2: 0.4212374622323706\n",
      "Epoch: 27, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 241.20455056501115, Val Loss: 264.04334872732215, Train SBP MSE: 170.67352340452993, Val SBP MSE: 191.09873203713954, Train SBP MAE: 9.829815466737747, Val SBP MAE: 10.303703396388462, Train SBP R2: 0.5338760526143873, Val SBP R2: 0.4785217248873286, Train DBP MSE: 66.29545283807082, Val DBP MSE: 72.95976577094777, Train DBP MAE: 6.1807241375139785, Val DBP MAE: 6.43552636246, Train DBP R2: 0.4736177242293693, Val DBP R2: 0.42352298771966945\n",
      "Epoch: 28, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 239.6904683140346, Val Loss: 260.57727502686885, Train SBP MSE: 169.44616746729997, Val SBP MSE: 189.314009410954, Train SBP MAE: 9.796457814284734, Val SBP MAE: 10.278622445787702, Train SBP R2: 0.5372280663473716, Val SBP R2: 0.48339195121869394, Train DBP MSE: 65.94320572099724, Val DBP MSE: 71.27276438111033, Train DBP MAE: 6.163502569736753, Val DBP MAE: 6.368832921981811, Train DBP R2: 0.47641454710607134, Val DBP R2: 0.43685249214789645\n",
      "Epoch: 29, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 0.0001, 0.0005), Train Loss: 238.77726140572685, Val Loss: 258.24069705523783, Train SBP MSE: 168.6690044499045, Val SBP MSE: 187.20298369314645, Train SBP MAE: 9.76911419439997, Val SBP MAE: 10.218069455827985, Train SBP R2: 0.5393505648240211, Val SBP R2: 0.48915260718069586, Train DBP MSE: 65.73953737437441, Val DBP MSE: 71.05329743474806, Train DBP MAE: 6.155835215262004, Val DBP MAE: 6.354016479764666, Train DBP R2: 0.4780316626578667, Val DBP R2: 0.43858656637629256\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 445.13195367257254, Val Loss: 392.0150248651313, Train SBP MSE: 329.8166611926733, Val SBP MSE: 290.58543877317607, Train SBP MAE: 13.97596884436916, Val SBP MAE: 13.158479911640713, Train SBP R2: 0.09924257165366701, Val SBP R2: 0.20703820601570289, Train DBP MSE: 114.83114564330799, Val DBP MSE: 101.45842763507554, Train DBP MAE: 8.34223892407364, Val DBP MAE: 7.862480922372001, Train DBP R2: 0.08824697342798671, Val DBP R2: 0.19834650487572858\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 370.2003395002093, Val Loss: 367.9398981613912, Train SBP MSE: 272.4712599346213, Val SBP MSE: 273.14453843413395, Train SBP MAE: 12.78218281653268, Val SBP MAE: 12.72954540209089, Train SBP R2: 0.25585775288162793, Val SBP R2: 0.25463167002386855, Train DBP MSE: 96.78819796237528, Val DBP MSE: 94.80389791119607, Train DBP MAE: 7.693116297323363, Val DBP MAE: 7.541527395956857, Train DBP R2: 0.23150699286096033, Val DBP R2: 0.25092594195062445\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 334.5898004586356, Val Loss: 327.6876570441823, Train SBP MSE: 245.1897523280363, Val SBP MSE: 241.47869617356307, Train SBP MAE: 12.008957408755165, Val SBP MAE: 11.84916458277021, Train SBP R2: 0.3303658767109535, Val SBP R2: 0.3410427551524876, Train DBP MSE: 88.01557525844503, Val DBP MSE: 86.22445025759757, Train DBP MAE: 7.261791043697085, Val DBP MAE: 7.176871439988273, Train DBP R2: 0.3011611381407423, Val DBP R2: 0.3187147334592092\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 315.3577483049665, Val Loss: 301.65326803650237, Train SBP MSE: 230.18114965355784, Val SBP MSE: 220.48341990649652, Train SBP MAE: 11.565190397753033, Val SBP MAE: 11.296167311641149, Train SBP R2: 0.37135565054241404, Val SBP R2: 0.3983355500159095, Train DBP MSE: 83.4894018795987, Val DBP MSE: 81.18014460628595, Train DBP MAE: 7.031192638005529, Val DBP MAE: 6.934426520265852, Train DBP R2: 0.3370987076375356, Val DBP R2: 0.35857130673859916\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 302.1107710536412, Val Loss: 330.1950973775749, Train SBP MSE: 219.5591618302638, Val SBP MSE: 243.5489681402812, Train SBP MAE: 11.248995619378771, Val SBP MAE: 11.839389989525932, Train SBP R2: 0.40036520512658036, Val SBP R2: 0.3353933097442968, Train DBP MSE: 80.58479487397636, Val DBP MSE: 86.64665790666047, Train DBP MAE: 6.8782528386354445, Val DBP MAE: 7.139824743352618, Train DBP R2: 0.360161128669236, Val DBP R2: 0.3153787440748984\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 292.07483212018695, Val Loss: 299.9537768529582, Train SBP MSE: 211.49375991384545, Val SBP MSE: 218.99114937307965, Train SBP MAE: 11.013700340802329, Val SBP MAE: 11.104341521508353, Train SBP R2: 0.4223925055744753, Val SBP R2: 0.40240772074918507, Train DBP MSE: 78.37301407264619, Val DBP MSE: 80.97012469006093, Train DBP MAE: 6.769228911495209, Val DBP MAE: 6.858504490511758, Train DBP R2: 0.37772254746750034, Val DBP R2: 0.3602307371458302\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 284.1594101893834, Val Loss: 287.6749799194894, Train SBP MSE: 205.10570455023225, Val SBP MSE: 208.50125786584354, Train SBP MAE: 10.821022483757565, Val SBP MAE: 10.927288541521344, Train SBP R2: 0.4398388295432356, Val SBP R2: 0.43103297886052305, Train DBP MSE: 76.61030350463531, Val DBP MSE: 79.17715340553742, Train DBP MAE: 6.6785597807543615, Val DBP MAE: 6.8700454418046135, Train DBP R2: 0.39171837313266067, Val DBP R2: 0.3743975415247186\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 277.07609019949774, Val Loss: 289.5678447604833, Train SBP MSE: 199.4184012624069, Val SBP MSE: 211.35375547967277, Train SBP MAE: 10.658247359548296, Val SBP MAE: 10.93985885407584, Train SBP R2: 0.4553713398331709, Val SBP R2: 0.4232489631343822, Train DBP MSE: 74.98086368081428, Val DBP MSE: 78.2159284802119, Train DBP MAE: 6.5995863982881815, Val DBP MAE: 6.721670448221479, Train DBP R2: 0.40465603636560077, Val DBP R2: 0.38199246822473953\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 270.7615513619559, Val Loss: 287.9745262466793, Train SBP MSE: 194.49682962355251, Val SBP MSE: 206.01499492595255, Train SBP MAE: 10.509479956545148, Val SBP MAE: 10.75554020753588, Train SBP R2: 0.468812571688486, Val SBP R2: 0.43781759797102004, Train DBP MSE: 73.36323621963156, Val DBP MSE: 81.96801599420353, Train DBP MAE: 6.517493712694304, Val DBP MAE: 6.8761064539909365, Train DBP R2: 0.4174999100841533, Val DBP R2: 0.3523460983793264\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 265.378448891776, Val Loss: 287.6419132379117, Train SBP MSE: 190.28806811046167, Val SBP MSE: 211.53506345079214, Train SBP MAE: 10.38272424659729, Val SBP MAE: 11.001635320772444, Train SBP R2: 0.4803070583021868, Val SBP R2: 0.4227542023003589, Train DBP MSE: 71.98509540392016, Val DBP MSE: 76.10491777326226, Train DBP MAE: 6.448877520356859, Val DBP MAE: 6.641935954080309, Train DBP R2: 0.4284422729137495, Val DBP R2: 0.39867219755740546\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 260.74319443620954, Val Loss: 279.11845847065314, Train SBP MSE: 186.78032566859187, Val SBP MSE: 204.34857321146407, Train SBP MAE: 10.274881603540694, Val SBP MAE: 10.868859417070661, Train SBP R2: 0.4898870020497653, Val SBP R2: 0.44236499978796595, Train DBP MSE: 70.66555375944739, Val DBP MSE: 74.76787880989589, Train DBP MAE: 6.381542787075043, Val DBP MAE: 6.6053511962618146, Train DBP R2: 0.43891936152325395, Val DBP R2: 0.4092365437934341\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 256.57622529035297, Val Loss: 266.5038972781389, Train SBP MSE: 183.52068612305456, Val SBP MSE: 194.20871466809302, Train SBP MAE: 10.182710452583859, Val SBP MAE: 10.421014467021397, Train SBP R2: 0.4987893556293468, Val SBP R2: 0.47003507319303683, Train DBP MSE: 69.57677184388339, Val DBP MSE: 72.29801134791911, Train DBP MAE: 6.332037581637928, Val DBP MAE: 6.431067183807918, Train DBP R2: 0.4475642304848154, Val DBP R2: 0.4287517080783464\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 252.69403857945034, Val Loss: 262.9112379816812, Train SBP MSE: 180.62828660868658, Val SBP MSE: 191.14965932873508, Train SBP MAE: 10.087560116856439, Val SBP MAE: 10.383254608535767, Train SBP R2: 0.5066887453657261, Val SBP R2: 0.4783827523473525, Train DBP MSE: 68.41103186220877, Val DBP MSE: 71.7669175381868, Train DBP MAE: 6.268704807584626, Val DBP MAE: 6.429610726683481, Train DBP R2: 0.45682014228934753, Val DBP R2: 0.4329480397063322\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 248.53708485456195, Val Loss: 276.83504260131167, Train SBP MSE: 177.32429207555063, Val SBP MSE: 200.47431470535315, Train SBP MAE: 9.989089695215226, Val SBP MAE: 10.574111213411603, Train SBP R2: 0.5157122361990145, Val SBP R2: 0.45293723970588795, Train DBP MSE: 67.39527383633146, Val DBP MSE: 76.37553518526371, Train DBP MAE: 6.220209747896876, Val DBP MAE: 6.606150048610142, Train DBP R2: 0.46488520555393575, Val DBP R2: 0.3965339681443424\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 245.39549391915457, Val Loss: 315.0100942329253, Train SBP MSE: 174.89428162681887, Val SBP MSE: 233.27295446666258, Train SBP MAE: 9.912785294532776, Val SBP MAE: 11.532184602791922, Train SBP R2: 0.522348801964792, Val SBP R2: 0.3634349290079527, Train DBP MSE: 66.52219679761807, Val DBP MSE: 81.76065168707457, Train DBP MAE: 6.174761407743182, Val DBP MAE: 6.9831957481111795, Train DBP R2: 0.47181738957089336, Val DBP R2: 0.353984546021861\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 242.564818636649, Val Loss: 260.4699441815643, Train SBP MSE: 172.61281871317303, Val SBP MSE: 190.60716018284808, Train SBP MAE: 9.844239343711308, Val SBP MAE: 10.393298034558978, Train SBP R2: 0.5285796717441771, Val SBP R2: 0.4798631468838912, Train DBP MSE: 65.82771642925788, Val DBP MSE: 69.86976978942685, Train DBP MAE: 6.140748309050288, Val DBP MAE: 6.283542557116917, Train DBP R2: 0.4773315257767107, Val DBP R2: 0.44793797360350185\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 239.25118101109095, Val Loss: 274.01235741540324, Train SBP MSE: 170.0673270860292, Val SBP MSE: 200.71195222729608, Train SBP MAE: 9.769936372191566, Val SBP MAE: 10.623326764351981, Train SBP R2: 0.5355316264563856, Val SBP R2: 0.45228876441919286, Train DBP MSE: 64.91668663160254, Val DBP MSE: 73.31650282966051, Train DBP MAE: 6.09652802673408, Val DBP MAE: 6.52024100856781, Train DBP R2: 0.48456505262742844, Val DBP R2: 0.42070430112434776\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 236.8471407182966, Val Loss: 251.80908673860037, Train SBP MSE: 168.11940912292425, Val SBP MSE: 183.0430558498874, Train SBP MAE: 9.70055057811737, Val SBP MAE: 10.042105264609201, Train SBP R2: 0.5408515565312673, Val SBP R2: 0.5005043936272657, Train DBP MSE: 64.31017414682607, Val DBP MSE: 68.7648562955987, Train DBP MAE: 6.062313901298387, Val DBP MAE: 6.228636280291421, Train DBP R2: 0.4893807286406796, Val DBP R2: 0.4566682268193627\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 234.42487456490653, Val Loss: 298.8947780267412, Train SBP MSE: 166.25974083009095, Val SBP MSE: 218.31952777674692, Train SBP MAE: 9.652412739283697, Val SBP MAE: 11.081248909378052, Train SBP R2: 0.545930469230742, Val SBP R2: 0.4042404700712262, Train DBP MSE: 63.61946947300949, Val DBP MSE: 80.58338287251955, Train DBP MAE: 6.026321570600782, Val DBP MAE: 6.846119766766685, Train DBP R2: 0.49486488603797574, Val DBP R2: 0.3632865003482513\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 231.72864086826868, Val Loss: 264.7331347421929, Train SBP MSE: 164.1569395718712, Val SBP MSE: 193.71156329139583, Train SBP MAE: 9.585503227097648, Val SBP MAE: 10.415071080071586, Train SBP R2: 0.5516733987929662, Val SBP R2: 0.4713917208255264, Train DBP MSE: 62.8904693676805, Val DBP MSE: 71.03688357641923, Train DBP MAE: 5.98674575984478, Val DBP MAE: 6.3731645739010405, Train DBP R2: 0.5006531070705309, Val DBP R2: 0.4387162571984794\n",
      "Epoch: 20, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 229.56642706996374, Val Loss: 264.9051188655484, Train SBP MSE: 162.37561239998917, Val SBP MSE: 193.95657954707784, Train SBP MAE: 9.527720800835745, Val SBP MAE: 10.462780709511893, Train SBP R2: 0.5565383552102241, Val SBP R2: 0.4707231101391782, Train DBP MSE: 62.37727163662143, Val DBP MSE: 70.96516094963249, Train DBP MAE: 5.962342754633086, Val DBP MAE: 6.3730045154980255, Train DBP R2: 0.5047278690342969, Val DBP R2: 0.43928295920424953\n",
      "Epoch: 21, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 227.0750823512486, Val Loss: 263.4471148468241, Train SBP MSE: 160.37796900912824, Val SBP MSE: 192.96545799848226, Train SBP MAE: 9.464911647013256, Val SBP MAE: 10.454044880131313, Train SBP R2: 0.5619940896688715, Val SBP R2: 0.4734277243984093, Train DBP MSE: 61.74784132418273, Val DBP MSE: 70.49753145893261, Train DBP MAE: 5.929561110384124, Val DBP MAE: 6.351587328393118, Train DBP R2: 0.5097255113478617, Val DBP R2: 0.44297784019522146\n",
      "Epoch: 22, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 225.04634278564453, Val Loss: 263.0329953251199, Train SBP MSE: 158.72167737935743, Val SBP MSE: 192.27839896306025, Train SBP MAE: 9.41595880766596, Val SBP MAE: 10.43969919934954, Train SBP R2: 0.5665175633576442, Val SBP R2: 0.47530260005495106, Train DBP MSE: 61.248025047477825, Val DBP MSE: 70.7660294059969, Train DBP MAE: 5.9035396867343355, Val DBP MAE: 6.380704846014296, Train DBP R2: 0.5136940252946893, Val DBP R2: 0.4408563573109019\n",
      "Epoch: 23, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 223.01123425641742, Val Loss: 250.10308108425664, Train SBP MSE: 157.17535191730954, Val SBP MSE: 182.15650333635844, Train SBP MAE: 9.370009015880312, Val SBP MAE: 10.056280356679643, Train SBP R2: 0.5707407100644961, Val SBP R2: 0.502923655495848, Train DBP MSE: 60.63716628207342, Val DBP MSE: 67.95376332530361, Train DBP MAE: 5.875503771362986, Val DBP MAE: 6.192513720485143, Train DBP R2: 0.5185442105388176, Val DBP R2: 0.4630769158722473\n",
      "Epoch: 24, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 221.21242480991907, Val Loss: 264.7818039784266, Train SBP MSE: 155.72174277394592, Val SBP MSE: 192.98859334563332, Train SBP MAE: 9.324986539684023, Val SBP MAE: 10.372007681901115, Train SBP R2: 0.5747106405982116, Val SBP R2: 0.4733645916879101, Train DBP MSE: 60.171378308811995, Val DBP MSE: 71.80790903167856, Train DBP MAE: 5.853401591706276, Val DBP MAE: 6.407488465513502, Train DBP R2: 0.522242541614266, Val DBP R2: 0.4326241536103813\n",
      "Epoch: 25, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 219.37438961791992, Val Loss: 261.56321716308594, Train SBP MSE: 154.1479566670062, Val SBP MSE: 191.2342021315954, Train SBP MAE: 9.276015908520563, Val SBP MAE: 10.28124745614188, Train SBP R2: 0.5790087846680956, Val SBP R2: 0.4781520483832874, Train DBP MSE: 59.784425054502705, Val DBP MSE: 70.34152053261863, Train DBP MAE: 5.829253145480156, Val DBP MAE: 6.277092959499359, Train DBP R2: 0.5253149293256474, Val DBP R2: 0.44421052935936867\n",
      "Epoch: 26, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 217.72060911865233, Val Loss: 252.1742100096708, Train SBP MSE: 152.84346204959803, Val SBP MSE: 184.01985715092505, Train SBP MAE: 9.23716056752886, Val SBP MAE: 10.069532196235656, Train SBP R2: 0.5825714707150014, Val SBP R2: 0.4978388570631931, Train DBP MSE: 59.33021409596894, Val DBP MSE: 68.16327855132324, Train DBP MAE: 5.806287461529459, Val DBP MAE: 6.199101435620444, Train DBP R2: 0.5289213395362685, Val DBP R2: 0.46142147317383975\n",
      "Epoch: 27, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 216.12197613351003, Val Loss: 245.81727559649312, Train SBP MSE: 151.54493889776992, Val SBP MSE: 178.82642639576625, Train SBP MAE: 9.195977490615844, Val SBP MAE: 9.897307849557059, Train SBP R2: 0.586117848180164, Val SBP R2: 0.5120109098196235, Train DBP MSE: 58.910796582355594, Val DBP MSE: 66.99793920751222, Train DBP MAE: 5.783209717362268, Val DBP MAE: 6.130261351776123, Train DBP R2: 0.53225149169396, Val DBP R2: 0.47062916917058883\n",
      "Epoch: 28, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 214.66775089024134, Val Loss: 261.3352637003283, Train SBP MSE: 150.33882988660446, Val SBP MSE: 189.47176039239037, Train SBP MAE: 9.158154150247574, Val SBP MAE: 10.363713593455723, Train SBP R2: 0.5894118347461372, Val SBP R2: 0.4829614736910838, Train DBP MSE: 58.54099126108869, Val DBP MSE: 71.87157888430451, Train DBP MAE: 5.766604983142444, Val DBP MAE: 6.454172254657745, Train DBP R2: 0.5351877257532708, Val DBP R2: 0.4321210789907428\n",
      "Epoch: 29, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.001), Train Loss: 213.20299520612446, Val Loss: 248.6313844502953, Train SBP MSE: 149.17083697600268, Val SBP MSE: 180.52485916351807, Train SBP MAE: 9.124146940769467, Val SBP MAE: 9.94524918259212, Train SBP R2: 0.5926017229909454, Val SBP R2: 0.5073761548912135, Train DBP MSE: 58.14888936380125, Val DBP MSE: 68.11661940270506, Train DBP MAE: 5.745327813805853, Val DBP MAE: 6.170880942058563, Train DBP R2: 0.5383009934087806, Val DBP R2: 0.46179014111440586\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 461.0733037405831, Val Loss: 410.87640530099816, Train SBP MSE: 342.88061134554306, Val SBP MSE: 301.9938858084015, Train SBP MAE: 14.135572013838626, Val SBP MAE: 13.395396637071881, Train SBP R2: 0.06356380969788655, Val SBP R2: 0.17590635486094264, Train DBP MSE: 117.74532864519466, Val DBP MSE: 108.90674330062699, Train DBP MAE: 8.41997949461808, Val DBP MAE: 8.129000582613264, Train DBP R2: 0.06510851950880203, Val DBP R2: 0.1394951267767648\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 384.7953877232143, Val Loss: 366.59012272501775, Train SBP MSE: 283.96343836494333, Val SBP MSE: 270.9244584505998, Train SBP MAE: 13.097679561315264, Val SBP MAE: 12.813425033351352, Train SBP R2: 0.2244716335401712, Val SBP R2: 0.2606899178630041, Train DBP MSE: 100.17240569081224, Val DBP MSE: 95.68642065468575, Train DBP MAE: 7.860174825249399, Val DBP MAE: 7.674350393486023, Train DBP R2: 0.20463656827654275, Val DBP R2: 0.24395286481611766\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 354.11291983816966, Val Loss: 366.14758908203794, Train SBP MSE: 260.51923759351286, Val SBP MSE: 265.72670710118217, Train SBP MAE: 12.454315186677661, Val SBP MAE: 12.365732271357945, Train SBP R2: 0.2884997451587419, Val SBP R2: 0.27487376083916837, Train DBP MSE: 92.72861818060795, Val DBP MSE: 100.43462972307064, Train DBP MAE: 7.496975712105206, Val DBP MAE: 7.719254030799866, Train DBP R2: 0.26373983467318174, Val DBP R2: 0.20643583952825895\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 334.4430493495396, Val Loss: 345.89490489506414, Train SBP MSE: 245.3767240916655, Val SBP MSE: 256.3488523502262, Train SBP MAE: 12.008725964341846, Val SBP MAE: 12.485160832105365, Train SBP R2: 0.32985524087960705, Val SBP R2: 0.3004644461757684, Train DBP MSE: 88.07096768100342, Val DBP MSE: 89.56081655152865, Train DBP MAE: 7.2583420171431134, Val DBP MAE: 7.376020058822632, Train DBP R2: 0.3007213253300811, Val DBP R2: 0.2923531017752976\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 319.4470603934152, Val Loss: 318.9208663438312, Train SBP MSE: 233.87027414868774, Val SBP MSE: 234.3892236408833, Train SBP MAE: 11.681439519487109, Val SBP MAE: 11.526681085259574, Train SBP R2: 0.3612803369391955, Val SBP R2: 0.3603888066327351, Train DBP MSE: 84.45815351815888, Val DBP MSE: 84.54690133846408, Train DBP MAE: 7.0802291244472775, Val DBP MAE: 6.994491948563712, Train DBP R2: 0.329406872521674, Val DBP R2: 0.3319695510787204\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 307.61797886265344, Val Loss: 307.52459249548764, Train SBP MSE: 224.6701218718506, Val SBP MSE: 226.4339208839576, Train SBP MAE: 11.413615731239318, Val SBP MAE: 11.451895363398961, Train SBP R2: 0.3864067373924378, Val SBP R2: 0.3820975721250903, Train DBP MSE: 81.70976559274571, Val DBP MSE: 81.10527726547423, Train DBP MAE: 6.946597906824521, Val DBP MAE: 6.8863097707475935, Train DBP R2: 0.35122892258615024, Val DBP R2: 0.35916285607394116\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 297.68526244245254, Val Loss: 320.75844857810404, Train SBP MSE: 216.92373733687077, Val SBP MSE: 238.55286867554952, Train SBP MAE: 11.196195530210222, Val SBP MAE: 11.964613528442383, Train SBP R2: 0.4075627741659532, Val SBP R2: 0.34902687655756737, Train DBP MSE: 79.41752209158994, Val DBP MSE: 82.2229094753228, Train DBP MAE: 6.837099010392598, Val DBP MAE: 6.99218664112091, Train DBP R2: 0.36942921082772784, Val DBP R2: 0.3503321084645743\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 289.4681651262556, Val Loss: 329.44139258124926, Train SBP MSE: 210.53420080862122, Val SBP MSE: 240.60943875235336, Train SBP MAE: 11.008053623131344, Val SBP MAE: 11.97196418397086, Train SBP R2: 0.4250131433216481, Val SBP R2: 0.34341482144413227, Train DBP MSE: 77.49450376575426, Val DBP MSE: 88.84807567387992, Train DBP MAE: 6.737792157820293, Val DBP MAE: 7.318119229371207, Train DBP R2: 0.3846978713371365, Val DBP R2: 0.29798468141834256\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 283.03993954554966, Val Loss: 290.7419693090798, Train SBP MSE: 205.51694083616323, Val SBP MSE: 212.21355789754455, Train SBP MAE: 10.856081517321723, Val SBP MAE: 10.913467040525164, Train SBP R2: 0.4387157081762969, Val SBP R2: 0.4209026980543903, Train DBP MSE: 75.99964795283759, Val DBP MSE: 78.5548338929089, Train DBP MAE: 6.660448262303216, Val DBP MAE: 6.73055911485127, Train DBP R2: 0.3965669448718476, Val DBP R2: 0.3793146748177465\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 276.47028677368166, Val Loss: 280.66056187017745, Train SBP MSE: 200.51984162780857, Val SBP MSE: 204.49335948810733, Train SBP MAE: 10.71342311382975, Val SBP MAE: 10.807383009501866, Train SBP R2: 0.4523632122648775, Val SBP R2: 0.44196990089327914, Train DBP MSE: 74.3441092426896, Val DBP MSE: 76.17749064719735, Train DBP MAE: 6.584080916241237, Val DBP MAE: 6.642042892987387, Train DBP R2: 0.4097118318372117, Val DBP R2: 0.3980987774936674\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 271.42948578055245, Val Loss: 279.96957614347747, Train SBP MSE: 196.6714111798546, Val SBP MSE: 204.05197212327437, Train SBP MAE: 10.597381653990064, Val SBP MAE: 10.76620222631182, Train SBP R2: 0.4628736040108046, Val SBP R2: 0.4431743773396477, Train DBP MSE: 73.07081022461726, Val DBP MSE: 75.92755318691465, Train DBP MAE: 6.516761684090751, Val DBP MAE: 6.59740742969513, Train DBP R2: 0.4198217565179668, Val DBP R2: 0.400073608399965\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 266.87181373291014, Val Loss: 271.1370770560758, Train SBP MSE: 193.23987673500955, Val SBP MSE: 197.26425022775348, Train SBP MAE: 10.492793923384802, Val SBP MAE: 10.524877763257708, Train SBP R2: 0.47224541721952173, Val SBP R2: 0.4616969989619243, Train DBP MSE: 71.865909190003, Val DBP MSE: 73.8936419719735, Train DBP MAE: 6.455915445011002, Val DBP MAE: 6.491097590650831, Train DBP R2: 0.42938860494462716, Val DBP R2: 0.41614415150057926\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 262.7464395987374, Val Loss: 282.1280885832401, Train SBP MSE: 190.08977191568735, Val SBP MSE: 206.96219323926798, Train SBP MAE: 10.400056215729032, Val SBP MAE: 10.936604511260986, Train SBP R2: 0.48084862212073354, Val SBP R2: 0.435232843287659, Train DBP MSE: 70.81012965267323, Val DBP MSE: 75.17042376081059, Train DBP MAE: 6.406912824504716, Val DBP MAE: 6.6193308262416295, Train DBP R2: 0.43777143682495423, Val DBP R2: 0.4060559152900426\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 258.6035666015625, Val Loss: 265.6848620845369, Train SBP MSE: 186.98263095403018, Val SBP MSE: 193.64265517321368, Train SBP MAE: 10.308797800050463, Val SBP MAE: 10.45080933254787, Train SBP R2: 0.4893344890627217, Val SBP R2: 0.47157976020301373, Train DBP MSE: 69.70056216933914, Val DBP MSE: 72.05564185634546, Train DBP MAE: 6.347968111685344, Val DBP MAE: 6.430670665686471, Train DBP R2: 0.4465813420597079, Val DBP R2: 0.430666742191928\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 255.00245347726005, Val Loss: 304.6006946807806, Train SBP MSE: 184.22648011589854, Val SBP MSE: 223.8968224384544, Train SBP MAE: 10.224571114764895, Val SBP MAE: 11.336283954238892, Train SBP R2: 0.4968617720450682, Val SBP R2: 0.389020913306103, Train DBP MSE: 68.79250211315365, Val DBP MSE: 80.73340719685304, Train DBP MAE: 6.304577638333185, Val DBP MAE: 6.884720119994027, Train DBP R2: 0.45379128932530455, Val DBP R2: 0.36210111312356286\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 252.13730562220982, Val Loss: 268.81109700386, Train SBP MSE: 181.91140460101076, Val SBP MSE: 196.54111264659028, Train SBP MAE: 10.150398326376505, Val SBP MAE: 10.572992763355801, Train SBP R2: 0.5031844407049144, Val SBP R2: 0.46367032727485546, Train DBP MSE: 68.175294857563, Val DBP MSE: 72.27521957000513, Train DBP MAE: 6.272480349969864, Val DBP MAE: 6.4158699107442585, Train DBP R2: 0.458691881234881, Val DBP R2: 0.4289317927578622\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 249.4614947352818, Val Loss: 291.2969722712933, Train SBP MSE: 179.91825013796708, Val SBP MSE: 213.46682658977403, Train SBP MAE: 10.092892332846779, Val SBP MAE: 11.031608840560914, Train SBP R2: 0.5086279155188791, Val SBP R2: 0.4174827256196725, Train DBP MSE: 67.4344076353065, Val DBP MSE: 77.85070631062125, Train DBP MAE: 6.235054042022568, Val DBP MAE: 6.710970089312962, Train DBP R2: 0.46457448532679857, Val DBP R2: 0.38487819822838487\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 246.3577383013044, Val Loss: 267.2447833980023, Train SBP MSE: 177.38009682380346, Val SBP MSE: 194.6097217378708, Train SBP MAE: 10.021054036358425, Val SBP MAE: 10.457246111679078, Train SBP R2: 0.51555982867253, Val SBP R2: 0.4689407881979115, Train DBP MSE: 66.8123929238806, Val DBP MSE: 72.65637930471595, Train DBP MAE: 6.204196525168419, Val DBP MAE: 6.446351949923379, Train DBP R2: 0.46951324817321716, Val DBP R2: 0.4259201352676575\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 243.99315924333845, Val Loss: 268.52275544328705, Train SBP MSE: 175.61461281233915, Val SBP MSE: 195.84928400981272, Train SBP MAE: 9.970247600603104, Val SBP MAE: 10.523080040359497, Train SBP R2: 0.5203815160675891, Val SBP R2: 0.46555821842062295, Train DBP MSE: 66.15238526127196, Val DBP MSE: 72.6902839129736, Train DBP MAE: 6.173426777049474, Val DBP MAE: 6.4604831875937325, Train DBP R2: 0.4747536729775934, Val DBP R2: 0.4256522447794635\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 241.72540289393834, Val Loss: 280.7853181061405, Train SBP MSE: 173.87237997741363, Val SBP MSE: 204.35009201218017, Train SBP MAE: 9.913220819766181, Val SBP MAE: 10.888976354653495, Train SBP R2: 0.5251397025166697, Val SBP R2: 0.4423608552205519, Train DBP MSE: 65.57532569449803, Val DBP MSE: 76.44809257301976, Train DBP MAE: 6.1448867368085045, Val DBP MAE: 6.705214026396615, Train DBP R2: 0.4793354944300483, Val DBP R2: 0.3959606704415538\n",
      "Epoch: 20, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 239.58838644845144, Val Loss: 275.429016643294, Train SBP MSE: 172.10548959283864, Val SBP MSE: 200.30426086690886, Train SBP MAE: 9.859100772033418, Val SBP MAE: 10.607026787022182, Train SBP R2: 0.5299652308366289, Val SBP R2: 0.4534012897882871, Train DBP MSE: 65.14879882288655, Val DBP MSE: 75.12950544554226, Train DBP MAE: 6.122091910243034, Val DBP MAE: 6.565752625410897, Train DBP R2: 0.48272209450207093, Val DBP R2: 0.40637922318288155\n",
      "Epoch: 21, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 237.29981235177178, Val Loss: 257.5710325293393, Train SBP MSE: 170.31031382205205, Val SBP MSE: 187.64040788517434, Train SBP MAE: 9.801449164635795, Val SBP MAE: 10.263004283360072, Train SBP R2: 0.5348680089584984, Val SBP R2: 0.4879589456073321, Train DBP MSE: 64.60079148117485, Val DBP MSE: 69.94695828140696, Train DBP MAE: 6.094483842825889, Val DBP MAE: 6.338330432019915, Train DBP R2: 0.48707324287379694, Val DBP R2: 0.44732808415595604\n",
      "Epoch: 22, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 235.50386715436662, Val Loss: 257.68716327451045, Train SBP MSE: 168.8634739718256, Val SBP MSE: 187.93524417021422, Train SBP MAE: 9.76303832248279, Val SBP MAE: 10.221033225849697, Train SBP R2: 0.5388194519753737, Val SBP R2: 0.4871543839248751, Train DBP MSE: 64.19944083051172, Val DBP MSE: 69.77535717572299, Train DBP MAE: 6.075503312570708, Val DBP MAE: 6.292471162469046, Train DBP R2: 0.49025994512612336, Val DBP R2: 0.4486839560075635\n",
      "Epoch: 23, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 233.52669524710518, Val Loss: 297.3092892383527, Train SBP MSE: 167.3224080790075, Val SBP MSE: 217.0667207481744, Train SBP MAE: 9.710718302168164, Val SBP MAE: 11.282271006774902, Train SBP R2: 0.5430282343501249, Val SBP R2: 0.40765918269869705, Train DBP MSE: 63.713069441117106, Val DBP MSE: 80.2566768091534, Train DBP MAE: 6.049490551689693, Val DBP MAE: 6.925057888943808, Train DBP R2: 0.4941217074018047, Val DBP R2: 0.3658679030338693\n",
      "Epoch: 24, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 231.83525184413364, Val Loss: 257.85580568121816, Train SBP MSE: 165.97744947586736, Val SBP MSE: 188.519579154794, Train SBP MAE: 9.673507010793687, Val SBP MAE: 10.287696207754953, Train SBP R2: 0.5467014309928171, Val SBP R2: 0.4855598259882612, Train DBP MSE: 63.315160142504865, Val DBP MSE: 69.35191271131502, Train DBP MAE: 6.032009948338781, Val DBP MAE: 6.279631455121722, Train DBP R2: 0.49728108550674643, Val DBP R2: 0.4520297178412145\n",
      "Epoch: 25, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 230.19861552908762, Val Loss: 253.25491888126464, Train SBP MSE: 164.78002186893406, Val SBP MSE: 184.74034232649834, Train SBP MAE: 9.635520300899232, Val SBP MAE: 10.101463248934065, Train SBP R2: 0.5499717079034854, Val SBP R2: 0.495872766746439, Train DBP MSE: 62.827689115208464, Val DBP MSE: 68.5334440620886, Train DBP MAE: 6.0059522273983275, Val DBP MAE: 6.231512865897588, Train DBP R2: 0.5011515788473269, Val DBP R2: 0.45849668434755486\n",
      "Epoch: 26, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 228.47336551252093, Val Loss: 263.3573066983406, Train SBP MSE: 163.34659474528078, Val SBP MSE: 192.16572729228162, Train SBP MAE: 9.589036037479127, Val SBP MAE: 10.402568283816747, Train SBP R2: 0.5538865196202578, Val SBP R2: 0.4756100632594704, Train DBP MSE: 62.48585521836668, Val DBP MSE: 71.20383100294019, Train DBP MAE: 5.98567635373388, Val DBP MAE: 6.393562637819563, Train DBP R2: 0.5038657213239555, Val DBP R2: 0.4373971554629992\n",
      "Epoch: 27, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 226.82206439993723, Val Loss: 255.0809431686262, Train SBP MSE: 162.0842388296571, Val SBP MSE: 185.6699943569569, Train SBP MAE: 9.554645945365088, Val SBP MAE: 10.153049650573731, Train SBP R2: 0.557334121279019, Val SBP R2: 0.4933358930993428, Train DBP MSE: 62.03869508617403, Val DBP MSE: 69.42789763485098, Train DBP MAE: 5.96506341946125, Val DBP MAE: 6.270257168006897, Train DBP R2: 0.5074161483584065, Val DBP R2: 0.45142933814926367\n",
      "Epoch: 28, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 225.06213643886022, Val Loss: 250.7766033709594, Train SBP MSE: 160.63254741757072, Val SBP MSE: 183.1088730006807, Train SBP MAE: 9.510140379503795, Val SBP MAE: 10.141622116988046, Train SBP R2: 0.5612988143250732, Val SBP R2: 0.5003247890118786, Train DBP MSE: 61.6853895013142, Val DBP MSE: 67.68997929609208, Train DBP MAE: 5.944203189260619, Val DBP MAE: 6.193939275496347, Train DBP R2: 0.5102213754115383, Val DBP R2: 0.46516115267646807\n",
      "Epoch: 29, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 5e-05, 0.0005), Train Loss: 223.6227824645996, Val Loss: 255.15774508586097, Train SBP MSE: 159.56364721235838, Val SBP MSE: 185.6249583054527, Train SBP MAE: 9.479934433419364, Val SBP MAE: 10.162817466654097, Train SBP R2: 0.5642180719408776, Val SBP R2: 0.49345878937503196, Train DBP MSE: 61.25926194393374, Val DBP MSE: 69.54677324713671, Train DBP MAE: 5.925048851200512, Val DBP MAE: 6.291775738171169, Train DBP R2: 0.5136048049503694, Val DBP R2: 0.45049006624947974\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 449.73005995570594, Val Loss: 398.6125553138077, Train SBP MSE: 333.15058958520285, Val SBP MSE: 293.8074537278067, Train SBP MAE: 14.060742982835182, Val SBP MAE: 13.302120863505772, Train SBP R2: 0.09013732889762771, Val SBP R2: 0.19824583579421184, Train DBP MSE: 116.47351997075747, Val DBP MSE: 104.82719465640794, Train DBP MAE: 8.42403240046265, Val DBP MAE: 8.060004538345337, Train DBP R2: 0.07520661094246761, Val DBP R2: 0.171728865317742\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 372.1072406581334, Val Loss: 360.28229346266613, Train SBP MSE: 274.06610763469826, Val SBP MSE: 265.79723070087897, Train SBP MAE: 12.84349459716252, Val SBP MAE: 12.560376103373937, Train SBP R2: 0.2515020878047619, Val SBP R2: 0.27468131306762855, Train DBP MSE: 97.82629120804974, Val DBP MSE: 94.49964511811088, Train DBP MAE: 7.746129880458968, Val DBP MAE: 7.536688839094979, Train DBP R2: 0.22326458917069625, Val DBP R2: 0.253329934607157\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 333.48688476736885, Val Loss: 380.5383456507374, Train SBP MSE: 244.051974337965, Val SBP MSE: 282.038795233854, Train SBP MAE: 12.003303087602342, Val SBP MAE: 12.763779910114833, Train SBP R2: 0.33347324543107726, Val SBP R2: 0.23036064716105975, Train DBP MSE: 89.1090874643074, Val DBP MSE: 98.51239616450476, Train DBP MAE: 7.312855954943385, Val DBP MAE: 7.664816953141349, Train DBP R2: 0.292478710932488, Val DBP R2: 0.2216239839396037\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 313.726976109096, Val Loss: 306.2817496346817, Train SBP MSE: 228.78743283500052, Val SBP MSE: 224.1757236590723, Train SBP MAE: 11.549042784432002, Val SBP MAE: 11.29522663481576, Train SBP R2: 0.3751620100294908, Val SBP R2: 0.38825983589913005, Train DBP MSE: 84.52992750269097, Val DBP MSE: 82.11683390089031, Train DBP MAE: 7.081472109287126, Val DBP MAE: 6.923766082559313, Train DBP R2: 0.32883699100338315, Val DBP R2: 0.3511702434226378\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 300.1209002685547, Val Loss: 297.5677556904404, Train SBP MSE: 218.42776655604874, Val SBP MSE: 216.9950118278055, Train SBP MAE: 11.236776772253855, Val SBP MAE: 11.200556421606882, Train SBP R2: 0.403455142105385, Val SBP R2: 0.4078548650232501, Train DBP MSE: 81.20684150420762, Val DBP MSE: 80.59279129488975, Train DBP MAE: 6.9154550474950245, Val DBP MAE: 6.861841819858551, Train DBP R2: 0.3552221123892453, Val DBP R2: 0.363212161578644\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 290.0455061959403, Val Loss: 309.89026785507065, Train SBP MSE: 210.6590270658188, Val SBP MSE: 227.0546116137602, Train SBP MAE: 11.0078246098314, Val SBP MAE: 11.476290390668597, Train SBP R2: 0.4246722321681098, Val SBP R2: 0.3804038050984573, Train DBP MSE: 78.83300122700113, Val DBP MSE: 82.84484469211768, Train DBP MAE: 6.799695400118828, Val DBP MAE: 7.004402936935425, Train DBP R2: 0.3740702745774426, Val DBP R2: 0.34541801160829577\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 281.4261373883929, Val Loss: 300.4371545781165, Train SBP MSE: 204.20669592764995, Val SBP MSE: 219.7298495232296, Train SBP MAE: 10.801421896641594, Val SBP MAE: 11.250731987162998, Train SBP R2: 0.4422940987585934, Val SBP R2: 0.40039192464201456, Train DBP MSE: 76.5965088776653, Val DBP MSE: 80.71517846747368, Train DBP MAE: 6.683886742905208, Val DBP MAE: 6.878907780211312, Train DBP R2: 0.3918279017176095, Val DBP R2: 0.3622451437867541\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 274.44365466657365, Val Loss: 309.3488237077619, Train SBP MSE: 198.88727272818443, Val SBP MSE: 227.92579477520164, Train SBP MAE: 10.654696568516323, Val SBP MAE: 11.402012400654383, Train SBP R2: 0.4568218971545549, Val SBP R2: 0.37802648376569514, Train DBP MSE: 74.86689206176912, Val DBP MSE: 81.42931752347164, Train DBP MAE: 6.597204675316811, Val DBP MAE: 6.910533621556418, Train DBP R2: 0.40556096479791437, Val DBP R2: 0.3566025167168311\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 267.8035037318638, Val Loss: 274.05093345432874, Train SBP MSE: 193.9527740022719, Val SBP MSE: 199.41089958774495, Train SBP MAE: 10.498739977060046, Val SBP MAE: 10.700865508542742, Train SBP R2: 0.4702984339870432, Val SBP R2: 0.45583913170353496, Train DBP MSE: 73.09576565704602, Val DBP MSE: 74.64985223636509, Train DBP MAE: 6.505575979641506, Val DBP MAE: 6.590357038102831, Train DBP R2: 0.41962361174706087, Val DBP R2: 0.41016910718312916\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 262.10972236066544, Val Loss: 295.1051660429625, Train SBP MSE: 189.64522064012942, Val SBP MSE: 214.64217115026415, Train SBP MAE: 10.36910228902953, Val SBP MAE: 11.02137914995466, Train SBP R2: 0.48206272956543206, Val SBP R2: 0.41427539584027695, Train DBP MSE: 71.65169967321876, Val DBP MSE: 80.4757802214356, Train DBP MAE: 6.428774200180599, Val DBP MAE: 6.8252021627698625, Train DBP R2: 0.43108941681195123, Val DBP R2: 0.36413670119737485\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 257.0628817199707, Val Loss: 303.33892517508275, Train SBP MSE: 185.9103436096036, Val SBP MSE: 222.7933531278937, Train SBP MAE: 10.263918430410113, Val SBP MAE: 11.300009713390896, Train SBP R2: 0.49226299724457434, Val SBP R2: 0.3920321068738297, Train DBP MSE: 70.28039001100167, Val DBP MSE: 80.55665062332037, Train DBP MAE: 6.36553063054766, Val DBP MAE: 6.8528373653548105, Train DBP R2: 0.441977540655787, Val DBP R2: 0.36349771987434265\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 251.8889545227051, Val Loss: 338.4647258849205, Train SBP MSE: 182.04885637003886, Val SBP MSE: 251.2844384531945, Train SBP MAE: 10.143172357504708, Val SBP MAE: 12.072059215273176, Train SBP R2: 0.5028090482018681, Val SBP R2: 0.3142844322914662, Train DBP MSE: 68.90835089466277, Val DBP MSE: 87.17960825034511, Train DBP MAE: 6.291764475049291, Val DBP MAE: 7.2214985592842105, Train DBP R2: 0.45287145632552117, Val DBP R2: 0.31116774341481346\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 248.232719304548, Val Loss: 300.8861397180087, Train SBP MSE: 179.30260284152507, Val SBP MSE: 221.17753024561716, Train SBP MAE: 10.056804994950976, Val SBP MAE: 11.161996283558437, Train SBP R2: 0.5103093007876103, Val SBP R2: 0.3964414324646107, Train DBP MSE: 67.94599167023433, Val DBP MSE: 79.7179383191235, Train DBP MAE: 6.241921266531945, Val DBP MAE: 6.795404824134281, Train DBP R2: 0.4605125360222059, Val DBP R2: 0.37012463757586134\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 244.07742482561383, Val Loss: 271.7272639579703, Train SBP MSE: 176.16917375141958, Val SBP MSE: 198.97043794894165, Train SBP MAE: 9.960643208381107, Val SBP MAE: 10.648740375954764, Train SBP R2: 0.5188669628502318, Val SBP R2: 0.45704108198969284, Train DBP MSE: 66.87180813424092, Val DBP MSE: 72.76377976423039, Train DBP MAE: 6.1880782905987335, Val DBP MAE: 6.466686094665527, Train DBP R2: 0.469041494647055, Val DBP R2: 0.4250715319948236\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 239.91048794817243, Val Loss: 256.10033143373033, Train SBP MSE: 172.99361474306792, Val SBP MSE: 186.64935407517106, Train SBP MAE: 9.85949164783614, Val SBP MAE: 10.22379417817252, Train SBP R2: 0.5275396853124056, Val SBP R2: 0.4906633750186372, Train DBP MSE: 65.83098656935339, Val DBP MSE: 69.46428133028091, Train DBP MAE: 6.133503411109107, Val DBP MAE: 6.2721387693541395, Train DBP R2: 0.47730556104290367, Val DBP R2: 0.4511418596490857\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 236.37461315830777, Val Loss: 264.64066934672746, Train SBP MSE: 170.25286106615073, Val SBP MSE: 193.25229951977272, Train SBP MAE: 9.781605819865636, Val SBP MAE: 10.386535610253471, Train SBP R2: 0.5350249173344122, Val SBP R2: 0.4726449791642642, Train DBP MSE: 64.98074745153059, Val DBP MSE: 71.40369022869476, Train DBP MAE: 6.091984199043683, Val DBP MAE: 6.3674977315221515, Train DBP R2: 0.4840564132149513, Val DBP R2: 0.4358180077214704\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 233.42149463500976, Val Loss: 289.7481090957112, Train SBP MSE: 167.98090746331715, Val SBP MSE: 212.22107742587963, Train SBP MAE: 9.709285574633734, Val SBP MAE: 10.98608238519941, Train SBP R2: 0.5412298163750189, Val SBP R2: 0.42088217844850884, Train DBP MSE: 64.24572730169866, Val DBP MSE: 77.54014112895426, Train DBP MAE: 6.053514497494698, Val DBP MAE: 6.711683151136126, Train DBP R2: 0.48989243307216257, Val DBP R2: 0.3873320669621161\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 230.2224109662737, Val Loss: 248.2913681044221, Train SBP MSE: 165.62683359277543, Val SBP MSE: 180.61995591047682, Train SBP MAE: 9.634853090306692, Val SBP MAE: 9.971192040361677, Train SBP R2: 0.5476589928699194, Val SBP R2: 0.5071166508796261, Train DBP MSE: 63.35100045745639, Val DBP MSE: 67.68976899288167, Train DBP MAE: 6.010703876311438, Val DBP MAE: 6.161544119630541, Train DBP R2: 0.49699651536292955, Val DBP R2: 0.46516281434526774\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 226.99570721697125, Val Loss: 274.71711723285796, Train SBP MSE: 163.19394867386615, Val SBP MSE: 199.8565846176002, Train SBP MAE: 9.55562584028244, Val SBP MAE: 10.567911000442505, Train SBP R2: 0.5543034090588853, Val SBP R2: 0.45462292760769984, Train DBP MSE: 62.50730089176824, Val DBP MSE: 74.87026117120492, Train DBP MAE: 5.963344057655334, Val DBP MAE: 6.543561587810516, Train DBP R2: 0.503695443848091, Val DBP R2: 0.40842759002098183\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 223.95447068132674, Val Loss: 260.9785333246374, Train SBP MSE: 160.87358146877133, Val SBP MSE: 190.8301386235374, Train SBP MAE: 9.488910732691629, Val SBP MAE: 10.383942556544712, Train SBP R2: 0.5606405297759596, Val SBP R2: 0.4792546739160256, Train DBP MSE: 61.73786242324462, Val DBP MSE: 70.16100314451121, Train DBP MAE: 5.924834539628029, Val DBP MAE: 6.326659123011998, Train DBP R2: 0.5098047432764579, Val DBP R2: 0.445636851435121\n",
      "Epoch: 20, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 221.18450231410435, Val Loss: 248.6569437379157, Train SBP MSE: 158.72791249033105, Val SBP MSE: 180.75954911030558, Train SBP MAE: 9.42257611340114, Val SBP MAE: 9.988671695000784, Train SBP R2: 0.5665005347378474, Val SBP R2: 0.5067357230718477, Train DBP MSE: 61.06836894284024, Val DBP MSE: 67.91213230457556, Train DBP MAE: 5.888603670157705, Val DBP MAE: 6.16707750144686, Train DBP R2: 0.5151204849562021, Val DBP R2: 0.46340585506488163\n",
      "Epoch: 21, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 218.75573020717076, Val Loss: 243.60178640250533, Train SBP MSE: 156.82879395771567, Val SBP MSE: 176.75141085547799, Train SBP MAE: 9.359060747323717, Val SBP MAE: 9.85518900566101, Train SBP R2: 0.571687189406467, Val SBP R2: 0.517673299691322, Train DBP MSE: 60.49355707318712, Val DBP MSE: 66.86699231186186, Train DBP MAE: 5.858138706878253, Val DBP MAE: 6.122340003871917, Train DBP R2: 0.519684459816243, Val DBP R2: 0.47166381990410255\n",
      "Epoch: 22, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 216.1224938040597, Val Loss: 247.9117147107447, Train SBP MSE: 154.807570772257, Val SBP MSE: 180.95663200765134, Train SBP MAE: 9.29782470543044, Val SBP MAE: 10.07997538343157, Train SBP R2: 0.5772073222950361, Val SBP R2: 0.5061979149541982, Train DBP MSE: 59.83966966565607, Val DBP MSE: 66.96837946648486, Train DBP MAE: 5.828051281598636, Val DBP MAE: 6.139044248935154, Train DBP R2: 0.5248762901294721, Val DBP R2: 0.4708627295584432\n",
      "Epoch: 23, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 213.97097479422433, Val Loss: 255.59623286580256, Train SBP MSE: 153.14810582002076, Val SBP MSE: 186.57734337761013, Train SBP MAE: 9.242833306768963, Val SBP MAE: 10.185100869750977, Train SBP R2: 0.5817394625980816, Val SBP R2: 0.49085988084551224, Train DBP MSE: 59.30259113592621, Val DBP MSE: 69.03529040511684, Train DBP MAE: 5.79919825048106, Val DBP MAE: 6.245254008974348, Train DBP R2: 0.529140664330781, Val DBP R2: 0.45453144573424875\n",
      "Epoch: 24, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 211.71593258754186, Val Loss: 253.59600601335765, Train SBP MSE: 151.42347809512881, Val SBP MSE: 184.4488956782293, Train SBP MAE: 9.195512559073311, Val SBP MAE: 10.127289447539193, Train SBP R2: 0.5864495679903041, Val SBP R2: 0.496668078645197, Train DBP MSE: 58.73206451536757, Val DBP MSE: 69.16479071754848, Train DBP MAE: 5.772421013631139, Val DBP MAE: 6.255663876846858, Train DBP R2: 0.533670614546988, Val DBP R2: 0.45350822488901843\n",
      "Epoch: 25, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 209.3625910069057, Val Loss: 241.6743213437375, Train SBP MSE: 149.58245126332332, Val SBP MSE: 175.1662250769965, Train SBP MAE: 9.138007714714323, Val SBP MAE: 9.803166601399013, Train SBP R2: 0.5914775692699755, Val SBP R2: 0.5219990214618621, Train DBP MSE: 58.17617612542403, Val DBP MSE: 66.52870342309828, Train DBP MAE: 5.7437651831865315, Val DBP MAE: 6.109627770314898, Train DBP R2: 0.5380843380113661, Val DBP R2: 0.47433674197041376\n",
      "Epoch: 26, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 207.4375957257952, Val Loss: 277.1491113066455, Train SBP MSE: 148.10747412469993, Val SBP MSE: 203.28956565854912, Train SBP MAE: 9.09126778685706, Val SBP MAE: 10.737310701942445, Train SBP R2: 0.5955058576209995, Val SBP R2: 0.4452548642372919, Train DBP MSE: 57.682524639273566, Val DBP MSE: 73.87540295699208, Train DBP MAE: 5.71746621475901, Val DBP MAE: 6.508773186206818, Train DBP R2: 0.542003903857792, Val DBP R2: 0.4162882634334002\n",
      "Epoch: 27, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 205.20686030535018, Val Loss: 281.88502119576907, Train SBP MSE: 146.33709133068174, Val SBP MSE: 205.85229461465016, Train SBP MAE: 9.033781281028475, Val SBP MAE: 10.823523220116751, Train SBP R2: 0.6003409240089793, Val SBP R2: 0.43826158143859106, Train DBP MSE: 57.18311777685691, Val DBP MSE: 76.050930453701, Train DBP MAE: 5.6919690372058325, Val DBP MAE: 6.611829083960397, Train DBP R2: 0.545969167077525, Val DBP R2: 0.39909876757655005\n",
      "Epoch: 28, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 203.44768676060266, Val Loss: 258.63270380553644, Train SBP MSE: 145.0111424513669, Val SBP MSE: 188.77117436204568, Train SBP MAE: 8.992023167644229, Val SBP MAE: 10.226185063689096, Train SBP R2: 0.6039622034747629, Val SBP R2: 0.4848732623815559, Train DBP MSE: 56.70981025866944, Val DBP MSE: 69.87839843879475, Train DBP MAE: 5.667210856781687, Val DBP MAE: 6.2807651982852395, Train DBP R2: 0.5497272029291153, Val DBP R2: 0.44786979605447796\n",
      "Epoch: 29, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.001), Train Loss: 201.68031690063478, Val Loss: 283.64260872626437, Train SBP MSE: 143.64400056106552, Val SBP MSE: 208.43941884507947, Train SBP MAE: 8.952180096135821, Val SBP MAE: 10.910676988329206, Train SBP R2: 0.6076959845664738, Val SBP R2: 0.43120172778700183, Train DBP MSE: 56.26783424556862, Val DBP MSE: 75.21067169769461, Train DBP MAE: 5.646100356963703, Val DBP MAE: 6.603196995231084, Train DBP R2: 0.5532364683410322, Val DBP R2: 0.4057379042580693\n",
      "Epoch: 0, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 459.15303700299944, Val Loss: 416.00472627043507, Train SBP MSE: 341.05471551205, Val SBP MSE: 310.65089533768884, Train SBP MAE: 14.12089932232096, Val SBP MAE: 13.545300334766933, Train SBP R2: 0.06855048693080146, Val SBP R2: 0.15228274235005834, Train DBP MSE: 118.00630048375713, Val DBP MSE: 105.37894017974975, Train DBP MAE: 8.412903270829164, Val DBP MAE: 8.043857734162467, Train DBP R2: 0.06303641735980425, Val DBP R2: 0.16736935830076927\n",
      "Epoch: 1, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 398.0105995274135, Val Loss: 376.13264473003267, Train SBP MSE: 294.3595361961408, Val SBP MSE: 277.3049326020236, Train SBP MAE: 13.38689420765468, Val SBP MAE: 12.9089966683524, Train SBP R2: 0.19607900378822585, Val SBP R2: 0.24327861105099025, Train DBP MSE: 103.52413922553009, Val DBP MSE: 98.84657353271481, Train DBP MAE: 8.00926439699786, Val DBP MAE: 7.855001012311663, Train DBP R2: 0.17802398701714772, Val DBP R2: 0.21898354823148714\n",
      "Epoch: 2, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 366.2991368687221, Val Loss: 369.64785864932884, Train SBP MSE: 270.03213225403846, Val SBP MSE: 270.057366702261, Train SBP MAE: 12.718030838789259, Val SBP MAE: 12.443562369482859, Train SBP R2: 0.2625192185851043, Val SBP R2: 0.26305607437523193, Train DBP MSE: 96.08653951137944, Val DBP MSE: 99.61046944682244, Train DBP MAE: 7.6637751272508075, Val DBP MAE: 7.670078132765633, Train DBP R2: 0.23707812265097794, Val DBP R2: 0.21294777728835623\n",
      "Epoch: 3, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 342.24760380859374, Val Loss: 329.77178475974466, Train SBP MSE: 252.0669411680022, Val SBP MSE: 243.4370854641974, Train SBP MAE: 12.202692108944484, Val SBP MAE: 12.00127555116926, Train SBP R2: 0.3115836875051723, Val SBP R2: 0.33569861990683547, Train DBP MSE: 89.95909192822037, Val DBP MSE: 86.35148974822648, Train DBP MAE: 7.362584602485384, Val DBP MAE: 7.19238209438324, Train DBP R2: 0.28572972189967194, Val DBP R2: 0.3177109563057944\n",
      "Epoch: 4, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 325.73289875837054, Val Loss: 322.25825093912687, Train SBP MSE: 239.43233948843334, Val SBP MSE: 238.0619349355013, Train SBP MAE: 11.84016491192409, Val SBP MAE: 11.676538703264509, Train SBP R2: 0.3460898621657068, Val SBP R2: 0.35036655724108545, Train DBP MSE: 86.04504349380385, Val DBP MSE: 84.21870553913561, Train DBP MAE: 7.160633058105196, Val DBP MAE: 7.039106124932426, Train DBP R2: 0.31680705276000953, Val DBP R2: 0.3345627246154037\n",
      "Epoch: 5, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 312.14769079241074, Val Loss: 311.1408944347877, Train SBP MSE: 228.86980076437385, Val SBP MSE: 228.2219301741465, Train SBP MAE: 11.535517059585027, Val SBP MAE: 11.46224336302621, Train SBP R2: 0.3749370561900691, Val SBP R2: 0.3772183770064542, Train DBP MSE: 82.98772916950632, Val DBP MSE: 82.94226962006114, Train DBP MAE: 7.009162741170611, Val DBP MAE: 7.013797234766824, Train DBP R2: 0.34108196156409754, Val DBP R2: 0.34464822800511385\n",
      "Epoch: 6, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 301.7424665422712, Val Loss: 307.4621309632575, Train SBP MSE: 220.61455570414137, Val SBP MSE: 224.6324136671799, Train SBP MAE: 11.294308596733638, Val SBP MAE: 11.322525752966744, Train SBP R2: 0.39748283445346566, Val SBP R2: 0.3870136009547619, Train DBP MSE: 80.80677112860891, Val DBP MSE: 82.84758680111257, Train DBP MAE: 6.897273093908174, Val DBP MAE: 6.943496601172856, Train DBP R2: 0.3583986493274637, Val DBP R2: 0.34539634538193076\n",
      "Epoch: 7, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 293.47635400565014, Val Loss: 307.07919528410247, Train SBP MSE: 214.1315182903065, Val SBP MSE: 225.50959605561988, Train SBP MAE: 11.099699504293714, Val SBP MAE: 11.307313546316964, Train SBP R2: 0.41518856250141145, Val SBP R2: 0.3846199086784887, Train DBP MSE: 78.99438531440073, Val DBP MSE: 81.5953237678092, Train DBP MAE: 6.80454014344556, Val DBP MAE: 6.871098135525839, Train DBP R2: 0.37278889373513857, Val DBP R2: 0.3552908515443298\n",
      "Epoch: 8, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 286.0546351283482, Val Loss: 302.60332233770674, Train SBP MSE: 208.45919613553136, Val SBP MSE: 221.07759579978145, Train SBP MAE: 10.932382908187593, Val SBP MAE: 11.505859568568638, Train SBP R2: 0.4306801580394013, Val SBP R2: 0.3967141377928104, Train DBP MSE: 77.21899060166066, Val DBP MSE: 81.53543274419366, Train DBP MAE: 6.712142941852978, Val DBP MAE: 7.003497825186593, Train DBP R2: 0.3868854308168883, Val DBP R2: 0.35576406850153186\n",
      "Epoch: 9, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 280.046363684954, Val Loss: 294.0961312916423, Train SBP MSE: 203.833016156711, Val SBP MSE: 215.18610450309325, Train SBP MAE: 10.799174527277266, Val SBP MAE: 11.259507047108242, Train SBP R2: 0.4433146500802848, Val SBP R2: 0.41279108757938043, Train DBP MSE: 75.81002927401742, Val DBP MSE: 78.92448799615931, Train DBP MAE: 6.642499328558785, Val DBP MAE: 6.831647586263929, Train DBP R2: 0.39807250682840833, Val DBP R2: 0.37639392677576455\n",
      "Epoch: 10, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 274.5223486179897, Val Loss: 284.85469735475084, Train SBP MSE: 199.72995656578843, Val SBP MSE: 208.8419612956596, Train SBP MAE: 10.667765796974727, Val SBP MAE: 10.781743815013341, Train SBP R2: 0.45452045573032773, Val SBP R2: 0.43010325298002416, Train DBP MSE: 74.36508864097917, Val DBP MSE: 76.02755990318086, Train DBP MAE: 6.5658948551620755, Val DBP MAE: 6.598930644198826, Train DBP R2: 0.40954525656027785, Val DBP R2: 0.399283425312178\n",
      "Epoch: 11, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 269.7541848763602, Val Loss: 282.23141909081494, Train SBP MSE: 196.11837903913465, Val SBP MSE: 204.18106990096987, Train SBP MAE: 10.559767266866139, Val SBP MAE: 10.696777701950074, Train SBP R2: 0.4643839819494643, Val SBP R2: 0.44282208988218597, Train DBP MSE: 73.18472980846477, Val DBP MSE: 78.07494643052179, Train DBP MAE: 6.506692387972559, Val DBP MAE: 6.677582192502703, Train DBP R2: 0.41891724124228147, Val DBP R2: 0.38310640972293\n",
      "Epoch: 12, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 265.47289967389787, Val Loss: 288.5078688487274, Train SBP MSE: 192.915911232669, Val SBP MSE: 210.39334763927138, Train SBP MAE: 10.466022217423575, Val SBP MAE: 11.086290764944893, Train SBP R2: 0.4731301946340586, Val SBP R2: 0.42586976453205905, Train DBP MSE: 72.08187862794881, Val DBP MSE: 78.12011997919441, Train DBP MAE: 6.445283120986393, Val DBP MAE: 6.7936273948124475, Train DBP R2: 0.42767381939937255, Val DBP R2: 0.38274947995351905\n",
      "Epoch: 13, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 261.5995136082241, Val Loss: 279.07752507434685, Train SBP MSE: 189.9870039072385, Val SBP MSE: 204.0443791666948, Train SBP MAE: 10.375456497478485, Val SBP MAE: 10.748168055125646, Train SBP R2: 0.48112929031582086, Val SBP R2: 0.4431950973196178, Train DBP MSE: 71.11506960318918, Val DBP MSE: 75.04967437190672, Train DBP MAE: 6.39640895824773, Val DBP MAE: 6.598917159012386, Train DBP R2: 0.4353502302677258, Val DBP R2: 0.40700999246140457\n",
      "Epoch: 14, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 258.1550962219238, Val Loss: 264.30345904543805, Train SBP MSE: 187.42531823328486, Val SBP MSE: 193.02503775834813, Train SBP MAE: 10.29897744599751, Val SBP MAE: 10.412188068989344, Train SBP R2: 0.4881254723508883, Val SBP R2: 0.47326514063830116, Train DBP MSE: 70.20881757057289, Val DBP MSE: 71.29167690241736, Train DBP MAE: 6.35296504872867, Val DBP MAE: 6.355724619729179, Train DBP R2: 0.44254582192490166, Val DBP R2: 0.4367030586394065\n",
      "Epoch: 15, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 254.70597990112304, Val Loss: 271.52728682941665, Train SBP MSE: 184.82086059175145, Val SBP MSE: 198.3357132043578, Train SBP MAE: 10.214795202541351, Val SBP MAE: 10.578406842531477, Train SBP R2: 0.4952384682769919, Val SBP R2: 0.458773145627418, Train DBP MSE: 69.34217217009493, Val DBP MSE: 73.20463987701099, Train DBP MAE: 6.3081813149486266, Val DBP MAE: 6.4627192306654795, Train DBP R2: 0.4494269390854403, Val DBP R2: 0.4215881638951069\n",
      "Epoch: 16, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 251.64026845441546, Val Loss: 265.1581026178391, Train SBP MSE: 182.53009722138935, Val SBP MSE: 193.39741084675165, Train SBP MAE: 10.154899712862287, Val SBP MAE: 10.392719324874879, Train SBP R2: 0.5014947383968085, Val SBP R2: 0.47224899325852, Train DBP MSE: 68.54581828039171, Val DBP MSE: 71.7812759844519, Train DBP MAE: 6.267247377286639, Val DBP MAE: 6.387959220450265, Train DBP R2: 0.455749945488378, Val DBP R2: 0.432834589311907\n",
      "Epoch: 17, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 248.50976698172434, Val Loss: 317.44027028615557, Train SBP MSE: 180.111374322656, Val SBP MSE: 233.91743415196683, Train SBP MAE: 10.075497543832235, Val SBP MAE: 11.523527493722098, Train SBP R2: 0.5081004769009427, Val SBP R2: 0.3616762456768027, Train DBP MSE: 67.81302905668733, Val DBP MSE: 83.54941982384778, Train DBP MAE: 6.231169452224459, Val DBP MAE: 6.959807479981014, Train DBP R2: 0.46156825191394657, Val DBP R2: 0.3398509519751557\n",
      "Epoch: 18, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 245.9661884626116, Val Loss: 262.7857376461273, Train SBP MSE: 178.23422306628942, Val SBP MSE: 191.51677907706951, Train SBP MAE: 10.020905676426207, Val SBP MAE: 10.332205008152552, Train SBP R2: 0.5132271370647667, Val SBP R2: 0.47738094050338886, Train DBP MSE: 67.12603096851687, Val DBP MSE: 71.28545032267164, Train DBP MAE: 6.199586013800757, Val DBP MAE: 6.3747695760045735, Train DBP R2: 0.4670229792235935, Val DBP R2: 0.436752256715231\n",
      "Epoch: 19, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 243.43073649291992, Val Loss: 266.1363402964646, Train SBP MSE: 176.34785236098506, Val SBP MSE: 194.18022270927509, Train SBP MAE: 9.961861614792687, Val SBP MAE: 10.422424082837786, Train SBP R2: 0.5183789763298703, Val SBP R2: 0.4701128232512427, Train DBP MSE: 66.4542572830808, Val DBP MSE: 71.9687221867095, Train DBP MAE: 6.161288526099069, Val DBP MAE: 6.402325971794128, Train DBP R2: 0.47235682560678904, Val DBP R2: 0.4313535205954858\n",
      "Epoch: 20, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 240.40646823817661, Val Loss: 267.6815714827403, Train SBP MSE: 174.03217016017487, Val SBP MSE: 194.79362108223546, Train SBP MAE: 9.892513590131488, Val SBP MAE: 10.41574620802743, Train SBP R2: 0.524703301900708, Val SBP R2: 0.4684389559153457, Train DBP MSE: 65.72347255917498, Val DBP MSE: 72.90527055123685, Train DBP MAE: 6.120001781715666, Val DBP MAE: 6.440866647325243, Train DBP R2: 0.4781592164134032, Val DBP R2: 0.423953570810371\n",
      "Epoch: 21, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 237.8708397251674, Val Loss: 261.82135906951737, Train SBP MSE: 172.10604137104053, Val SBP MSE: 190.82247821495966, Train SBP MAE: 9.840571771069936, Val SBP MAE: 10.285218571908134, Train SBP R2: 0.5299637238833044, Val SBP R2: 0.4792755779618516, Train DBP MSE: 65.0932078062003, Val DBP MSE: 71.02349447213098, Train DBP MAE: 6.094761743780545, Val DBP MAE: 6.329077998937879, Train DBP R2: 0.48316348413926347, Val DBP R2: 0.43882204853094386\n",
      "Epoch: 22, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 235.78287607509068, Val Loss: 251.07617222717954, Train SBP MSE: 170.49786561853975, Val SBP MSE: 182.6780982167699, Train SBP MAE: 9.787545986700058, Val SBP MAE: 10.040132119287764, Train SBP R2: 0.5343557890079502, Val SBP R2: 0.5015003054000887, Train DBP MSE: 64.59191465486862, Val DBP MSE: 68.42378908726138, Train DBP MAE: 6.071680535694531, Val DBP MAE: 6.204109515489851, Train DBP R2: 0.48714372438998943, Val DBP R2: 0.45936310122269297\n",
      "Epoch: 23, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 233.61453698643277, Val Loss: 252.91282914281982, Train SBP MSE: 168.9328812458186, Val SBP MSE: 184.44071844375497, Train SBP MAE: 9.741790348904473, Val SBP MAE: 10.13818831362043, Train SBP R2: 0.538629894791075, Val SBP R2: 0.49669039302731455, Train DBP MSE: 63.96871538913565, Val DBP MSE: 68.49038137554058, Train DBP MAE: 6.040498344598498, Val DBP MAE: 6.221264738750458, Train DBP R2: 0.49209189253292895, Val DBP R2: 0.45883693556162675\n",
      "Epoch: 24, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 231.4002394016811, Val Loss: 257.9677634858126, Train SBP MSE: 167.21482573633853, Val SBP MSE: 187.54099504350927, Train SBP MAE: 9.684781144666673, Val SBP MAE: 10.150497753552028, Train SBP R2: 0.543322050902532, Val SBP R2: 0.4882302275600846, Train DBP MSE: 63.45317445732414, Val DBP MSE: 70.44527221160529, Train DBP MAE: 6.012184119684355, Val DBP MAE: 6.281341994217464, Train DBP R2: 0.4961852593827294, Val DBP R2: 0.44339075619686896\n",
      "Epoch: 25, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 229.33415369175503, Val Loss: 257.0434676105841, Train SBP MSE: 165.57501371442171, Val SBP MSE: 187.01455905236386, Train SBP MAE: 9.637002542448045, Val SBP MAE: 10.164936787469047, Train SBP R2: 0.5478005173768812, Val SBP R2: 0.4896667882828757, Train DBP MSE: 63.0066291676219, Val DBP MSE: 70.04337796488423, Train DBP MAE: 5.985257339876038, Val DBP MAE: 6.294601032556806, Train DBP R2: 0.4997308046013772, Val DBP R2: 0.4465662432910814\n",
      "Epoch: 26, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 227.48188730381557, Val Loss: 272.5691905117558, Train SBP MSE: 164.2080244908233, Val SBP MSE: 198.3457693522403, Train SBP MAE: 9.596421803270067, Val SBP MAE: 10.536504849433898, Train SBP R2: 0.5515338815228068, Val SBP R2: 0.45874570398719283, Train DBP MSE: 62.500619374082554, Val DBP MSE: 74.2422908811531, Train DBP MAE: 5.965944699021748, Val DBP MAE: 6.510384472642626, Train DBP R2: 0.5037484947337014, Val DBP R2: 0.41338937180282576\n",
      "Epoch: 27, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 225.50383717912948, Val Loss: 252.60767785722638, Train SBP MSE: 162.68280505772597, Val SBP MSE: 183.69614090049987, Train SBP MAE: 9.547238467100689, Val SBP MAE: 10.051497226061139, Train SBP R2: 0.5556993858646813, Val SBP R2: 0.49872222761253227, Train DBP MSE: 62.02993243593357, Val DBP MSE: 68.9275740687047, Train DBP MAE: 5.938719847358976, Val DBP MAE: 6.206253536360604, Train DBP R2: 0.5074857233228709, Val DBP R2: 0.4553825448452794\n",
      "Epoch: 28, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 223.39345673566547, Val Loss: 251.004951372443, Train SBP MSE: 161.07987983071885, Val SBP MSE: 182.65147838931375, Train SBP MAE: 9.492954957471575, Val SBP MAE: 10.045624748638698, Train SBP R2: 0.5600771113564416, Val SBP R2: 0.5015729467073211, Train DBP MSE: 61.50388865344483, Val DBP MSE: 68.3723412122263, Train DBP MAE: 5.913184299084119, Val DBP MAE: 6.200943014172145, Train DBP R2: 0.5116624822335876, Val DBP R2: 0.4597696063282809\n",
      "Epoch: 29, Hyper parameters: (<class 'torch.optim.adam.Adam'>, 1e-05, 0.0005), Train Loss: 221.71993357979912, Val Loss: 251.55430061856396, Train SBP MSE: 159.76789539205004, Val SBP MSE: 183.504601571454, Train SBP MAE: 9.462210610478264, Val SBP MAE: 10.105040347834995, Train SBP R2: 0.563660252743939, Val SBP R2: 0.49924490820733425, Train DBP MSE: 61.124092528477135, Val DBP MSE: 68.06379425588594, Train DBP MAE: 5.897337234064511, Val DBP MAE: 6.175627037348066, Train DBP R2: 0.5146780427287797, Val DBP R2: 0.4622075284578242\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(hyp3)):\n",
    "    print(hyp3[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the pickle file\n",
    "# with open('/Users/rohansanda/Desktop/cs229_proj/losses/mse_losses4.pickle', 'rb') as file:\n",
    "#     mse = pickle.load(file)\n",
    "with open('/Users/rohansanda/Desktop/cs229_proj/mae_losses.pickle', 'rb') as file:\n",
    "    mae = pickle.load(file)\n",
    "# with open('/Users/rohansanda/Desktop/cs229_proj/losses/r2_scores4.pickle', 'rb') as file:\n",
    "#     r2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_mae': [[],\n",
       "  [15.375833636578406, 8.713700729494212],\n",
       "  [11.972529101582936, 7.353000742769241],\n",
       "  [11.439663389321735, 7.038355425446374],\n",
       "  [11.076581835222244, 6.8411152461801255],\n",
       "  [10.800626489673341, 6.696952756827218],\n",
       "  [10.602119946759087, 6.595589204876764],\n",
       "  [10.438135647712436, 6.505613999080658],\n",
       "  [10.292415665701457, 6.4304461440563205],\n",
       "  [10.171087990726743, 6.359010631322861],\n",
       "  [10.070176399060658, 6.3051252791336605],\n",
       "  [9.966994945015227, 6.248124210868563],\n",
       "  [9.883347949232373, 6.189953450410707],\n",
       "  [9.79264413877896, 6.143974798781532],\n",
       "  [9.729157598767962, 6.098834008073807],\n",
       "  [9.653731476586206, 6.050686426905223],\n",
       "  [9.59808897307941, 6.0108258758340565],\n",
       "  [9.541993831511906, 5.970723407517161],\n",
       "  [9.471223325668063, 5.9286748676538465],\n",
       "  [9.420249505696978, 5.895256172483308],\n",
       "  [9.361980288519177, 5.857829941439628],\n",
       "  [9.304077087974548, 5.821863911976133],\n",
       "  [9.25330858596393, 5.792142102261952],\n",
       "  [9.216913956683022, 5.767190180243764],\n",
       "  [9.164881928076063, 5.744840924446923],\n",
       "  [9.117783676474435, 5.7182214578322],\n",
       "  [9.077041244792937, 5.692642519044876],\n",
       "  [9.032416500691005, 5.670464270305634],\n",
       "  [8.996689843416213, 5.6534270384345735],\n",
       "  [8.956761166007178, 5.629914494797162],\n",
       "  [8.912737594624929, 5.606759631337439],\n",
       "  [8.87903367329325, 5.589007786590712],\n",
       "  [8.841933682503019, 5.573643998125621],\n",
       "  [8.811000398962838, 5.554744347684724],\n",
       "  [8.76487607557433, 5.539409979517119],\n",
       "  [8.74093315142904, 5.5272385739837375],\n",
       "  [8.713532646397182, 5.511839062993867],\n",
       "  [8.675212875093733, 5.492091031561579],\n",
       "  [8.639965228612082, 5.476325308718],\n",
       "  [8.623215117032187, 5.4668664071798325],\n",
       "  [8.578972011572974, 5.451527432812963],\n",
       "  [8.553840880611965, 5.436950826277052],\n",
       "  [8.51020661514146, 5.414504398260798],\n",
       "  [8.492775985908509, 5.406952996243749],\n",
       "  [8.465485380969728, 5.399612687778473],\n",
       "  [8.44057142190252, 5.384786333952631],\n",
       "  [8.407675051702771, 5.3720577984912055],\n",
       "  [8.386586891194753, 5.360472165788923],\n",
       "  [8.360646968507767, 5.351287633476939],\n",
       "  [8.338134855161394, 5.344373952416011],\n",
       "  [8.310336535419736, 5.327564877097947]],\n",
       " 'val_mae': [[],\n",
       "  [12.217105600002833, 7.576255136666979],\n",
       "  [11.756352823230198, 7.26373891613824],\n",
       "  [11.298428224754334, 6.962576482868195],\n",
       "  [11.06328768863678, 6.854749084595271],\n",
       "  [10.865795494433812, 6.753632110609327],\n",
       "  [10.589014391463143, 6.629924735655103],\n",
       "  [10.543812297030858, 6.519328643267495],\n",
       "  [10.450180394009182, 6.497902377510071],\n",
       "  [10.373595440101624, 6.490567090334211],\n",
       "  [10.277715554346358, 6.3646320267132355],\n",
       "  [10.243828898756844, 6.449388479260036],\n",
       "  [10.168654436765399, 6.297725832230705],\n",
       "  [10.13911204586029, 6.301141551399231],\n",
       "  [10.245570435251508, 6.375599510138375],\n",
       "  [9.931738461739677, 6.201085520853315],\n",
       "  [10.101186216190882, 6.283480352061136],\n",
       "  [9.930562637683323, 6.160771397168296],\n",
       "  [9.917156643431527, 6.1767473630496434],\n",
       "  [9.901564419937134, 6.177986690003531],\n",
       "  [9.940197104045323, 6.096576123523712],\n",
       "  [9.768772889654977, 6.0297571237700325],\n",
       "  [9.770735525131226, 6.088331806114741],\n",
       "  [9.884261475018093, 6.116009500326429],\n",
       "  [10.01960733707973, 6.201624402781896],\n",
       "  [9.76306651524135, 6.0271145871979845],\n",
       "  [9.734146297018869, 5.999608479840415],\n",
       "  [9.837853921399798, 6.059048527894701],\n",
       "  [9.735428364317757, 6.001661932849884],\n",
       "  [9.679567831366402, 5.986144155011858],\n",
       "  [9.680780412837438, 5.991913413824354],\n",
       "  [9.769326988247462, 5.924908165904454],\n",
       "  [9.695569918142047, 5.962392629432678],\n",
       "  [9.68404313708714, 5.942082137380328],\n",
       "  [9.733173186547416, 5.964125698348454],\n",
       "  [9.628747635364533, 5.951403975296021],\n",
       "  [9.666958768790108, 5.930609272820609],\n",
       "  [9.641017359161378, 5.956759972599574],\n",
       "  [9.673469102750506, 5.948057188456399],\n",
       "  [9.59044229575566, 5.882102230943953],\n",
       "  [9.802557717950004, 6.074196170193808],\n",
       "  [9.776443267604282, 6.000719177722931],\n",
       "  [9.665839617211478, 5.954697637040274],\n",
       "  [9.655850185012817, 5.929641919367654],\n",
       "  [9.740187832478114, 5.988761911855425],\n",
       "  [9.605373414284843, 5.96454426877158],\n",
       "  [9.832864487130301, 5.96837161255564],\n",
       "  [9.620000165993826, 5.9095250920023235],\n",
       "  [9.65996976740701, 5.939062900761195],\n",
       "  [9.653477613898685, 5.935405529444559],\n",
       "  [9.724839403833661, 5.957530332279205]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train = mae['train_mae']\n",
    "mae_val = mae['val_mae']\n",
    "mae_train_sbp = mae_train[0]\n",
    "mae_train_dbp = mae_train[1]\n",
    "mae_val_sbp = mae_val[0]\n",
    "mae_val_dbp = mae_val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_val_fixed = mae_val[1:]\n",
    "mae_train_fixed = mae_train[1:]\n",
    "mae_val_sbp = []\n",
    "mae_val_dbp = []\n",
    "mae_train_sbp = []\n",
    "mae_train_dbp = []\n",
    "\n",
    "for i in range(len(mae_train_fixed)):\n",
    "    mae_val_sbp.append(mae_val_fixed[i][0])\n",
    "    mae_val_dbp.append(mae_val_fixed[i][1])\n",
    "    mae_train_sbp.append(mae_train_fixed[i][0])\n",
    "    mae_train_dbp.append(mae_train_fixed[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract the validation and training losses\n",
    "# mse_train = mse['train_mse']\n",
    "# mse_val = mse['val_mse']\n",
    "# mae_train = mae['train_mae']\n",
    "# mae_val = mae['val_mae']\n",
    "# mae_train_sbp = mae_train[0]\n",
    "# mae_train_dbp = mae_train[1]\n",
    "# mae_val_sbp = mae_val[0]\n",
    "# mae_val_dbp = mae_val[1]\n",
    "# r2_train = r2['train_r2']\n",
    "# r2_val = r2['val_r2']\n",
    "\n",
    "# Plot the losses\n",
    "# plt.plot(mse_val, label='Validation Loss')\n",
    "# plt.plot(mse_train, label='Training Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('MSE Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(mae_val_sbp, label='Validation Loss')\n",
    "plt.plot(mae_train_sbp, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MAE Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the losses\n",
    "# plt.plot(r2_val, label='Validation r2')\n",
    "# plt.plot(r2_train, label='Training r2')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('R2 Score')\n",
    "# plt.title('R2 Score')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
