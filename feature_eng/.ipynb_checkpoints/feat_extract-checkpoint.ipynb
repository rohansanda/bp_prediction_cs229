{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "# Yang Paper:  https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9142317   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test1_segments.pickle', 'rb') as f:\n",
    "    segments = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('test1_bps.pickle', 'rb') as f:\n",
    "    labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(segments, labels, samples): \n",
    "    rand_rows = np.random.choice(segments.shape[0], size=samples, replace=False)  # for testing purposes to shorten time\n",
    "    X = segments[rand_rows, :]\n",
    "    y = labels[rand_rows, :]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "    \n",
    "    y_train_s = y_train[:, 0]\n",
    "    y_eval_s = y_eval[:, 0]\n",
    "    y_test_s = y_test[:, 0]\n",
    "    \n",
    "    y_train_d = y_train[:, 1]\n",
    "    y_eval_d = y_eval[:, 1]\n",
    "    y_test_d = y_test[:, 1]\n",
    "    \n",
    "    X_train_f = feature_prep(X_train)\n",
    "    X_eval_f = feature_prep(X_eval)\n",
    "    \n",
    "    # Run on SVM, linear, ridge reg, ada boost regression \n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)   # Random Forest\n",
    "    rf_reg.fit(X_train_f, y_train_s)\n",
    "    predictions.append(rf_reg.predict(X_eval_f))\n",
    "    \n",
    "    svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)    # SVR\n",
    "    svr.fit(X_train_f, y_train_s)\n",
    "    predictions.append(svr.predict(X_eval_f))\n",
    "    \n",
    "    ridge = Ridge(alpha=1)    # Ridge Regressor\n",
    "    ridge.fit(X_train_f, y_train_s)\n",
    "    predictions.append(ridge.predict(X_eval_f))\n",
    "    \n",
    "    ada_reg = AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=10), n_estimators=100, random_state=42)\n",
    "    ada_reg.fit(X_train_f, y_train_s)\n",
    "    predictions.append(ada_reg.predict(X_eval_f))\n",
    "\n",
    "    for prediction in predictions:      \n",
    "        mae = mean_absolute_error(y_eval_s, prediction)\n",
    "        mse = mean_squared_error(y_eval_s, prediction)\n",
    "        r2 = r2_score(y_eval_s, prediction)\n",
    "\n",
    "        print(\"MAE:\", mae)\n",
    "        print(\"MSE:\", mse)\n",
    "        print(\"RMSE:\", np.sqrt(mse))\n",
    "        print(\"r2:\", r2)\n",
    "    \n",
    "main(segments, labels, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_prep(X):\n",
    "    n_rows, n_cols = X.shape\n",
    "    feature_extr = Feature_Extract()\n",
    "    features = []\n",
    "    # ppgk, pir_p, pi_p, pi_v = feature_extr.Gen_Morph_Features(X)\n",
    "    # bws_66, dbws_66, sbws_66, bwrs_66 = feature_extr.Bandwidth_Features(X, n_rows, n_cols, 66)\n",
    "    # bws_75, dbws_75, sbws_75, bwrs_75 = feature_extr.Bandwidth_Features(X, n_rows, n_cols, 75)\n",
    "    # bws_50, dbws_50, sbws_50, bwrs_50 = feature_extr.Bandwidth_Features(X, n_rows, n_cols, 50)\n",
    "    # bws_90, dbws_90, sbws_90, bwrs_90 = feature_extr.Bandwidth_Features(X, n_rows, n_cols, 90)\n",
    "    # bws_33, dbws_33, sbws_33, bwrs_33 = feature_extr.Bandwidth_Features(X, n_rows, n_cols, 33)\n",
    "    # pca_feats = feature_extr.PCA(X) \n",
    "    # pc_1 = pca_feats[:, 0]\n",
    "    # pc_2 = pca_feats[:, 1]\n",
    "    \n",
    "    features.extend(feature_extr.Gen_Morph_Features(X))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 10))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 25))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 33))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 50))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 65))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 75))\n",
    "    features.extend(feature_extr.Bandwidth_Features(X, n_rows, n_cols, 90))\n",
    "    features.extend(feature_extr.PCA(X))\n",
    "    \n",
    "    return np.column_stack(features)\n",
    "    \n",
    "    #return np.column_stack((ppgk, pir_p, bws_66, bws_75, pi_p, sbws_66, bwrs_50, sbws_50, dbws_50, bws_90, dbws_90, pc_2, bws_50, dbws_33, sbws_33, dbws_75, bwrs_66, dbws_66, pi_v, pc_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Extract:\n",
    "    def __init__(self, ppgk_win_len=40, ppgk_order=3, n_components=5):\n",
    "        self.ppgk_win_len = ppgk_win_len\n",
    "        self.ppgk_order = ppgk_order\n",
    "        self.n_components = n_components\n",
    "        \n",
    "        \n",
    "    def PCA(self, X): \n",
    "        pca = PCA(n_components=self.n_components) \n",
    "        pca.fit(X)  \n",
    "        return [pca.transform(X)]\n",
    "    \n",
    "    \n",
    "    def Gen_Morph_Features(self, X):\n",
    "        x_means = np.mean(X, axis=1) \n",
    "        baselines = np.mean(savgol_filter(X, window_length=self.ppgk_win_len, polyorder=self.ppgk_order), axis=1)\n",
    "        peak_intens = np.max(X, axis=1) - baselines \n",
    "        valley_intens = baselines - X[:, 0]\n",
    "        ppgk = (x_means - valley_intens) / (peak_intens - valley_intens)\n",
    "        pir_p = peak_intens / valley_intens\n",
    "        return [ppgk, pir_p, peak_intens, valley_intens]\n",
    "    \n",
    "    \n",
    "    def Bandwidth_Features(self, X, n_rows, n_cols, percentage):\n",
    "        max_indices = np.argmax(X, axis=1)\n",
    "        mod_heights = np.max(X, axis=1) * (percentage / 100)\n",
    "        hist = {'bws':[], 'dbws':[], 'sbws':[], 'bwrs':[]}\n",
    "        for i in range(n_rows): \n",
    "            mod_height = mod_heights[i]\n",
    "            max_ind = max_indices[i]\n",
    "            spec_indices = [j for j in range(n_cols) if X[i,j] >= mod_height]\n",
    "            if len(spec_indices) < 3:     # abnormal pulse\n",
    "                hist['bws'].append(hist['bws'][i - 1])\n",
    "                hist['dbws'].append(hist['dbws'][i - 1])\n",
    "                hist['sbws'].append(hist['sbws'][i - 1])\n",
    "                hist['bwrs'].append(hist['bwrs'][i - 1])\n",
    "            else: \n",
    "                bw = np.max(spec_indices) - np.min(spec_indices)\n",
    "                dbw = np.max(spec_indices) - max_ind\n",
    "                sbw = max_ind - np.min(spec_indices)\n",
    "                if sbw == 0 or dbw == 0:   # abnormal pulse\n",
    "                    hist['bws'].append(hist['bws'][i - 1])\n",
    "                    hist['dbws'].append(hist['dbws'][i - 1])\n",
    "                    hist['sbws'].append(hist['sbws'][i - 1])\n",
    "                    hist['bwrs'].append(hist['bwrs'][i - 1])\n",
    "                else: \n",
    "                    bwr = dbw / sbw\n",
    "                    hist['bws'].append(bw)\n",
    "                    hist['dbws'].append(dbw)\n",
    "                    hist['sbws'].append(sbw)\n",
    "                    hist['bwrs'].append(bwr)    \n",
    "        return [np.array(hist['bws']), np.array(hist['dbws']), np.array(hist['sbws']), np.array(hist['bwrs'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
